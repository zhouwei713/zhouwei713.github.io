<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>luobodazahui</title>
  
  <subtitle>周萝卜的分享</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://blog.luobodazahui.top/"/>
  <updated>2019-10-16T03:37:24.924Z</updated>
  <id>https://blog.luobodazahui.top/</id>
  
  <author>
    <name>Luobo Zhou</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>用 Python 爬取网易严选妹子内衣信息，探究妹纸们的偏好</title>
    <link href="https://blog.luobodazahui.top/2019/10/16/%E7%94%A8-Python-%E7%88%AC%E5%8F%96%E7%BD%91%E6%98%93%E4%B8%A5%E9%80%89%E5%A6%B9%E5%AD%90%E5%86%85%E8%A1%A3%E4%BF%A1%E6%81%AF%EF%BC%8C%E6%8E%A2%E7%A9%B6%E5%A6%B9%E7%BA%B8%E4%BB%AC%E7%9A%84%E5%81%8F%E5%A5%BD/"/>
    <id>https://blog.luobodazahui.top/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/</id>
    <published>2019-10-16T03:32:51.000Z</published>
    <updated>2019-10-16T03:37:24.924Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/fengmian.jpg"></p><p>今天继续来分析爬虫数据分析文章，一起来看看网易严选商品评论的获取和分析。</p><blockquote><p>警告：本教程仅用作学习交流，请勿用作商业盈利，违者后果自负！如本文有侵犯任何组织集团公司的隐私或利益，请告知联系萝卜删除！！！声明：这是一篇超级严肃的技术文，超！级！严！肃！请本着学习交流的态度阅读，谢谢！</p></blockquote><p><img src="/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/shouzhang.jpg"></p><p><a id="more"></a></p><h1>网易商品评论爬取</h1><h2>分析网页</h2><h3>评论分析</h3><p>进入到网易精选官网，搜索“文胸”后，先随便点进一个商品。</p><p><img src="/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/1.png"></p><p>在商品页面，打开 Chrome 的控制台，切换至 Network 页，再把商品页面切换到评价标签下，选择一个评论文字，如“薄款、穿着舒适、满意”，在 Network 中搜索。</p><p><img src="/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/2.png"></p><p>可以发现，评论文字是通过 listByItemByTag.json 传递过来的，点击进入该请求，并拷贝出该请求的 URL：</p><blockquote><p>https://you.163.com/xhr/comment/listByItemByTag.json?csrf_token=060f4782bf9fda38128cfaeafb661f8c&amp;__timestamp=1571106038283&amp;itemId=1616018&amp;tag=%E5%85%A8%E9%83%A8&amp;size=20&amp;page=1&amp;orderBy=0&amp;oldItemTag=%E5%85%A8%E9%83%A8&amp;oldItemOrderBy=0&amp;tagChanged=0</p></blockquote><p><img src="/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/3.png"></p><p>将该 URL 放入 Postman 中，逐个尝试 url query params，最后能够发现，只需保留 itemId 和 page 两个请求参数即可。</p><p><img src="/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/4.png"></p><p>请求返回的是一个 JSON 格式的数据，下面就是分析该 JSON 数据了。</p><p>不难发现，所有的评论数据都存储在 commentList 中，我们只需保存该数据即可。</p><p>下面就是如何获取 itemId 的信息了，这个是产品的 ID，我们回到网易精选首页，继续分析。</p><h3>产品 ID 获取</h3><p>当我们在搜索框中输入关键字进行搜索的时候，同样能够发现在 Network 中有很多请求，此时可以观察各个请求，通过请求文件的名称（此处需要一些经验，守规矩的程序员都不会乱起名字），我们可以定位到搜索时展示搜索结果的请求。</p><p><img src="/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/5.png"></p><p>搜索一般都是 search，所以我们就锁定了这个 search.json 的请求。同样把请求 URL 拷贝到 Postman 中，逐个验证传参，最后保留 page 和 keyword 两个参数即可。</p><p><img src="/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/6.png"></p><p>该请求返回的数据较多，还是需要耐心的分析数据，也能够发现，在 result-&gt;data-&gt;directly-&gt;searcherResult-&gt;result 下面的 id 值，即为我们要获取的产品 ID。</p><p>以上，我们基本完成了前期的分析工作，下面开始代码的编写。</p><h2>编写代码</h2><h3>获取产品 ID</h3><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def search_keyword(keyword):</span><br><span class="line">    uri = &apos;https://you.163.com/xhr/search/search.json&apos;</span><br><span class="line">    query = &#123;</span><br><span class="line">        &quot;keyword&quot;: keyword,</span><br><span class="line">        &quot;page&quot;: 1</span><br><span class="line">    &#125;</span><br><span class="line">    try:</span><br><span class="line">        res = requests.get(uri, params=query).json()</span><br><span class="line">        result = res[&apos;data&apos;][&apos;directly&apos;][&apos;searcherResult&apos;][&apos;result&apos;]</span><br><span class="line">        product_id = []</span><br><span class="line">        for r in result:</span><br><span class="line">            product_id.append(r[&apos;id&apos;])</span><br><span class="line">        return product_id</span><br><span class="line">    except:</span><br><span class="line">        raise</span><br></pre></td></tr></table></figure></p><p>我这里是获取了 page 为 1 的产品 ID，下面就是通过产品 ID 来获取不同产品下的评论信息。</p><p>通过前面的分析，我们可以知道，评论信息都是如下形式的，对这种形式的信息，我们可以很方便地存储进入 MongoDB，然后再慢慢分析数据里的内容。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">                &quot;skuInfo&quot;: [</span><br><span class="line">                    &quot;颜色:肤色&quot;,</span><br><span class="line">                    &quot;杯码:75B&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;frontUserName&quot;: &quot;1****8&quot;,</span><br><span class="line">                &quot;frontUserAvatar&quot;: &quot;https://yanxuan.nosdn.127.net/f8f20a77db47b8c66c531c14c8b38ee7.jpg&quot;,</span><br><span class="line">                &quot;content&quot;: &quot;质量好，穿着舒服&quot;,</span><br><span class="line">                &quot;createTime&quot;: 1555546727635,</span><br><span class="line">                &quot;picList&quot;: [</span><br><span class="line">                    &quot;https://yanxuan.nosdn.127.net/742f28186d805571e4b3f28faa412941.jpg&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;commentReplyVO&quot;: null,</span><br><span class="line">                &quot;memberLevel&quot;: 4,</span><br><span class="line">                &quot;appendCommentVO&quot;: null,</span><br><span class="line">                &quot;star&quot;: 5,</span><br><span class="line">                &quot;itemId&quot;: 1680205</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure></p><p>对于 MongoDB，我们既可以自己搭建，也可以使用网上免费的服务。在这里我介绍一个免费的 MongoDB 服务网站：<a href="https://mlab.com/home" target="_blank" rel="noopener">mlab</a>，使用很简单，就不过多介绍使用过程了。</p><p>数据库有了，下面就是把数据保存进去了。</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">def details(product_id):</span><br><span class="line">    url = &apos;https://you.163.com/xhr/comment/listByItemByTag.json&apos;</span><br><span class="line">    try:</span><br><span class="line">        C_list = []</span><br><span class="line">        for i in range(1, 100):</span><br><span class="line">            query = &#123;</span><br><span class="line">                &quot;itemId&quot;: product_id,</span><br><span class="line">                &quot;page&quot;: i,</span><br><span class="line">            &#125;</span><br><span class="line">            res = requests.get(url, params=query).json()</span><br><span class="line">            if not res[&apos;data&apos;][&apos;commentList&apos;]:</span><br><span class="line">                break</span><br><span class="line">            print(&quot;爬取第 %s 页评论&quot; % i)</span><br><span class="line">            commentList = res[&apos;data&apos;][&apos;commentList&apos;]</span><br><span class="line">            C_list.append(commentList)</span><br><span class="line">            time.sleep(1)</span><br><span class="line">            # save to mongoDB</span><br><span class="line">            try:</span><br><span class="line">                mongo_collection.insert_many(commentList)</span><br><span class="line">            except:</span><br><span class="line">                continue</span><br><span class="line">        return C_list</span><br><span class="line">    except:</span><br><span class="line">        raise</span><br></pre></td></tr></table></figure></p><p>最后爬取完成之后，总共是七千多条数据，下面就可以根据个人需要做一些分析了。</p><p><img src="/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/7.png"></p><p>爬取的数据 MongoDB 链接</p><blockquote><p>conn = MongoClient(&quot;mongodb://%s:%s@ds149974.mlab.com:49974/you163&quot; % ('you163', 'you163'))db = conn.you163mongo_collection = db.you163</p></blockquote><h1>商品评论数据分析</h1><p>下面就到了激动人心的时刻了，一探妹子偏好！</p><h2>偏好颜色</h2><p>先来看看妹子们偏好的颜色</p><p><img src="/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/8.png"></p><p>可以看出，黑色是遥遥领先的哦，这里你要做到心中有数！</p><p>再通过饼状图来观察下不同颜色的占比情况</p><p><img src="/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/9.png"></p><p>那么这些颜色中，有你的她喜欢的吗？</p><h2>尺寸分布</h2><p><img src="/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/10.png"></p><p>没有问题，75B 就是大多数妹子的尺寸了</p><p>如果你对这种罩杯尺寸没有研究的话，不要紧，贴心的我给你准备了对照表，拿走不谢</p><p><img src="/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/chima.jpg"></p><h2>商品评论</h2><p>最后我们再来看看妹子们对于商品的评价情况</p><p><img src="/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/11.png"></p><p>就星级评价上来看，大多数都是五星好评，毕竟打着“严选”的名号，质量是必须有保证的。</p><p>再来看看在评论区，妹子最喜欢用什么词语来描述呢</p><p><img src="/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/data_wc.png"></p><p>舒服、很舒服，非常舒服；满意、很满意，非常满意。</p><p>仿佛进入了“夸夸群”，看来妹子们首要看重的就是舒服与否，毕竟是贴身的，质量最重要！</p><p>好了，看了上面的分析，单身的你是不是更加有了脱单的冲动？如果是已经有软妹傍身的你，是不是该下手讨好下身边的她了呢？</p><p>完整代码</p><blockquote><p>https://github.com/zhouwei713/data_analysis/tree/master/you163_spider</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/fengmian.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;今天继续来分析爬虫数据分析文章，一起来看看网易严选商品评论的获取和分析。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;警告：本教程仅用作学习交流，请勿用作商业盈利，违者后果自负！如本文有侵犯任何组织集团公司的隐私或利益，请告知联系萝卜删除！！！
声明：这是一篇超级严肃的技术文，超！级！严！肃！请本着学习交流的态度阅读，谢谢！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;/2019/10/16/用-Python-爬取网易严选妹子内衣信息，探究妹纸们的偏好/shouzhang.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.luobodazahui.top/categories/Python/"/>
    
    
      <category term="Python" scheme="https://blog.luobodazahui.top/tags/Python/"/>
    
      <category term="数据分析" scheme="https://blog.luobodazahui.top/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>爬 Boss 直聘，分析 Python 工作现状</title>
    <link href="https://blog.luobodazahui.top/2019/10/12/%E7%88%AC-Boss-%E7%9B%B4%E8%81%98%EF%BC%8C%E5%88%86%E6%9E%90-Python-%E5%B7%A5%E4%BD%9C%E7%8E%B0%E7%8A%B6/"/>
    <id>https://blog.luobodazahui.top/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/</id>
    <published>2019-10-12T05:32:01.000Z</published>
    <updated>2019-10-12T05:38:33.649Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/yes.jpg"></p><h1>引子</h1><p>要说在当今的编程圈，找10位程序猿询问下当前世界上最好的语言是哪个，那必须是 PHP（强迫症）！但是如果你询问当今最火爆的语言是哪个，那么80%的小伙伴儿会毫不犹豫的告诉你，是 Python！</p><p>不错，Python 依靠其简单易学，语言优雅等优势早早就获得了众多码农的爱戴，现如今又借助着人工智能这股强劲的东风，更加风光无限。</p><p>也正是因为如此，每年才会有众多的新鲜小白们跨入 Python 的大门，希望可以在未来的某一天，找到一条比较好的职业道路。</p><p>但是语言火爆，就一定代表职业前景美好嘛，为了解开这个疑问，我爬取了 Boss 直聘网站上帝都地区的 Python 相关岗位，来看看对于正在寻找 Python 岗位的公司，他们的要求是怎样的，薪资状况又是什么水平呢。</p><p><img src="/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/fengmian.png"></p><p><a id="more"></a></p><h1>抓取数据</h1><p>Boss 直聘网站大家应该都非常清楚了，就不做过多介绍了，直接进入主题。</p><h2>页面分析</h2><p>在 Boss 直聘的官网上搜索 Python，可以看到浏览器的 URL 变为如下：</p><p><img src="/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/1.png"></p><p>把该地址复制到 Postman 尝试访问，发现无法得到正确的返回：</p><p><img src="/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/2.png"></p><p>此时，再次回到浏览器，查看该请求下面的 headers，可以看到其中有一个 cookie，是很长的一串字符串，我们拷贝这个 cookie 到 Postman 中，再次请求：</p><p><img src="/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/3.png"></p><p>成功了，看来 Boss 直聘网也只是做了简单的 cookies 验证。</p><h2>BeautifulSoup 使用</h2><p>下面就是解析 HTML 数据了，我比较习惯用 BeautifulSoup 这个库来解析。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import requests</span><br><span class="line"></span><br><span class="line">url = &apos;https://www.zhipin.com/job_detail/?query=python&amp;city=101010100&apos;</span><br><span class="line"></span><br><span class="line">res = requests.get(url, headers=header).text</span><br><span class="line">print(res)</span><br><span class="line">content = BeautifulSoup(res, &quot;html.parser&quot;)</span><br><span class="line">ul = content.find_all(&apos;ul&apos;)</span><br><span class="line">print(ul[12])</span><br></pre></td></tr></table></figure></p><p>可以使用 BeautifulSoup 的 find 函数来查找 HTML 的元素标签，个人觉得还是挺方便的，虽然说速度上比 xpath 要慢，但是书写简单呀。</p><h2>编写代码</h2><p>我们通过分析 HTML 网页可以知道，所有的工作信息都是保存在 ul 这个标签中的，我们可以通过上面的代码拿到页面中所有的 ul 标签，find_all 返回的是一个列表，然后再查看，工作具体位于第几个 ul 中，这样就拿到具体的工作信息了。</p><p><img src="/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/4.png"></p><p>如图中所示，我们需要抓取红框中的信息，主要分为四部分。</p><ul><li>python：可以得到该 job 具体页面地址</li><li>10-15K：每个 job 的薪资</li><li>柯莱特集团：招聘公司名称</li><li>北京 朝阳区 望京|3-5年|学历不限：该 job 的详情信息</li></ul><p>对于前三个信息，还是比较好抓取的。</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">job_details_uri = job.find(&apos;h3&apos;, attrs=&#123;&apos;class&apos;: &apos;name&apos;&#125;).find(&apos;a&apos;)[&apos;href&apos;]</span><br><span class="line">job_company = job.find(&apos;div&apos;, attrs=&#123;&apos;class&apos;: &apos;company-text&apos;&#125;).find(&apos;h3&apos;, attrs=&#123;&apos;class&apos;: &apos;name&apos;&#125;).find(&apos;a&apos;).text</span><br><span class="line">job_salary = job.find(&apos;h3&apos;, attrs=&#123;&apos;class&apos;: &apos;name&apos;&#125;).find(&apos;span&apos;, attrs=&#123;&apos;class&apos;: &apos;red&apos;&#125;).text</span><br></pre></td></tr></table></figure></p><p>对于 job 的详情信息，需要用到正则表达式来分割字符串，我们先来看下该部分的原始形式：</p><p><img src="/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/5.png"></p><p>又可以把该部分切分成三块，site、year 和 edu。可以使用正则的 group 特性，帮助我们完成切分，最后我写的正则如下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rege = r&apos;&lt;p&gt;([\u4e00-\u9fa5 ]+)&lt;em class=&quot;vline&quot;&gt;&lt;/em&gt;([\d+-年]+|[\u4e00-\u9fa5]+)&lt;em class=&quot;vline&quot;&gt;&lt;/em&gt;([\u4e00-\u9fa5]+)&apos;</span><br></pre></td></tr></table></figure></p><p>正则表达式的具体写法这里就不说了，不熟悉的可以自行查找下。</p><p>下面把这部分代码整合到一起：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">for job in jobs:</span><br><span class="line">    job_dict = &#123;&#125;</span><br><span class="line">    job_details_uri = job.find(&apos;h3&apos;, attrs=&#123;&apos;class&apos;: &apos;name&apos;&#125;).find(&apos;a&apos;)[&apos;href&apos;]</span><br><span class="line">    job_company = job.find(&apos;div&apos;, attrs=&#123;&apos;class&apos;: &apos;company-text&apos;&#125;).find(&apos;h3&apos;, attrs=&#123;&apos;class&apos;: &apos;name&apos;&#125;).find(&apos;a&apos;).text</span><br><span class="line">    job_salary = job.find(&apos;h3&apos;, attrs=&#123;&apos;class&apos;: &apos;name&apos;&#125;).find(&apos;span&apos;, attrs=&#123;&apos;class&apos;: &apos;red&apos;&#125;).text</span><br><span class="line">    job_details = str(job.find(&apos;p&apos;))</span><br><span class="line">    print(job_details)</span><br><span class="line">    job_rege = re.match(rege, job_details)</span><br><span class="line">    job_dict[&apos;name&apos;] = job_company</span><br><span class="line">    job_dict[&apos;uri&apos;] = job_details_uri</span><br><span class="line">    job_dict[&apos;salary&apos;] = job_salary</span><br><span class="line">    job_dict[&apos;site&apos;] = job_rege.group(1)</span><br><span class="line">    job_dict[&apos;year&apos;] = job_rege.group(2)</span><br><span class="line">    job_dict[&apos;edu&apos;] = job_rege.group(3)</span><br><span class="line">    job_list.append(job_dict)</span><br><span class="line">print(job_list)</span><br></pre></td></tr></table></figure></p><p>由于我们最后还是得到了一个列表，里面包含字典，那么保存到 MongoDB 中应该是最为方便快捷的了。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mongo_collection.insert_many(job_list)</span><br></pre></td></tr></table></figure></p><h2>抓取多个页面</h2><p>通过查看 Boss 网站的下一页源码可得到翻页 URL 的规律：</p><blockquote><p>https://www.zhipin.com/c101010100/?query=python&amp;page=</p></blockquote><ul><li>c101010100：是城市代码，在我们这里就代表北京</li><li>query：也很明显，就是我们的搜索关键字</li><li>page：页数</li></ul><p><img src="/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/6.png"></p><p>于是我们最后整合代码如下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">def jobs(page):</span><br><span class="line"></span><br><span class="line">    for i in range(1, page + 1):</span><br><span class="line">        job_list = []</span><br><span class="line">        try:</span><br><span class="line">            print(&quot;正在抓取第 %s 页数据&quot; % i)</span><br><span class="line">            uri = &apos;/c101010100/?query=python&amp;page=%s&apos; % i</span><br><span class="line">            res = requests.get(config.url + uri, headers=header).text</span><br><span class="line">            content = BeautifulSoup(res, &quot;html.parser&quot;)</span><br><span class="line">            ul = content.find_all(&apos;ul&apos;)</span><br><span class="line">            jobs = ul[12].find_all(&quot;li&quot;)</span><br><span class="line">            for job in jobs:</span><br><span class="line">                job_dict = &#123;&#125;</span><br><span class="line">                job_details_uri = job.find(&apos;h3&apos;, attrs=&#123;&apos;class&apos;: &apos;name&apos;&#125;).find(&apos;a&apos;)[&apos;href&apos;]</span><br><span class="line">                job_company = job.find(&apos;div&apos;, attrs=&#123;&apos;class&apos;: &apos;company-text&apos;&#125;).find(&apos;h3&apos;, attrs=&#123;&apos;class&apos;: &apos;name&apos;&#125;).find(</span><br><span class="line">                    &apos;a&apos;).text</span><br><span class="line">                job_salary = job.find(&apos;h3&apos;, attrs=&#123;&apos;class&apos;: &apos;name&apos;&#125;).find(&apos;span&apos;, attrs=&#123;&apos;class&apos;: &apos;red&apos;&#125;).text</span><br><span class="line">                job_details = str(job.find(&apos;p&apos;))</span><br><span class="line">                job_rege = re.match(rege, job_details)</span><br><span class="line">                job_dict[&apos;name&apos;] = job_company</span><br><span class="line">                job_dict[&apos;uri&apos;] = job_details_uri</span><br><span class="line">                job_dict[&apos;salary&apos;] = job_salary</span><br><span class="line">                try:</span><br><span class="line">                    job_dict[&apos;site&apos;] = job_rege.group(1)</span><br><span class="line">                    job_dict[&apos;year&apos;] = job_rege.group(2)</span><br><span class="line">                    job_dict[&apos;edu&apos;] = job_rege.group(3)</span><br><span class="line">                except:</span><br><span class="line">                    continue</span><br><span class="line">                job_list.append(job_dict)</span><br><span class="line">            print(job_list)</span><br><span class="line"></span><br><span class="line">            # save to mongoDB</span><br><span class="line">            try:</span><br><span class="line">                mongo_collection.insert_many(job_list)</span><br><span class="line">            except:</span><br><span class="line">                continue</span><br><span class="line">            time.sleep(1)</span><br><span class="line">        except:</span><br><span class="line">            continue</span><br></pre></td></tr></table></figure></p><blockquote><p>因为我上面的正在表达式并不能匹配所有的情况，所以使用 try...except 来忽略了其他不规则的情况。</p></blockquote><h2>岗位详情抓取</h2><p>job 详情抓取完毕之后，开始抓取岗位详情，就是每个 job 的具体要求，毕竟知己知彼，百战不殆。</p><p>我们可以从 URI 中获得每个工作的详情页面地址，然后再拼接到 Boss 的主 URL 上：</p><blockquote><p>https://www.zhipin.com/job_detail/a8920821a7487a901HJ43tm7EFY~.html</p></blockquote><p>再来看下工作详情页面，所有的任职描述都在如下的 div 标签中：</p><p><img src="/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/7.png"></p><p>没有什么特殊的，直接用 BeautifulSoup 解析即可。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">def run_main():</span><br><span class="line">    jobs = job_collection.find()</span><br><span class="line">    for job in jobs:</span><br><span class="line">        print(&apos;获得工作的uri &apos;, job[&apos;uri&apos;])</span><br><span class="line">        get_details(job)</span><br><span class="line">        time.sleep(1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def get_details(items):</span><br><span class="line">    base_url = config.url</span><br><span class="line">    url = base_url + items[&apos;uri&apos;]</span><br><span class="line">    company_name = items[&apos;name&apos;]</span><br><span class="line">    try:</span><br><span class="line">        res = requests.get(url, headers=header).text</span><br><span class="line">        content = BeautifulSoup(res, &quot;html.parser&quot;)</span><br><span class="line">        text = content.find(&apos;div&apos;, attrs=&#123;&apos;class&apos;: &apos;text&apos;&#125;).text.strip()</span><br><span class="line">        result = &#123;&apos;name&apos;: company_name, &apos;details&apos;: text&#125;</span><br><span class="line">        details_collection.insert_one(result)</span><br><span class="line">    except:</span><br><span class="line">        raise </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    run_main()</span><br></pre></td></tr></table></figure></p><p>最后我把爬取到的数据都保存到了 mlab 在线服务器中了，有需要的可以来这里获取<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">job_conn = MongoClient(&quot;mongodb://%s:%s@ds151612.mlab.com:51612/boss&quot; % (&apos;boss&apos;, &apos;boss123&apos;))</span><br><span class="line">job_db = job_conn.boss</span><br><span class="line">job_collection = job_db.boss</span><br><span class="line">details_collection = job_db.job_details</span><br></pre></td></tr></table></figure></p><h1>分析数据</h1><p>Python 相关工作的数据已经拿到了，下面我们就来简单的做些分析，看看 Python 的工作前景到底怎么样</p><h2>薪资水平</h2><p>我们先来看看大家最关心的薪资水平吧</p><p><img src="/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/8.png"></p><p>发现在我爬取的数据中，15-30K 的薪资是占据绝大多数的，次之的是 15-25K，总的来说，这个水平在北京只能算是中等吧。</p><p>当然我们也看到了，还是有一些企业在用高薪招 Python 工程师，那就是有9家企业报价到了 30-60K，这个薪资对于年入百万的大佬来说可能不算什么，但是我们相信对于我们绝大多数的普通码农来说那绝对是超级高薪了，所以我们不能放过对于这种高薪的追求，来看看这些岗位的技能要求吧</p><p>出高薪的企业是如下</p><p><img src="/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/9.png"></p><p>对于我来说比较熟悉的企业还是蛮多的，映客、旷视、网易，京东都是大厂了，看来大厂就是财大气粗</p><p>再来看看他们对于职位的要求，高频词词云</p><p><img src="/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/money_wc.png"></p><p>基础组件 redis，MySQL，web 框架 tornado，flask 和 Django，这些技能看来是我们寻求高薪 Python 岗位的必备技能了。</p><p>而 “熟练，善于，掌握，精通” 等高频词语则告诉了我们，掌握一项技能，不能仅仅是知道了一些皮毛，我们要知其然，更要知其所以然。</p><h2>工作年限</h2><p>接下来再看看 Python 岗位对于工作年限上的要求又是怎样的呢</p><p><img src="/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/10.png"></p><p>大部分的工作年限要求都是集中在了3-5年，看来这个工龄的码农们应该是比较吃香的，年轻力壮，而且可塑性强，关键是能加班啊！</p><h2>学历要求</h2><p>下面再来看看对于学历的要求</p><p><img src="/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/11.png"></p><p>都说现在的企业招聘对于学历卡的严，但是在上图中能看出，大多数公司要求也不是特别高，只要你是本科毕业，最起码学历这关你是过的。</p><p>不过还是有一些企业要求是硕士，很有想法嘛，直接卡掉了 N 多的本科生，那么我们就来看看这些企业招收硕士的情况</p><p><img src="/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/12.png"></p><p>确实有很多大厂，比如爱奇艺和旷视。但是其他的不仅公司名气不够，就连给的薪资也不够看啊，那个绿盟科技是什么鬼，难不成是薪资少写了一个零嘛！</p><h2>所有任职要求词云</h2><p>最后，我们再来看看，想要找一份 Python 相关的工作，哪些技能是必备的呢</p><p><img src="/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/fulljob_wc.png"></p><p>精通 Python 就不用说了，那是本职。Java 语言的要求出现的频率也比较高，看来现在越来越要求程序猿们一人精通多种语言了，毕竟艺多不压身嘛。还有就是要熟悉 Linux，毕竟我们大多数的服务都是部署在 Linux 系统上的，不会怎么行呢。然后就是计算机专业，web 开发，Redis，MySQL 等等通用的技能了，掌握掌握，统统掌握。</p><p>怎么样，看完上面的分析，你有信心找到一份不错的 Python 相关的工作嘛？</p><p>完整代码在公众号后台回复“job”获取</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/yes.jpg&quot;&gt;&lt;/p&gt;
&lt;h1&gt;引子&lt;/h1&gt;
&lt;p&gt;要说在当今的编程圈，找10位程序猿询问下当前世界上最好的语言是哪个，那必须是 PHP（强迫症）！但是如果你询问当今最火爆的语言是哪个，那么80%的小伙伴儿会毫不犹豫的告诉你，是 Python！&lt;/p&gt;
&lt;p&gt;不错，Python 依靠其简单易学，语言优雅等优势早早就获得了众多码农的爱戴，现如今又借助着人工智能这股强劲的东风，更加风光无限。&lt;/p&gt;
&lt;p&gt;也正是因为如此，每年才会有众多的新鲜小白们跨入 Python 的大门，希望可以在未来的某一天，找到一条比较好的职业道路。&lt;/p&gt;
&lt;p&gt;但是语言火爆，就一定代表职业前景美好嘛，为了解开这个疑问，我爬取了 Boss 直聘网站上帝都地区的 Python 相关岗位，来看看对于正在寻找 Python 岗位的公司，他们的要求是怎样的，薪资状况又是什么水平呢。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/10/12/爬-Boss-直聘，分析-Python-工作现状/fengmian.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.luobodazahui.top/categories/Python/"/>
    
    
      <category term="Python" scheme="https://blog.luobodazahui.top/tags/Python/"/>
    
      <category term="数据分析" scheme="https://blog.luobodazahui.top/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>Python 带你分析，英超是否已经大结局</title>
    <link href="https://blog.luobodazahui.top/2019/10/09/Python-%E5%B8%A6%E4%BD%A0%E5%88%86%E6%9E%90%EF%BC%8C%E8%8B%B1%E8%B6%85%E6%98%AF%E5%90%A6%E5%B7%B2%E7%BB%8F%E5%A4%A7%E7%BB%93%E5%B1%80/"/>
    <id>https://blog.luobodazahui.top/2019/10/09/Python-带你分析，英超是否已经大结局/</id>
    <published>2019-10-09T05:40:09.000Z</published>
    <updated>2019-10-09T05:44:39.320Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/10/09/Python-带你分析，英超是否已经大结局/fengmian.jpg"></p><h1>引子</h1><p>随着本轮英超战罢，领头羊利物浦已经领先第二名曼城8分之多，新赛季的8连胜，不仅彰显着红军将士誓夺英超首冠的决心，也似乎在提醒着英超诸强，利物浦的复兴已然来临。</p><p>而曼城意外的输给狼队，不仅被拉大了和榜首的差距，也被身后的娜娜迎头赶上，看来英超亚军之争也是分外激烈。</p><p>不过足球本身就是一项偶然性很强的运动，在足球场上，分分秒秒都可能发生意想不到的事情，何况是漫长的一整个赛季。今天我们就从数据上出发，通过分析英超各个球队的数据，来看看哪些球队更具有冠军相，英超五强，谁人称雄。</p><p><a id="more"></a></p><p><img src="/2019/10/09/Python-带你分析，英超是否已经大结局/fengmian2.jpg"></p><h1>抓取数据</h1><p>我这里选择的是“懂球帝”网站上提供的数据</p><blockquote><p>https://www.dongqiudi.com/data?competition=8</p></blockquote><p>首先可以在数据页面拿到英超各个球队的战绩，进球数和净胜球等信息</p><p><img src="/2019/10/09/Python-带你分析，英超是否已经大结局/1.png"></p><blockquote><p>https://www.dongqiudi.com/team/50000516.html</p></blockquote><p>之后就是在每个球队的主页上，抓取球队所有球员的信息</p><p><img src="/2019/10/09/Python-带你分析，英超是否已经大结局/2.png"></p><p><img src="/2019/10/09/Python-带你分析，英超是否已经大结局/3.png"></p><p>下面给出部分抓取代码</p><p>抓取球队信息<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_team_data</span><span class="params">()</span>:</span></span><br><span class="line">    qiudui_url = <span class="string">'https://www.dongqiudi.com/data?competition=8'</span></span><br><span class="line">    qiudui_res = requests.get(qiudui_url, headers=header, cookies=session).text</span><br><span class="line">    content = BeautifulSoup(qiudui_res, <span class="string">'html.parser'</span>)</span><br><span class="line">    team_content = content.find(<span class="string">'table'</span>).find_all(<span class="string">'tr'</span>)</span><br><span class="line">    team_list = list(map(deal_element_list, team_content[<span class="number">2</span>:]))</span><br><span class="line">    save_to_csv(team_list)</span><br><span class="line">    print(<span class="string">'get player data now...'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> team_list:</span><br><span class="line">        print(<span class="string">"爬取url："</span>, i[<span class="number">0</span>])</span><br><span class="line">        get_players_urls(i[<span class="number">0</span>])</span><br></pre></td></tr></table></figure></p><p>对于球员信息，这里使用 selenium 来模拟浏览网页<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_players_urls</span><span class="params">(u)</span>:</span></span><br><span class="line">    Chrome_driver = webdriver.Chrome(options=options)</span><br><span class="line">    u = u</span><br><span class="line">    Chrome_driver.get(u)</span><br><span class="line">    ele_div = Chrome_driver.find_element_by_xpath(<span class="string">'//*[@id="__layout"]/div/div[2]/div[2]/div[1]/div[2]/div[2]/div[2]'</span>)</span><br><span class="line">    ele_p = ele_div.find_elements_by_tag_name(<span class="string">'p'</span>)</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></p><p>最后，我们可以得到两个数据文件，分别是 yingchao_data.csv 和 player_data.csv。</p><h1>分析数据</h1><h2>1. 英超球队进球数据</h2><p>首先先来看看各支球队在进球方面的数据，我选取了球队的进球和净胜球的数据</p><p><img src="/2019/10/09/Python-带你分析，英超是否已经大结局/4.gif"></p><p>可以看出基本上排在前列的球队无论是进球数量还是净胜球数量，都是比较高的，其中曼城和利物浦更是独一档的存在，绝对的英超巨无霸。</p><p>而排在下游的球队，净胜球就惨不忍睹了，副班长伍德福德8轮联赛下来，进4球失20球的成绩还是太扎眼，保级之路漫漫，劝君珍惜英超时啊。</p><h2>2. 球队球员综合得分</h2><p>接下来再来看看每个球队球员的综合得分情况，也许球员的综合得分也能够从侧面反应出每支球队的整体战斗力吧</p><p><img src="/2019/10/09/Python-带你分析，英超是否已经大结局/5.png"></p><p>从球员的综合得分来看，曼城还是高居榜首，热刺和利物浦紧随其后。</p><p>看来曼城无论从攻击力还是球员的综合实力来看，都是高居英超榜首的，但是现在竟然落后8分之多，是利物浦太过强势还是曼城自身出现了问题呢？</p><p>而目前排名中游的曼联，在这个榜单中的排位也不是很低，可以说曼联球员的能力还是有的，就是不知道怎么，在老爵爷隐退之后，曼联就不再是曾经的红魔了。</p><h2>3. 各队前锋数据</h2><p>下面我选择了各队前锋球员中的射术、速度和力量来作为分析数据，看看每支球队的前锋们，都是怎样的水平</p><p><img src="/2019/10/09/Python-带你分析，英超是否已经大结局/6.png"></p><p>曼城还是第一，他的锋线由阿奎罗、斯特拉，热苏斯等人组成，有冲击力，有速度，有技术，妥妥的英超第一锋线。</p><p>而由萨拉赫领衔的利物浦则排在第4位，感觉本赛季萨拉赫的状态有所下降，不过马内倒是依旧强势，不管怎么说，利物浦的锋线三叉戟依旧稳定恐怖。</p><p><img src="/2019/10/09/Python-带你分析，英超是否已经大结局/7.png"></p><p>还可以从上面的散点图中看出，阿森纳的前锋们，在速度方面是英超里最突出的，毕竟有奥巴梅扬的加持；而在射术方面，则是曼城最好，阿奎罗作为球王的女婿，也不是盖的；而在力量方面，应该是维拉队更加强悍一些，毕竟对于中下游球队来说，冲击力可是立身之本呢。</p><h2>4. 各队中场数据</h2><p>对于中场球员，我选择了传球、速度和盘带三项指标作为分析数据</p><p><img src="/2019/10/09/Python-带你分析，英超是否已经大结局/8.png"></p><p>曼城仍然占据首位，毕竟是由德布劳内和席尔瓦组成的中场啊，无论是控制力还是向前的传递能力，都是世界顶级的。而他们两人还同时处在助攻榜的前两位，想想曼城的前锋们真是幸福啊</p><p><img src="/2019/10/09/Python-带你分析，英超是否已经大结局/9.png"></p><h2>5. 各队后卫数据</h2><p>对于后防线上的球员，我选取了传球、防守和力量作为评判指标</p><p><img src="/2019/10/09/Python-带你分析，英超是否已经大结局/10.png"></p><p>曼城利物浦再次占据前两位，看来防守赢得胜利，不仅仅适用于 NBA，在足球场上也是同样适用啊。</p><p>而在这两份榜单中，都不见了阿森纳的身影，没有强大的中场，又没有稳固的后防，虽然现在位居积分榜的第三位，但是本赛季娜娜的联赛还是不好踢啊，祝好吧！</p><h2>6. 英超五强数据</h2><p>最后我们来看看英超五强的数据对比</p><p><img src="/2019/10/09/Python-带你分析，英超是否已经大结局/11.gif"></p><p>可以看到，曼城还是在各个方面都要强于其他四支球队，而利物浦也不遑多让，毕竟联赛八连胜就是最好的佐证。</p><p>对于阿森纳来说，可能保住前四的位置，再次杀入欧冠才是更为实际的目标了。而对于切尔西呢，当前的表现只能是中规中矩，期待它未来的爆发。至于曼联，只求尽快回到赢球的轨迹上来！</p><p>不过联赛才刚刚开始，毕竟在漫长的联赛当中，要想赢得冠军，就要比拼阵容、板凳、任性，稳定性等待诸多因素。一切都还未定，无论是整体实力超强的蓝月亮后来居上，还是众志成城的红军一骑绝尘，这都是一个值得期待的盛世英超！</p><p><img src="/2019/10/09/Python-带你分析，英超是否已经大结局/yingchao.jpg"></p><p>好了，今天的分享就到这里了，公众号后台回复“英超”，可以获取完整代码哦！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/10/09/Python-带你分析，英超是否已经大结局/fengmian.jpg&quot;&gt;&lt;/p&gt;
&lt;h1&gt;引子&lt;/h1&gt;
&lt;p&gt;随着本轮英超战罢，领头羊利物浦已经领先第二名曼城8分之多，新赛季的8连胜，不仅彰显着红军将士誓夺英超首冠的决心，也似乎在提醒着英超诸强，利物浦的复兴已然来临。&lt;/p&gt;
&lt;p&gt;而曼城意外的输给狼队，不仅被拉大了和榜首的差距，也被身后的娜娜迎头赶上，看来英超亚军之争也是分外激烈。&lt;/p&gt;
&lt;p&gt;不过足球本身就是一项偶然性很强的运动，在足球场上，分分秒秒都可能发生意想不到的事情，何况是漫长的一整个赛季。今天我们就从数据上出发，通过分析英超各个球队的数据，来看看哪些球队更具有冠军相，英超五强，谁人称雄。&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.luobodazahui.top/categories/Python/"/>
    
    
      <category term="Python" scheme="https://blog.luobodazahui.top/tags/Python/"/>
    
      <category term="数据分析" scheme="https://blog.luobodazahui.top/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>2019 年排名前6的数据分析工具</title>
    <link href="https://blog.luobodazahui.top/2019/09/27/2019-%E5%B9%B4%E6%8E%92%E5%90%8D%E5%89%8D6%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/"/>
    <id>https://blog.luobodazahui.top/2019/09/27/2019-年排名前6的数据分析工具/</id>
    <published>2019-09-27T06:29:23.000Z</published>
    <updated>2019-09-27T06:38:12.804Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/09/27/2019-年排名前6的数据分析工具/8.jpg"></p><p>作者：Lewis Chou</p><p>翻译：周萝卜</p><p>译文出品：萝卜大杂烩</p><p>对于数据分析工具，我们通过会有一个疑问，在众多的数据分析工具中，到底有什么区别，哪一个更好，我又应该学习哪一个呢？</p><p>虽然这是一个老生常谈的问题了，但它却是非常重要，我也一直在努力寻找最终的答案。如果你到网上去搜索相关的问题，很难得到一个完全公正的观点。因为评估某个数据分析工具的人，他们可能从不同角度出发，并且不可避免的带有一些个人感受。</p><p>今天就让我们抛开所有的个人感受，一起客观的聊一聊市场上的数据分析工具，仅仅代表我个人的观点，供你参考。</p><p>我列举了三种类型6个工具，下面就让我来一一介绍。</p><p><a id="more"></a></p><h1>1. Excel</h1><p>Excel 具有多种强大的功能，诸如创建表单、数据透视表和 VBA 编程等，其强大的功能令任何数据分析工具都无法超越它，从而确保人们可以根据自身的需要来分析数据。</p><p><img src="/2019/09/27/2019-年排名前6的数据分析工具/1.png"></p><p>然而一些精通计算机编程语言的人可能并不愿意使用  Excel 作为分析工具，因为 Excel  并不能很好的处理大数据。但是请思考一下，我们日常生活中的数据，是否真的达到了大数据的级别？在我看来，Excel  是多功能的工具，它非常适合处理小型数据，而且还用于各类插件，用于处理数以百万的数据。</p><p>综上所述，基于 Excel 的强大功能和庞大的用户基础，我认为它是必不可少的工具。如果你想学习数据分析，Excel 绝对是首选工具。</p><h1>2. BI tools</h1><p>商业智能诞生于数据分析，而且它诞生于一个很高的起点上。它诞生的目的就是为了缩短业务数据到业务决策的时间，并通过数据来影响决策。</p><p>虽然 Excel 可以做很多事情，但是 Excel 的产品目标并不是这样的。你可以使用 Excel绘制课程表，制作问卷或者当作计算器使用，甚至可以画图，如果你掌握了 VBA 编程，你甚至还可以制作小型的游戏。但是这些都不是真正的数据分析功能。</p><p><img src="/2019/09/27/2019-年排名前6的数据分析工具/2.png"></p><p>但是 BI 工具是专门用来做数据分析的。</p><p>以常见的 BI 工具为例，例如 Power BI，FineReport 和 Tableau。你会发现它们都是根据数据分析流程来进行设计的。首先是数据处理，数据清洗，然后是数据建模，最后则是数据可视化。通过可视化的图表来直观的展示分析结果并影响最终的决策。</p><p>这个流程就是数据分析的唯一方法，而且在此过程中会有各种各样困扰人们的痛点。</p><p>例如，可以使用 BI 工具简化重复和低廉的数据清洗工作。</p><p>如果数据量非常巨大，那么传统的 Excel 则很难完成透视表的处理。</p><p>如果我们使用 Excel 进行图表展示，也需要花费大量的时间来编辑图表的颜色，字体等信息。</p><p>这些都是 BI 工具可以为我们解决的痛点。</p><p>现在让我们来比较下市场上比较流行的三种 BI 工具：Power BI，FineReport 和 Tableau</p><h2>1）Tableau</h2><p>Tableau 的核心本质是 Excel 的 PivotTable 和 PivotChart，可以说 Tableau 敏锐的意识到 Excel 的这一功能的强大之处，很早就进入了市场，并且延续了这一核心价值。</p><p><img src="/2019/09/27/2019-年排名前6的数据分析工具/3.png"></p><p>从发展历史和当前市场的反馈来看， Tableau 的可视化效果更好。我并不认为这是因为它的图表做的多么的炫酷，而是因为它的设计和用户体验给了我们简单而新鲜的感觉。</p><p>的确，就像是 Tableau 自己宣传的那样，它们投入了大量的学术力量来研究人们喜欢什么样的图表，怎样给用户提供操作和体验上的终极体验。</p><p>此外，Tableau 还增加了数据清洗功能和智能分析功能，这也是 Tableau 未来的产品优势。</p><h2>2）Power BI</h2><p>Power BI 的优势在于其业务模型和数据分析能力。</p><p>Power BI 最开始是 Excel 的插件，但是发展的并不好。所以后来它脱离了 Excel 并发展成为 BI 工具。作为一个后来者，Power BI 每个月都有迭代更新并且正在迎头赶上。</p><p><img src="/2019/09/27/2019-年排名前6的数据分析工具/4.jpeg"></p><p>Power BI 当前有三种许可方式：Power BI free，Power BI Pro 和 Power BI Premium。同Tableau 一样，其免费版本并不包含所有的功能，但是对于个人用户而言，已经足够用了。而且 Power BI 的数据分析功能十分强大，它的PowerPivot 和 DAX 语言可以使我们能够类似于在 Excel 中编写公式的方式完成更加复杂高级的分析。</p><h2>3）FineReport</h2><p>FineReport 之所以与众不同，就是因为其自助数据分析功能非常适合企业用户。通过一些简单的拖拽操作，你就可以使用 FineReport 设计各式各样的报表，并能够轻松构建数据决策分析系统。</p><p><img src="/2019/09/27/2019-年排名前6的数据分析工具/5.gif"></p><p>FineReport 可以直接连接到各种数据库上，并且可以方便快捷的自定义各种样式来制作每周，每月和年度报告。它的操作页面类似 Excel 的界面，功能包括报告创建，报告权限分配，报告管理和数据导入等等。</p><p>此外，FineReport 的可视化功能也是非常突出的，它提供了多种仪表盘模板和众多可进行二次开发的插件库。</p><p>而 FineReport 的个人版是完全免费的，而且可以使用所有的功能。</p><h1>3. R &amp; Python</h1><p>R 和 Python 是我要讨论的第三种工具，虽然像 Excel 和 BI 工具这些软件已经尽最大的努力来满足数据分析的需求，但是这些软件还是无法完全自定义的。如果我们存在一些需要超级自定义的需求，那么这些软件就无能为力了。</p><p>但是编程语言则不同，它们灵活且强大，你可以编写代码来执行个人所需要的任何操作。例如，R 和 Python 是数据科学家们必不可少的工具，从某些专业角度看，它们绝对比 Excel 和 BI 工具更加强大。</p><p>那么 R 和 Python 可以实现哪些 Excel 和 BI 无法实现的场景呢？</p><h2>1） 专业统计分析</h2><p>就 R 语言而言，它最擅长统计分析，比如正态分布，使用算法对数据进行分类和回归分析等。这种分析就像是将数据用作实验一样，可以帮助我们回答下面的问题：</p><p><img src="/2019/09/27/2019-年排名前6的数据分析工具/6.png"></p><ul><li>数据是正态分布，三角分布还是其他类型的分布？</li><li>什么是离散情况？</li><li>当前数据十分在我们想要达到的控制范围内？</li><li>不同的参数对最终的结果影响是怎样的？</li><li>如果某个参数发生变化，将会带来什么影响？</li></ul><h2>2）个体预测分析</h2><p>比如我们想要预测消费者的行为：</p><ul><li>用户会在我们的店里停留多久？</li><li>用户会消费多少钱？</li><li>我们还可以找出用户的个人信用状况，再根据他在线消费记录来进行贷款操作。</li><li>我们还可以根据用户的网上浏览情况推送不同的信息</li></ul><p>当然以上这些多少会涉及到当下流行的机器学习和人工智能的概念。</p><p><img src="/2019/09/27/2019-年排名前6的数据分析工具/7.jpeg"></p><h1>结论</h1><p>通过上面的比较，能够得到各种工具之间的区别。最后我想说的是，存在即是合理的。Excel，BI 工具和编程语言可能在某些功能上是有重叠的，但是它们也是互补的。</p><p>在选择数据分析工具之前，你必须首先明确自己的工作内容：是否会使用到我上面提到的应用场景。或者考虑下你个人的职业方向：是面向数据科学还是业务分析领域。</p><blockquote><p>文章来源：</p><p>https://towardsdatascience.com/python-tricks-101-what-every-new-programmer-should-know-c512a9787022</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/09/27/2019-年排名前6的数据分析工具/8.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;作者：Lewis Chou&lt;/p&gt;
&lt;p&gt;翻译：周萝卜&lt;/p&gt;
&lt;p&gt;译文出品：萝卜大杂烩&lt;/p&gt;
&lt;p&gt;对于数据分析工具，我们通过会有一个疑问，在众多的数据分析工具中，到底有什么区别，哪一个更好，我又应该学习哪一个呢？&lt;/p&gt;
&lt;p&gt;虽然这是一个老生常谈的问题了，但它却是非常重要，我也一直在努力寻找最终的答案。如果你到网上去搜索相关的问题，很难得到一个完全公正的观点。因为评估某个数据分析工具的人，他们可能从不同角度出发，并且不可避免的带有一些个人感受。&lt;/p&gt;
&lt;p&gt;今天就让我们抛开所有的个人感受，一起客观的聊一聊市场上的数据分析工具，仅仅代表我个人的观点，供你参考。&lt;/p&gt;
&lt;p&gt;我列举了三种类型6个工具，下面就让我来一一介绍。&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.luobodazahui.top/categories/Python/"/>
    
    
      <category term="Python" scheme="https://blog.luobodazahui.top/tags/Python/"/>
    
      <category term="翻译" scheme="https://blog.luobodazahui.top/tags/%E7%BF%BB%E8%AF%91/"/>
    
  </entry>
  
  <entry>
    <title>每个新手程序员都应该知道的 Python 技巧</title>
    <link href="https://blog.luobodazahui.top/2019/09/25/%E6%AF%8F%E4%B8%AA%E6%96%B0%E6%89%8B%E7%A8%8B%E5%BA%8F%E5%91%98%E9%83%BD%E5%BA%94%E8%AF%A5%E7%9F%A5%E9%81%93%E7%9A%84-Python-%E6%8A%80%E5%B7%A7/"/>
    <id>https://blog.luobodazahui.top/2019/09/25/每个新手程序员都应该知道的-Python-技巧/</id>
    <published>2019-09-25T06:44:08.000Z</published>
    <updated>2019-09-25T06:53:40.013Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/09/25/每个新手程序员都应该知道的-Python-技巧/page.jpeg"></p><p>作者：Peter Nistrup</p><p>翻译：周萝卜</p><p>译文出品：萝卜大杂烩</p><p>当下，Python 比以往的任何时候都更加流行，人们每天都在实践着 Python 是多么的强大且易用。</p><p>我从事 Python 编程已经有几年时间了，但是最近6个月才是全职的。下面列举的这些事情，是我最开始使用 Python 的时候，就希望清楚的：</p><ul><li>字符串操作</li><li>列表推导</li><li>Lambda 和 Map 函数</li><li>在一行里使用 if elif 和 else 条件判断</li><li>zip() 函数</li></ul><p><a id="more"></a></p><h1>字符串操作</h1><p><img src="/2019/09/25/每个新手程序员都应该知道的-Python-技巧/1.jpg"></p><p>Python 非常擅长使用类似数学运算符 + 和 * 来操作字符串</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>my_string = <span class="string">"Hi Medium..!"</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(my_string * <span class="number">2</span>)</span><br><span class="line">Hi Medium..!Hi Medium..!</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(my_string + <span class="string">" I love Python"</span> * <span class="number">2</span>)</span><br><span class="line">Hi Medium..! I love Python I love Python</span><br></pre></td></tr></table></figure></p><p>我们也可以非常方便的对字符串做取反操作，只需要使用 [::-1] 就可以，同时该操作还不仅仅局限于字符串操作。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(my_string[::<span class="number">-1</span>])</span><br><span class="line">!..muideM iH</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>my_list = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(my_list[::<span class="number">-1</span>])</span><br><span class="line">[<span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure></p><p>那么对于包含多个字符串的列表呢，我们甚至可以做一个 Yoda-translator ！<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>word_list = [<span class="string">"awesome"</span>, <span class="string">"is"</span>, <span class="string">"this"</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">' '</span>.join(word_list[::<span class="number">-1</span>]) + <span class="string">'!'</span>)</span><br><span class="line">this <span class="keyword">is</span> awesome!</span><br></pre></td></tr></table></figure></p><p>在上面的代码中，我们使用了 .join() 方法，用空格把反转列表里的元素拼接了起来，并且增加了感叹号。</p><h1>列表推导</h1><p><img src="/2019/09/25/每个新手程序员都应该知道的-Python-技巧/2.jpg"></p><p>哦，天啊！一旦我知道了这些，我的整个世界都改变了（可能还没有真实发生，但是已经接近了）。这是以中国强大的、直观的且可读的方法来快速的操作列表。</p><p>假如我们有这样一个函数，取一个数的平方再增加5<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">stupid_func</span><span class="params">(x)</span>:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">return</span> x**<span class="number">2</span> + <span class="number">5</span></span><br></pre></td></tr></table></figure></p><p>现在如果我们要把该函数应用到一个列表的所有奇数当中，如果不了解列表推导式，你可能会这么写<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>my_list = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>new_list = []</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> x <span class="keyword">in</span> my_list:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">if</span> x % <span class="number">2</span> != <span class="number">0</span>:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        new_list.append(stupid_func(x))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(new_list)</span><br><span class="line">[<span class="number">6</span>, <span class="number">14</span>, <span class="number">30</span>]</span><br></pre></td></tr></table></figure></p><p>但是我们还有更简单的方法!<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>my_list = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print([stupid_func(x) <span class="keyword">for</span> x <span class="keyword">in</span> my_list <span class="keyword">if</span> x % <span class="number">2</span> != <span class="number">0</span>])</span><br><span class="line">[<span class="number">6</span>, <span class="number">14</span>, <span class="number">30</span>]</span><br></pre></td></tr></table></figure></p><p>列表推导适用于 [ expression for item in list ] 条件，同时如果那你想要应用一些布尔条件，例如上面获取奇数的条件： [ expression for item in list if conditional ]，那么它和下面的写法是一致的<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; for item in list:</span><br><span class="line">&gt;&gt;&gt;     if conditional:</span><br><span class="line">&gt;&gt;&gt;         expression</span><br></pre></td></tr></table></figure></p><p>很酷，不过我们还可以做的更好，因为我们根本不需要函数“stupid_func”<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print([x ** <span class="number">2</span> + <span class="number">5</span> <span class="keyword">for</span> x <span class="keyword">in</span> my_list <span class="keyword">if</span> x % <span class="number">2</span> != <span class="number">0</span>])</span><br><span class="line">[<span class="number">6</span>, <span class="number">14</span>, <span class="number">30</span>]</span><br></pre></td></tr></table></figure></p><h1>Lambda 和 Map</h1><p><img src="/2019/09/25/每个新手程序员都应该知道的-Python-技巧/3.png"></p><h2>Lambda</h2><p>Lambda 有一点奇怪，但是就像我介绍的其他内容一样，只要你去只用它，就会发现它是多么的强大和直观。</p><p>Lambda 其实就是一个小的匿名函数。为什么要匿名呢？这是因为 Lambda 常常用来执行小型简单的操作，而这些操作往往不需要使用 def my_function() 来定义正式的函数</p><p>我们还是以上面的例子为例，对一个数进行平方并加5。在上面的代码中我们定义了一个函数 def stupid_func(x)，现在让我们使用 Lambda 来重新创建它<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>stupid_func = (<span class="keyword">lambda</span> x : x ** <span class="number">2</span> + <span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print([stupid_func(<span class="number">1</span>), stupid_func(<span class="number">3</span>), stupid_func(<span class="number">5</span>)])</span><br><span class="line">[<span class="number">6</span>, <span class="number">14</span>, <span class="number">30</span>]</span><br></pre></td></tr></table></figure></p><p>那么，为什么要使用这种奇怪的语法呢？其实这种写法的用处就体现在，我们不要定义实际的功能，就可以实现一些简单的操作。我们继续以数字列表为例，如果我们想对下面的列表进行排序，一种方法是使用 sorted()<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>my_list = [<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">-1</span>, <span class="number">-2</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(sorted(my_list))</span><br><span class="line">[<span class="number">-2</span>, <span class="number">-1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br></pre></td></tr></table></figure></p><p>这样确实可以了，但是，如果我们想按照元素平方数的大小来排序，使用 Lambda 就非常方便了。可以使用 Lambda 来定义 sorted() 函数用于排序的 key<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(sorted(my_list, key = <span class="keyword">lambda</span> x : x ** <span class="number">2</span>))</span><br><span class="line">[<span class="number">0</span>, <span class="number">-1</span>, <span class="number">1</span>, <span class="number">-2</span>, <span class="number">2</span>]</span><br></pre></td></tr></table></figure></p><h2>Map</h2><p>Map 是一个用来将函数应用到序列的每个元素上，比如列表。假设我们必须要列出两个列表对应位置元素的乘积，那么该怎么做呢，可以使用 Lambda 和 Map<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(list(map(<span class="keyword">lambda</span> x, y : x * y, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])))</span><br><span class="line">[<span class="number">4</span>, <span class="number">10</span>, <span class="number">18</span>]</span><br></pre></td></tr></table></figure></p><p>和下面的代码相比，Lambda 与 Map 的组合实在是太优雅了<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x, y = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z = []</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i <span class="keyword">in</span> range(len(x)):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    z.append(x[i] * y[i])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(z)</span><br><span class="line">[<span class="number">4</span>, <span class="number">10</span>, <span class="number">18</span>]</span><br></pre></td></tr></table></figure></p><h1>在一行里使用 if elif 和 else 条件判断</h1><p><img src="/2019/09/25/每个新手程序员都应该知道的-Python-技巧/4.jpg"></p><p>有时，你可能会写出如下的代码<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = int(input())</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">if</span> x &gt;= <span class="number">10</span>:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    print(<span class="string">"Horse"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">elif</span> <span class="number">1</span> &lt; x &lt; <span class="number">10</span>:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    print(<span class="string">"Duck"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">else</span>:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    print(<span class="string">"Baguette"</span>)</span><br></pre></td></tr></table></figure></p><p>运行此命令时，系统会提示你从 input() 函数输入内容，假设我们输入5，我们将得到 Duck。 但是我们也可以像下面这样写<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Horse"</span> <span class="keyword">if</span> x &gt;= <span class="number">10</span> <span class="keyword">else</span> <span class="string">"Duck"</span> <span class="keyword">if</span> <span class="number">1</span> &lt; x &lt; <span class="number">10</span> <span class="keyword">else</span> <span class="string">"Baguette"</span>)</span><br></pre></td></tr></table></figure></p><p>这实在是太简单了！快去阅读你的旧代码，你会发现有太多的地方可以将这种简单的 if else 判断替换成这种单行判断。</p><h1>zip()</h1><p><img src="/2019/09/25/每个新手程序员都应该知道的-Python-技巧/5.jpg"></p><p>还记得在 Map 函数部分，我们并行处理两个列表的例子嘛，使用 zip() 会更加简单</p><p>假如我们有两个列表，一个包含名字，一个包含姓氏，怎样才能很好的合并它们呢，使用 zip()！<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>first_names = [<span class="string">"Peter"</span>, <span class="string">"Christian"</span>, <span class="string">"Klaus"</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>last_names = [<span class="string">"Jensen"</span>, <span class="string">"Smith"</span>, <span class="string">"Nistrup"</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print([<span class="string">' '</span>.join(x) <span class="keyword">for</span> x <span class="keyword">in</span> zip(first_names, last_names)])</span><br><span class="line">[<span class="string">'Peter Jensen'</span>, <span class="string">'Christian Smith'</span>, <span class="string">'Klaus Nistrup'</span>]</span><br></pre></td></tr></table></figure></p><p>哇哦，有个地方错了，我的名字不叫 Peter Jensen，那么就可以调整如下<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print([<span class="string">' '</span>.join(x) <span class="keyword">for</span> x <span class="keyword">in</span> zip(first_names, last_names[::<span class="number">-1</span>])])</span><br><span class="line">[<span class="string">'Peter Nistrup'</span>, <span class="string">'Christian Smith'</span>, <span class="string">'Klaus Jensen'</span>]</span><br></pre></td></tr></table></figure></p><h1>结束语</h1><p>我这里只是汇总了一个简单的清单，目的就是为了让你能够了解到 Python 可以优雅的做很多事情。如果你有任何不同的想法，可以留言哦！</p><blockquote><p>来源：https://towardsdatascience.com/python-tricks-101-what-every-new-programmer-should-know-c512a9787022</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/09/25/每个新手程序员都应该知道的-Python-技巧/page.jpeg&quot;&gt;&lt;/p&gt;
&lt;p&gt;作者：Peter Nistrup&lt;/p&gt;
&lt;p&gt;翻译：周萝卜&lt;/p&gt;
&lt;p&gt;译文出品：萝卜大杂烩&lt;/p&gt;
&lt;p&gt;当下，Python 比以往的任何时候都更加流行，人们每天都在实践着 Python 是多么的强大且易用。&lt;/p&gt;
&lt;p&gt;我从事 Python 编程已经有几年时间了，但是最近6个月才是全职的。下面列举的这些事情，是我最开始使用 Python 的时候，就希望清楚的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;字符串操作&lt;/li&gt;
&lt;li&gt;列表推导&lt;/li&gt;
&lt;li&gt;Lambda 和 Map 函数&lt;/li&gt;
&lt;li&gt;在一行里使用 if elif 和 else 条件判断&lt;/li&gt;
&lt;li&gt;zip() 函数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.luobodazahui.top/categories/Python/"/>
    
    
      <category term="Python" scheme="https://blog.luobodazahui.top/tags/Python/"/>
    
      <category term="翻译" scheme="https://blog.luobodazahui.top/tags/%E7%BF%BB%E8%AF%91/"/>
    
  </entry>
  
  <entry>
    <title>老兵不死|数据纪念男篮世界杯</title>
    <link href="https://blog.luobodazahui.top/2019/09/16/%E8%80%81%E5%85%B5%E4%B8%8D%E6%AD%BB-%E6%95%B0%E6%8D%AE%E7%BA%AA%E5%BF%B5%E7%94%B7%E7%AF%AE%E4%B8%96%E7%95%8C%E6%9D%AF/"/>
    <id>https://blog.luobodazahui.top/2019/09/16/老兵不死-数据纪念男篮世界杯/</id>
    <published>2019-09-16T08:47:05.000Z</published>
    <updated>2019-09-16T09:40:42.691Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/09/16/老兵不死-数据纪念男篮世界杯/9.jpg"></p><p>男篮世界杯已经落下帷幕，相信看球的朋友们都已经过足了篮球瘾。有些许遗憾，也有世界霸主的失落，还有老兵不死的坚持，当然还有斗牛军团的登顶。自杀式输给波兰，溃败式负于尼日利亚，从前一直代表亚洲征战奥运会的中国，可能就要缺席下一届了。当阿联老去，中国即将不再有任何一名球员具备世界篮球运动员的水平，没有一个！期待中国男篮的再次崛起吧！星光黯淡，小将领衔，教练席上的神奇老者也没能创造神奇，历史最差战绩，我们都不知道该不该赋予这只美国男篮以“梦之队”的称号。也许在不久后的东京，他们会球星云集，卷土重来吧。什么是老兵，是接近40岁“高龄”的斗士，是场均准两双的无解，是令人啧啧称奇的坚持。钻石的最后，虽然没能如愿，但是谁又会在乎呢，你已经征服了整个世界！潘帕斯草原上的雄鹰，终将振翅高飞。一如足球领域一样，斗牛军团的篮球同样强大。不能不佩服和感慨，当加索尔和卢比奥内外联合，双剑合璧时，他们就是篮球界的霸主。</p><p>下面我们就一起通过真实的数据，来细数本届男篮世界杯上的各项数据吧。</p><p><a id="more"></a></p><h1>数据从哪里来</h1><h2>我不生产数据，只是数据的搬运工</h2><p>下面分析的数据，都是抓取自新浪体育</p><p><strong>数据抓取</strong></p><p>在新浪体育网站上，有个世界杯专栏，在数据榜这个模块里，可以找个类似下面的链接</p><blockquote><p>https://events.sports.sina.com.cn/bps/peony/mersh/beitai/fiba/stats/playerdata_order?leagueid=433&amp;ordertype=FieldGoalsAverage&amp;order=desc&amp;dpc=1</p></blockquote><p>该链接，只要修改 ordertype 字段，就可以获取到诸如球员得分，篮板球，助攻数等一些列数据，具体的过程就不说了，就是发请求，解析 json 的简单操作</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">url_list = [</span><br><span class="line">    <span class="string">'https://events.sports.sina.com.cn/bps/peony/mersh/beitai/fiba/stats/playerdata_order?leagueid=433&amp;ordertype=PointsAverage'</span>,</span><br><span class="line">    <span class="string">'https://events.sports.sina.com.cn/bps/peony/mersh/beitai/fiba/stats/playerdata_order?leagueid=433&amp;ordertype=ReboundsAverage'</span>,</span><br><span class="line">    <span class="string">'https://events.sports.sina.com.cn/bps/peony/mersh/beitai/fiba/stats/playerdata_order?leagueid=433&amp;ordertype=PlusMinusAverage'</span>,</span><br><span class="line">    <span class="string">'https://events.sports.sina.com.cn/bps/peony/mersh/beitai/fiba/stats/playerdata_order?leagueid=433&amp;ordertype=StealsAverage'</span>,</span><br><span class="line">    <span class="string">'https://events.sports.sina.com.cn/bps/peony/mersh/beitai/fiba/stats/playerdata_order?leagueid=433&amp;ordertype=AssistsAverage'</span>,</span><br><span class="line">    <span class="string">'https://events.sports.sina.com.cn/bps/peony/mersh/beitai/fiba/stats/playerdata_order?leagueid=433&amp;ordertype=BlockedAverage'</span>,</span><br><span class="line">    <span class="string">'https://events.sports.sina.com.cn/bps/peony/mersh/beitai/fiba/stats/playerdata_order?leagueid=433&amp;ordertype=TurnoversAverage'</span>,</span><br><span class="line">    <span class="string">'https://events.sports.sina.com.cn/bps/peony/mersh/beitai/fiba/stats/playerdata_order?leagueid=433&amp;ordertype=PersonalFoulsAverage'</span>,</span><br><span class="line">    <span class="string">'https://events.sports.sina.com.cn/bps/peony/mersh/beitai/fiba/stats/playerdata_order?leagueid=433&amp;ordertype=FieldGoalsAverage'</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fire</span><span class="params">(url)</span>:</span></span><br><span class="line">    file_name = url.split(<span class="string">'='</span>)[<span class="number">2</span>]</span><br><span class="line">    res = requests.get(url).json()</span><br><span class="line">    data = res[<span class="string">'playerdata_order'</span>]</span><br><span class="line">    items = map(get_data, data)</span><br><span class="line">    print(<span class="string">'save data'</span>)</span><br><span class="line">    save_to_csv(items, file_name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">(data)</span>:</span></span><br><span class="line">    name = data[<span class="string">'CNAlias'</span>]</span><br><span class="line">    country = data[<span class="string">'TeamCNName'</span>]</span><br><span class="line">    points = data[<span class="string">'PointsAverage'</span>]</span><br><span class="line">    rebounds = data[<span class="string">'ReboundsAverage'</span>]</span><br><span class="line">    steals = data[<span class="string">'StealsAverage'</span>]</span><br><span class="line">    assists = data[<span class="string">'AssistsAverage'</span>]</span><br><span class="line">    fouls = data[<span class="string">'PersonalFoulsAverage'</span>]</span><br><span class="line">    plus_minus = data[<span class="string">'PlusMinusAverage'</span>]</span><br><span class="line">    blocked = data[<span class="string">'BlockedAverage'</span>]</span><br><span class="line">    goals_percentage = data[<span class="string">'FieldGoalsPercentage_m'</span>]</span><br><span class="line">    turnovers = data[<span class="string">'TurnoversAverage'</span>]</span><br><span class="line">    result = &#123;</span><br><span class="line">        <span class="string">'name'</span>: name,</span><br><span class="line">        <span class="string">'country'</span>: country,</span><br><span class="line">        <span class="string">'points'</span>: points,</span><br><span class="line">        <span class="string">'rebounds'</span>: rebounds,</span><br><span class="line">        <span class="string">'steals'</span>: steals,</span><br><span class="line">        <span class="string">'assists'</span>: assists,</span><br><span class="line">        <span class="string">'fouls'</span>: fouls,</span><br><span class="line">        <span class="string">'plus_minus'</span>: plus_minus,</span><br><span class="line">        <span class="string">'blocked'</span>: blocked,</span><br><span class="line">        <span class="string">'goals_percentage'</span>: goals_percentage,</span><br><span class="line">        <span class="string">'turnovers'</span>: turnovers</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_csv</span><span class="params">(data, file_name)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(file_name + <span class="string">'_data.csv'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(<span class="string">'name,country,points,rebounds,steals,assists,fouls,plus_minus,blocked,goals_percentage,turnovers\n'</span>)</span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> data:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                row = <span class="string">'&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;'</span>.format(d[<span class="string">'name'</span>],</span><br><span class="line">                                                                d[<span class="string">'country'</span>],</span><br><span class="line">                                                                d[<span class="string">'points'</span>],</span><br><span class="line">                                                                d[<span class="string">'rebounds'</span>],</span><br><span class="line">                                                                d[<span class="string">'steals'</span>],</span><br><span class="line">                                                                d[<span class="string">'assists'</span>],</span><br><span class="line">                                                                d[<span class="string">'fouls'</span>],</span><br><span class="line">                                                                d[<span class="string">'plus_minus'</span>],</span><br><span class="line">                                                                d[<span class="string">'blocked'</span>],</span><br><span class="line">                                                                d[<span class="string">'goals_percentage'</span>],</span><br><span class="line">                                                                d[<span class="string">'turnovers'</span>])</span><br><span class="line">                f.write(row)</span><br><span class="line">                f.write(<span class="string">'\n'</span>)</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> url_list:</span><br><span class="line">        fire(url)</span><br><span class="line">        time.sleep(<span class="number">2</span>)</span><br></pre></td></tr></table></figure></p><p><strong>数据保存</strong></p><p>我分别抓取了以得分、篮板，助攻等排名的数据，并分别保存在不同的 csv 文件当中，最后的文件内容大致如下</p><p><img src="/2019/09/16/老兵不死-数据纪念男篮世界杯/1.gif"></p><h1>全体球员可视化</h1><h2>球员得分排名</h2><p><img src="/2019/09/16/老兵不死-数据纪念男篮世界杯/2.gif"></p><p>几个亮点</p><ul><li>韩国的归化球员竟然场均得分最高</li><li>阿联成功入选</li><li>没有美国人</li></ul><p>可能是韩国队打的比赛不多，对手不是很强，这个罗建儿作为迷你型中锋，也可以在内线翻云覆雨。阿联确实宝刀不老，还记得最后的生死战，如果没有阿联，比赛可能早花了。再次印证本届美国男篮无大牌，没有绝对的进攻核心，可能是他们兵败中国的最大原因了。</p><h2>球员篮板排名</h2><p><img src="/2019/09/16/老兵不死-数据纪念男篮世界杯/3.gif"></p><p>有意思了，罗建儿竟然又是第一，要是按照国内排高校的标准，这妥妥的是双一流！</p><h2>球员得分篮板排名</h2><p><img src="/2019/09/16/老兵不死-数据纪念男篮世界杯/4.gif"></p><p>罗建儿是本届世界杯唯一的一个能拿到得分篮板两双的球员，且是20+10，能力还是毋庸置疑的！然后就要说说两位老将了，斯科拉和易建联。两位都是17+的场均得分加上7+的篮板，能够看得出，在攻防两端，两名球员都是各自球队不可或缺的一员。真的是家有一老，如有一宝啊。不过人家阿根廷男篮已经完成了新老交替，未来依旧可期。而中国男篮呢，未来靠谁，是亚洲第一后卫-郭艾伦，还是大魔王-周琦，都还缺乏领袖气质和绝对能力啊！</p><h1>最佳阵容可视化分析</h1><p>最佳阵容球员<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">the_best_lineup = [</span><br><span class="line">    <span class="string">'博格达诺维奇'</span>,</span><br><span class="line">    <span class="string">'富尼耶'</span>,</span><br><span class="line">    <span class="string">'卢比奥'</span>,</span><br><span class="line">    <span class="string">'斯科拉'</span>,</span><br><span class="line">    <span class="string">'加索尔'</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure></p><h2>球员能力分析</h2><p>接下来就来看看本届世界杯，最佳阵容成员的各自数据。能力强不强，数据不说谎。</p><p>我分别选取了得分、篮板、助攻、抢断、封盖、犯规和失误为考察点，分别画出了各自的能力雷达图</p><p><img src="/2019/09/16/老兵不死-数据纪念男篮世界杯/5.gif"></p><p>三个外线，两个内线，各自都以不同的能力，影响着比赛，帮助着团队。塞尔维亚的博格达诺维奇，得分能力比较强，场均助攻也不错，关键是助攻失误比非常低，妥妥的进攻发动机。法国队的富尼耶，得分助攻比较平均，从数据上来看，是五个人中较弱的一位。但是其强大的冲击力，是法国队得以击败美国的关键之一。西班牙的卢比奥，是五个人中助攻最高的一位，但是同时失误次数也最多。他在外线的威胁，是西班牙能够轻松击败阿根廷的重要因素。当年的金童已经蓄起了胡须，岁月的沧桑给了他更多的坚忍。阿根廷的斯科拉，作为攻守两端的绝对核心，如果不是两鬓的点点白发，不会有人知道他已经39岁了。此时的数据已经不再重要，篮球才是一切！西班牙的小加索尔，成功的从哥哥手中结果了国家队的大旗，不是十分华丽的数据的背后，是他在球场上的经验，老道和威慑力，有他在，西班牙就不会轻易被击败。</p><h2>球员投篮命中率对比</h2><p><img src="/2019/09/16/老兵不死-数据纪念男篮世界杯/6.png"></p><p>没想到，投篮命中率最高的竟然是一名外线球员，也许这样和当今篮球的发展相关，大个往外跑，小个向里冲！最佳五人组，每个人的命中率都在40%以上，怎一个稳字了得。</p><h2>球员正负值对比</h2><p><img src="/2019/09/16/老兵不死-数据纪念男篮世界杯/7.png"></p><p>富尼耶是五个人中正负值最低的，我说他在五个人里最弱，是不是也从侧面得到了印证呢。而加索尔的正负值是最高的，他就是球队的定海神针。犹记得当阿根廷反攻凶猛时，就是加索尔临危上场，稳定军心，遏制对手的进攻，成功帮助球队拿下比赛。</p><h3>老兵不死</h3><h2>只是逐渐凋零</h2><p>来看看阿联的数据，竟然是莫名的心酸</p><p><img src="/2019/09/16/老兵不死-数据纪念男篮世界杯/8.png"></p><p>我不想再去分析为啥他的正负值这么低，因为我们都看到了他在球场上的努力和汗水，还有他因为丢失到手的篮板而懊恼的双手砸地的场景。</p><p>还有斯科拉，12.9的正负值，43.4%的命中率，场均17.9分，8.1篮板，没有人能够要求他再多做些什么了，尽情释放，努力燃烧，不悔！</p><p>最后以天下足球的文案来结尾，再合适不过了。</p><blockquote><p>岁月你别催，该来的我不推；岁月你别催，走远的仍要追。当不得不说再见的时候，挥别的那一刻就如同流水的光阴，谁能抵得过，谁能叹息、奈何。</p></blockquote><p><img src="/2019/09/16/老兵不死-数据纪念男篮世界杯/10.jpg"></p><p><img src="/2019/09/16/老兵不死-数据纪念男篮世界杯/11.jpg"></p><p>公众号后台回复“老兵不死”，获取完整代码。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/09/16/老兵不死-数据纪念男篮世界杯/9.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;男篮世界杯已经落下帷幕，相信看球的朋友们都已经过足了篮球瘾。有些许遗憾，也有世界霸主的失落，还有老兵不死的坚持，当然还有斗牛军团的登顶。
自杀式输给波兰，溃败式负于尼日利亚，从前一直代表亚洲征战奥运会的中国，可能就要缺席下一届了。当阿联老去，中国即将不再有任何一名球员具备世界篮球运动员的水平，没有一个！期待中国男篮的再次崛起吧！
星光黯淡，小将领衔，教练席上的神奇老者也没能创造神奇，历史最差战绩，我们都不知道该不该赋予这只美国男篮以“梦之队”的称号。也许在不久后的东京，他们会球星云集，卷土重来吧。
什么是老兵，是接近40岁“高龄”的斗士，是场均准两双的无解，是令人啧啧称奇的坚持。钻石的最后，虽然没能如愿，但是谁又会在乎呢，你已经征服了整个世界！潘帕斯草原上的雄鹰，终将振翅高飞。
一如足球领域一样，斗牛军团的篮球同样强大。不能不佩服和感慨，当加索尔和卢比奥内外联合，双剑合璧时，他们就是篮球界的霸主。&lt;/p&gt;
&lt;p&gt;下面我们就一起通过真实的数据，来细数本届男篮世界杯上的各项数据吧。&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.luobodazahui.top/categories/Python/"/>
    
    
      <category term="Python" scheme="https://blog.luobodazahui.top/tags/Python/"/>
    
      <category term="数据分析" scheme="https://blog.luobodazahui.top/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>Python 分析天气，告诉你中秋应该去哪里</title>
    <link href="https://blog.luobodazahui.top/2019/09/11/Python-%E5%88%86%E6%9E%90%E5%A4%A9%E6%B0%94%EF%BC%8C%E5%91%8A%E8%AF%89%E4%BD%A0%E4%B8%AD%E7%A7%8B%E5%BA%94%E8%AF%A5%E5%8E%BB%E5%93%AA%E9%87%8C/"/>
    <id>https://blog.luobodazahui.top/2019/09/11/Python-分析天气，告诉你中秋应该去哪里/</id>
    <published>2019-09-11T11:26:46.000Z</published>
    <updated>2019-09-11T11:33:44.038Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/09/11/Python-分析天气，告诉你中秋应该去哪里/zhongqiu.jpg"></p><p>中秋佳节将近，不知道各位小伙伴儿有没有想好去哪里玩呢。不过说实在的，每到节假日，到处都是人山人海，那句“我动也不能动”，还不时的出现在我的耳畔呢。</p><p>但是又说回来，假期出游，除了人的因素外，天气的因素是不是也要考虑下呢，今天，我们就带大家来看看，中秋小长假，哪些地方适宜出游。</p><p><a id="more"></a></p><h1>获取数据</h1><p>数据的获取，就从中国天气网站上直接抓取，网络上的一些 API，有的信息不是很全，只能获取最近3天的数据，有的又需要付费，还不如自己抓来的痛快。</p><blockquote><p>http://www.weather.com.cn/weather15d/10124020102A.shtml</p></blockquote><p>网站也没有做什么限制，我们抓数据的时候，只需要控制好访问频率，不要影响人家的正常运行就可以。</p><p>同时还需要准备四个数据文件</p><ul><li>省会城市列表，provincial_capital</li><li>全国城市 id 信息表，china-city-list.csv</li><li>著名景点名称列表，attractions</li><li>全国景点 id 信息表，china-scenic-list.txt</li></ul><p>抓取的过程不再详细说明了，直接给出完整代码<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding = utf-8</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">@author: zhou</span></span><br><span class="line"><span class="string">@time:2019/9/5 14:36</span></span><br><span class="line"><span class="string">@File: main.py</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">(name, city, code)</span>:</span></span><br><span class="line">    print(<span class="string">"正在下载城市%s的数据"</span> % city)</span><br><span class="line">    url = <span class="string">'http://www.weather.com.cn/weather15d/%s.shtml'</span> % code[<span class="number">2</span>:]</span><br><span class="line">    res = requests.get(url).content.decode()</span><br><span class="line">    content = BeautifulSoup(res, <span class="string">"html.parser"</span>)</span><br><span class="line">    weather_list = content.find(<span class="string">'ul'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'t clearfix'</span>&#125;).find_all(<span class="string">'li'</span>)</span><br><span class="line">    items = map(parse_item, weather_list)</span><br><span class="line">    save_to_csv(name, city, items)</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(item)</span>:</span></span><br><span class="line">    time = item.find(<span class="string">'span'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'time'</span>&#125;).text</span><br><span class="line">    wea = item.find(<span class="string">'span'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'wea'</span>&#125;).text</span><br><span class="line">    tem = item.find(<span class="string">'span'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'tem'</span>&#125;).text</span><br><span class="line">    wind = item.find(<span class="string">'span'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'wind'</span>&#125;).text</span><br><span class="line">    wind_level = item.find(<span class="string">'span'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'wind1'</span>&#125;).text</span><br><span class="line">    result = &#123;</span><br><span class="line">        <span class="string">"time"</span>: time,</span><br><span class="line">        <span class="string">"wea"</span>: wea,</span><br><span class="line">        <span class="string">"tem"</span>: tem,</span><br><span class="line">        <span class="string">"wind"</span>: wind,</span><br><span class="line">        <span class="string">"wind_level"</span>: wind_level</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_csv</span><span class="params">(name, city, data)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'%s_data.csv'</span> % name):</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'%s_data.csv'</span> % name, <span class="string">'a+'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">'city,time,wea,tem,wind,wind_level\n'</span>)</span><br><span class="line">            <span class="keyword">for</span> d <span class="keyword">in</span> data:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    row = <span class="string">'&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;'</span>.format(city,</span><br><span class="line">                                                     d[<span class="string">'time'</span>],</span><br><span class="line">                                                     d[<span class="string">'wea'</span>],</span><br><span class="line">                                                     d[<span class="string">'tem'</span>],</span><br><span class="line">                                                     d[<span class="string">'wind'</span>],</span><br><span class="line">                                                     d[<span class="string">'wind_level'</span>])</span><br><span class="line">                    f.write(row)</span><br><span class="line">                    f.write(<span class="string">'\n'</span>)</span><br><span class="line">                <span class="keyword">except</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'%s_data.csv'</span> % name, <span class="string">'a+'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> d <span class="keyword">in</span> data:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    row = <span class="string">'&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;'</span>.format(city,</span><br><span class="line">                                                     d[<span class="string">'time'</span>],</span><br><span class="line">                                                     d[<span class="string">'wea'</span>],</span><br><span class="line">                                                     d[<span class="string">'tem'</span>],</span><br><span class="line">                                                     d[<span class="string">'wind'</span>],</span><br><span class="line">                                                     d[<span class="string">'wind_level'</span>])</span><br><span class="line">                    f.write(row)</span><br><span class="line">                    f.write(<span class="string">'\n'</span>)</span><br><span class="line">                <span class="keyword">except</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">    provincial = pd.read_csv(<span class="string">'provincial_capital'</span>)</span><br><span class="line">    china_city_code = pd.read_csv(<span class="string">'china-city-list.csv'</span>)</span><br><span class="line">    china_scenic_code = pd.read_csv(<span class="string">'china-scenic-list.txt'</span>, sep=<span class="string">'\t'</span>)</span><br><span class="line">    china_scenic_code.columns = [<span class="string">'ID'</span>, <span class="string">'name'</span>, <span class="string">'area'</span>, <span class="string">'provincial'</span>]</span><br><span class="line">    attraction = pd.read_csv(<span class="string">'attractions'</span>)</span><br><span class="line">    provincial_data = pd.DataFrame()</span><br><span class="line">    attraction_data = pd.DataFrame()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 省会抓取</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> provincial[<span class="string">'city'</span>].values.tolist():</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> china_city_code[<span class="string">'City_CN'</span>].values.tolist():</span><br><span class="line">            <span class="keyword">if</span> j == i:</span><br><span class="line">                provincial_data = pd.concat([china_city_code[china_city_code[<span class="string">'City_CN'</span>] == j], provincial_data])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> city <span class="keyword">in</span> provincial_data[<span class="string">'City_CN'</span>].values.tolist():</span><br><span class="line">        city_id = provincial_data[provincial_data[<span class="string">'City_CN'</span>] == city][<span class="string">'City_ID'</span>].values.tolist()[<span class="number">0</span>]</span><br><span class="line">        get_data(<span class="string">'weather'</span>, city, city_id)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 景点抓取</span></span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> attraction[<span class="string">'attractions'</span>].values.tolist():</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> china_scenic_code[<span class="string">'name'</span>].values.tolist():</span><br><span class="line">            <span class="keyword">if</span> c == a:</span><br><span class="line">                attraction_data = pd.concat([china_scenic_code[china_scenic_code[<span class="string">'name'</span>] == c], attraction_data])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> attrac <span class="keyword">in</span> attraction_data[<span class="string">'name'</span>].values.tolist():</span><br><span class="line">        city_id = attraction_data[attraction_data[<span class="string">'name'</span>] == attrac][<span class="string">'ID'</span>].values.tolist()[<span class="number">0</span>]</span><br><span class="line">        get_data(<span class="string">'attraction'</span>, attrac, city_id)</span><br></pre></td></tr></table></figure></p><h1>省会天气分析</h1><p>我们首先来看看省会天气，毕竟省会城市是每个省份的中心，也是旅游的重点城市。</p><h2>降水和温度</h2><p>对于降水的概率，我采取的是如果预报是有雨，则设置降水概率为80，如果是预报是晴，则降水概率为20.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">weather_dict = &#123;</span><br><span class="line">    <span class="string">"snow"</span>: <span class="number">100</span>,</span><br><span class="line">    <span class="string">"rain"</span>: <span class="number">80</span>,</span><br><span class="line">    <span class="string">"cloud"</span>: <span class="number">50</span>,</span><br><span class="line">    <span class="string">"overcast"</span>: <span class="number">60</span>,</span><br><span class="line">    <span class="string">"sun"</span>: <span class="number">20</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在中秋节这一天，各个省会城市的降水和温度</p><p><img src="/2019/09/11/Python-分析天气，告诉你中秋应该去哪里/1.gif"></p><p>能够看出，大部分城市在这一天都是天公不作美的，降水的概率都非常的大。而温度的话，大概率降水的城市，温度都不是很高，早晚出行，可能还会很凉哦。温度最高的应该就是南昌了，还能达到30°C，一个艳阳高照的日子，是不是去看看革命圣地？</p><p>接下来我们再通过一个双轴图来更加直观的查看下降水和温度的情况</p><p><img src="/2019/09/11/Python-分析天气，告诉你中秋应该去哪里/2.gif"></p><p>看来在进入9月之后，全国普遍的温度都在慢慢回落了，温度适宜出行，但是就是会伴随着绵绵的细雨呀。</p><p>再来看下几大城市在中秋前后一周的天气情况</p><h2>北京</h2><p><img src="/2019/09/11/Python-分析天气，告诉你中秋应该去哪里/3.png"></p><p>北京的气温还是比较平稳的，没有太大的波动，可能早晚一件薄外套就能hold的住，不过这几天，应该都会是阴蒙蒙的，不会有太好的阳光。</p><h2>上海</h2><p><img src="/2019/09/11/Python-分析天气，告诉你中秋应该去哪里/4.png"></p><p>上海的降水概率要比北京大一些，不过温度倒是相差不多。</p><h2>杭州</h2><p><img src="/2019/09/11/Python-分析天气，告诉你中秋应该去哪里/5.png"></p><p>杭州的平均温度还是要高一些，降水的概率也较高，毕竟典型的东南沿海城市嘛，雨天的西湖，你期待不？</p><h2>成都</h2><p><img src="/2019/09/11/Python-分析天气，告诉你中秋应该去哪里/6.png"></p><p>成都基本天天下雨了，那还出门看大熊猫嘛，这是个问题啊！</p><h1>著名景区天气</h1><p>下面我们再来看看一些著名景区的天气情况，我大好河山，景区太多了，只能简单列举一些最著名的地方来看看了。</p><h2>降水情况</h2><p><img src="/2019/09/11/Python-分析天气，告诉你中秋应该去哪里/7.gif"></p><p>在我选取的这些景区当中，大部分都是会有降水的，不过也会有阳光明媚的地方。比如说黄山和八达岭长城，预计会是晴天，去爬爬长城和黄山，是不错的选择。而美丽的九寨沟和西湖等，虽说会下雨，但是在雨天漫步，也不失为一种情趣吧。</p><h2>降水和温度</h2><p>我们再来看看各地的温度情况</p><p><img src="/2019/09/11/Python-分析天气，告诉你中秋应该去哪里/8.gif"></p><p>不知道为啥承德的温度会那么低，感觉去避暑已经不太合适了，而长白山已经只有7°C了，慌不慌？</p><h1>降水与温度分布</h1><p>最后，我们再来看看，中秋节当天，降水和气温的分布情况</p><h2>降水</h2><p><img src="/2019/09/11/Python-分析天气，告诉你中秋应该去哪里/9.gif"></p><p>进入9月，东南沿海降水明显增多，京津地区也是阴雨连绵，这是一场秋雨一场寒的节奏吗！</p><h2>气温</h2><p><img src="/2019/09/11/Python-分析天气，告诉你中秋应该去哪里/10.gif"></p><p>东南半壁，温度还是比较适宜的，现在的天气下，不冷不热，正是出游好温度。</p><p>好了，今天的分析就到这里了，那么，你中秋节最终的选择是哪里呢？</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/09/11/Python-分析天气，告诉你中秋应该去哪里/zhongqiu.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;中秋佳节将近，不知道各位小伙伴儿有没有想好去哪里玩呢。不过说实在的，每到节假日，到处都是人山人海，那句“我动也不能动”，还不时的出现在我的耳畔呢。&lt;/p&gt;
&lt;p&gt;但是又说回来，假期出游，除了人的因素外，天气的因素是不是也要考虑下呢，今天，我们就带大家来看看，中秋小长假，哪些地方适宜出游。&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.luobodazahui.top/categories/Python/"/>
    
    
      <category term="Python" scheme="https://blog.luobodazahui.top/tags/Python/"/>
    
      <category term="数据分析" scheme="https://blog.luobodazahui.top/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>数据里的大学|那些年，你的大学还好吗</title>
    <link href="https://blog.luobodazahui.top/2019/09/04/%E6%95%B0%E6%8D%AE%E9%87%8C%E7%9A%84%E5%A4%A7%E5%AD%A6-%E9%82%A3%E4%BA%9B%E5%B9%B4%EF%BC%8C%E4%BD%A0%E7%9A%84%E5%A4%A7%E5%AD%A6%E8%BF%98%E5%A5%BD%E5%90%97/"/>
    <id>https://blog.luobodazahui.top/2019/09/04/数据里的大学-那些年，你的大学还好吗/</id>
    <published>2019-09-04T10:01:57.000Z</published>
    <updated>2019-09-04T10:12:50.755Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/09/04/数据里的大学-那些年，你的大学还好吗/college.jpg"></p><p>当前正值开学季，各个心怀梦想的学子们都迈入了自己理想中的大学。只是当我们站在象牙塔前，再回首凝望高中生活，一路走来，是不是会感慨万千呢。都说高考是普通大众改变命运的最好的阶梯，那么大学就是培养能力，形成品格的试验田，而通向这块田地的之路却并不平坦。尤其是一些高考大省的小伙伴儿们，是经历了怎样的拼搏，才一路拼杀过来的呢。</p><p>这里就涉及到了各个省份的招生标准和各省的高校资源情况了，毕竟每个省的高校，在本省的招生数量既多，要求又低（差不多是这样...）。</p><p>都说高考其实是相对公平的选拔，那么今天我们就用数据来说话，看看全国的教育资源，高校分布到底是怎样，哪里的小伙伴相对来说，更容易踏入大学的校门呢。</p><p><a id="more"></a></p><h1>数据获取</h1><p>这里我选择的是“高考网”作为我数据的来源</p><blockquote><p>http://college.gaokao.com/schlist/p1</p></blockquote><p>网站很简单，也没有任何的反爬机制，直接分析页面，获取并保存数据就可以了这里直接给出代码，不关心数据获取过程的小伙伴儿可以跳过此部分<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">108</span>):</span><br><span class="line">        print(<span class="string">"正在下载第%s页数据"</span> % i)</span><br><span class="line">        url = <span class="string">'http://college.gaokao.com/schlist/p%s'</span> % i</span><br><span class="line">        res = requests.get(url).text</span><br><span class="line">        content = BeautifulSoup(res, <span class="string">"html.parser"</span>)</span><br><span class="line">        college_list = content.find(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'scores_List'</span>&#125;).find_all(<span class="string">'dl'</span>)</span><br><span class="line">        items = map(parse_item, college_list)</span><br><span class="line">        save_to_csv(items)</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(item)</span>:</span></span><br><span class="line">    college_name = item.find(<span class="string">'strong'</span>)[<span class="string">'title'</span>]</span><br><span class="line">    college_attr = item.find_all(<span class="string">'li'</span>)</span><br><span class="line">    college_site = college_attr[<span class="number">0</span>].text[<span class="number">6</span>:]</span><br><span class="line">    college_title = college_attr[<span class="number">1</span>].text[<span class="number">5</span>:]</span><br><span class="line">    college_type = college_attr[<span class="number">2</span>].text[<span class="number">5</span>:]</span><br><span class="line">    college_belong = college_attr[<span class="number">3</span>].text[<span class="number">5</span>:]</span><br><span class="line">    college_nature = college_attr[<span class="number">4</span>].text[<span class="number">5</span>:]</span><br><span class="line">    college_website = college_attr[<span class="number">5</span>].text[<span class="number">5</span>:]</span><br><span class="line">    result = &#123;</span><br><span class="line">        <span class="string">'college_name'</span>: college_name,</span><br><span class="line">        <span class="string">'college_site'</span>: college_site,</span><br><span class="line">        <span class="string">'college_title'</span>: college_title,</span><br><span class="line">        <span class="string">'college_type'</span>: college_type,</span><br><span class="line">        <span class="string">'college_belong'</span>: college_belong,</span><br><span class="line">        <span class="string">'college_nature'</span>: college_nature,</span><br><span class="line">        <span class="string">'college_website'</span>: college_website</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_csv</span><span class="params">(data)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">r'college_data.csv'</span>):</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'college_data.csv'</span>, <span class="string">'a+'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">'name,site,title,type,belong,nature,website\n'</span>)</span><br><span class="line">            <span class="keyword">for</span> d <span class="keyword">in</span> data:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    row = <span class="string">'&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;'</span>.format(d[<span class="string">'college_name'</span>],</span><br><span class="line">                                                        d[<span class="string">'college_site'</span>],</span><br><span class="line">                                                        d[<span class="string">'college_title'</span>],</span><br><span class="line">                                                        d[<span class="string">'college_type'</span>],</span><br><span class="line">                                                        d[<span class="string">'college_belong'</span>],</span><br><span class="line">                                                        d[<span class="string">'college_nature'</span>],</span><br><span class="line">                                                        d[<span class="string">'college_website'</span>])</span><br><span class="line">                    f.write(row)</span><br><span class="line">                    f.write(<span class="string">'\n'</span>)</span><br><span class="line">                <span class="keyword">except</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'college_data.csv'</span>, <span class="string">'a+'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> d <span class="keyword">in</span> data:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    row = <span class="string">'&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;'</span>.format(d[<span class="string">'college_name'</span>],</span><br><span class="line">                                                        d[<span class="string">'college_site'</span>],</span><br><span class="line">                                                        d[<span class="string">'college_title'</span>],</span><br><span class="line">                                                        d[<span class="string">'college_type'</span>],</span><br><span class="line">                                                        d[<span class="string">'college_belong'</span>],</span><br><span class="line">                                                        d[<span class="string">'college_nature'</span>],</span><br><span class="line">                                                        d[<span class="string">'college_website'</span>])</span><br><span class="line">                    f.write(row)</span><br><span class="line">                    f.write(<span class="string">'\n'</span>)</span><br><span class="line">                <span class="keyword">except</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    get_data()</span><br></pre></td></tr></table></figure></p><p>我们来看下最后拿到的数据</p><p><img src="/2019/09/04/数据里的大学-那些年，你的大学还好吗/1.gif"></p><p>数据还是比较整齐的，下面就进入到数据分析阶段</p><h1>高校总数量排行</h1><p>先不考虑高校质量、级别等因素，单单从高校数量方面来看下各个省份的排名情况</p><h2>排行榜</h2><p><strong>总体排名</strong></p><p><img src="/2019/09/04/数据里的大学-那些年，你的大学还好吗/2.gif"></p><p><strong>高校数量前十</strong></p><p><img src="/2019/09/04/数据里的大学-那些年，你的大学还好吗/3.png"></p><p><strong>高校数量后十</strong></p><p><img src="/2019/09/04/数据里的大学-那些年，你的大学还好吗/4.png"></p><p>能够看到，高校数量靠前的省份为江苏、山东、湖北、广东，这些可都是高考大省，同时高校数量也是非常多的。而更加著名的高考大省河南河北，同样也有着不错的高校数量，看来这些省份虽然考生多，但是要想考上本省的一个大学，还是比较有优势的。但是对于贵州、内蒙、青海，西藏等地区的考生来说，高考考出省，也许会是个不错的选择哦。</p><h2>全国高校热力图</h2><p>我们再通过一张热力图来看看全国大学的分布情况</p><p><img src="/2019/09/04/数据里的大学-那些年，你的大学还好吗/5.png"></p><p>不出意外，京畿重地、东南沿海加湖广地区、东北工业区、珠江三角洲和巴蜀地区，是大学比较几种的地区，同时也是我国经济比较发达且人口比较密集的区域，记者之间还是有着千丝万缕的联系的。</p><h2>地区高校数量段位</h2><p><img src="/2019/09/04/数据里的大学-那些年，你的大学还好吗/6.png"></p><p>在这个图表中，山东和江苏是独一档的存在。然后大西北还是需要继续发展啊，基本是在倒数第一和第二挡位。</p><h3>高校质量排行</h3><p>前面的高校数量分析，并没有考虑高校的质量，即该省份拥有985，211高校的数量。现在就来分析下从高质量高校层面分析，哪些省份又排名靠前呢</p><h2>高质量高校数量排行</h2><p><strong>985高校排行</strong></p><p><img src="/2019/09/04/数据里的大学-那些年，你的大学还好吗/7.png"></p><p>毫无疑问，北京位居第一，其拥有的985高校是其他地区所不能比拟的。紧随其后的是上海，国际化的金融中心，也需要众多高等院校来衬托。山东也不错，位居第三。而前面榜单上的头名江苏则表现不佳，只拥有两所985院校，看来江苏的高校数量多，但是超级名牌大学却不是很多啊。那么江苏的小伙伴儿，你们的高考困难吗？</p><p><strong>211高校排行</strong></p><p><img src="/2019/09/04/数据里的大学-那些年，你的大学还好吗/8.png">拥有211院校的省份相对来说就比较多了，不过还是北京拥有的最多，谁让人家是帝都呢。上海依然位居次席，地位稳稳的，配得上自己的身价。</p><p><strong>985211高校综合</strong></p><p>我们再把拥有985和211高校的省份综合起来看</p><p><img src="/2019/09/04/数据里的大学-那些年，你的大学还好吗/9.gif"></p><p>北京，上海，江苏，高质量高校三巨头出现了，就是它们。那么，这些省份的考生们，考名牌大学的困难程度是不是要比其他地区低一些呢，我没经历过，我没发言权，哈哈哈哈。</p><h2>高质量高校热力分布图</h2><p><img src="/2019/09/04/数据里的大学-那些年，你的大学还好吗/10.gif"></p><p>京津和长三角地区优势明显，妥妥的高质量院校聚集地。</p><h2>各地区高质量高校占比</h2><p><strong>北京高质量高校占比</strong></p><p><img src="/2019/09/04/数据里的大学-那些年，你的大学还好吗/11.gif"></p><p>北京一个省份，占有率高达19%，绝对的全国教育中心，人才聚集地。</p><p><strong>高质量高校三巨头占比</strong></p><p><img src="/2019/09/04/数据里的大学-那些年，你的大学还好吗/12.gif"></p><p>三巨头也不遑多让，高达37%的占比，真真是羡煞其他地区了。</p><p><strong>占比前十城市高质量高校占比</strong></p><p><img src="/2019/09/04/数据里的大学-那些年，你的大学还好吗/13.gif"></p><p>这个比例，拿走了绝大部分的教育资源，其他地区，没得玩了。</p><p>你所在的省份，有优势吗？</p><h1>高校类别及属性分布</h1><p>最后，我们再来看看，各种类型及不同属性的高校分布情况</p><p><img src="/2019/09/04/数据里的大学-那些年，你的大学还好吗/14.png"></p><p>工科和综合性大学是最多的，这应该是和报考人数以及社会需求息息相关的。</p><p><img src="/2019/09/04/数据里的大学-那些年，你的大学还好吗/15.png"></p><p>全国的高职专科所占比例接近50%，看来这种定向培养专业人才的高校还是有其生存之道的，当然，占有32%的本科院校，依然是广大学子的首选院校。</p><p>不知道看了上面的分析，你想要报考哪种院校呢？</p><p>所有的代码都上传到 GitHub 上了，想要的自提</p><blockquote><p>https://github.com/zhouwei713/data_analysis/tree/master/college</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/09/04/数据里的大学-那些年，你的大学还好吗/college.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;当前正值开学季，各个心怀梦想的学子们都迈入了自己理想中的大学。只是当我们站在象牙塔前，再回首凝望高中生活，一路走来，是不是会感慨万千呢。都说高考是普通大众改变命运的最好的阶梯，那么大学就是培养能力，形成品格的试验田，而通向这块田地的之路却并不平坦。尤其是一些高考大省的小伙伴儿们，是经历了怎样的拼搏，才一路拼杀过来的呢。&lt;/p&gt;
&lt;p&gt;这里就涉及到了各个省份的招生标准和各省的高校资源情况了，毕竟每个省的高校，在本省的招生数量既多，要求又低（差不多是这样...）。&lt;/p&gt;
&lt;p&gt;都说高考其实是相对公平的选拔，那么今天我们就用数据来说话，看看全国的教育资源，高校分布到底是怎样，哪里的小伙伴相对来说，更容易踏入大学的校门呢。&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.luobodazahui.top/categories/Python/"/>
    
    
      <category term="Python" scheme="https://blog.luobodazahui.top/tags/Python/"/>
    
      <category term="数据分析" scheme="https://blog.luobodazahui.top/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>数说成龙电影|数据告诉你，成龙大哥真的老了吗</title>
    <link href="https://blog.luobodazahui.top/2019/08/30/%E6%95%B0%E8%AF%B4%E6%88%90%E9%BE%99%E7%94%B5%E5%BD%B1-%E6%95%B0%E6%8D%AE%E5%91%8A%E8%AF%89%E4%BD%A0%EF%BC%8C%E6%88%90%E9%BE%99%E5%A4%A7%E5%93%A5%E7%9C%9F%E7%9A%84%E8%80%81%E4%BA%86%E5%90%97/"/>
    <id>https://blog.luobodazahui.top/2019/08/30/数说成龙电影-数据告诉你，成龙大哥真的老了吗/</id>
    <published>2019-08-30T02:15:37.000Z</published>
    <updated>2019-08-30T02:24:31.864Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/08/30/数说成龙电影-数据告诉你，成龙大哥真的老了吗/1.jpg"></p><p>最近的电影《哪吒》绝对是风靡全国，各种“我命由我不由天”，激励着平民大众。而《上海堡垒》则彻底扑街，鹿晗也跌落神坛，流量不再。而老大哥成龙的新片《龙牌之谜》也在日前悄悄上映了，之所用悄悄是因为电影并没有做过多的宣传，低调上映。但是上映之后的口碑却不敢恭维，好多影迷都说，大哥老了，也开始持续拍烂片了。今天，我们就来分析下历年成龙的电影得分数据和《龙牌之谜》的评论，用数据来告诉你，真的是大哥老了，打不动了吗？</p><p><a id="more"></a></p><h1>豆瓣数据分析</h1><h2>豆瓣数据获取</h2><p>爬取的过程还是蛮简单的，直接给出代码</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    data = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">150</span>, <span class="number">25</span>):</span><br><span class="line"></span><br><span class="line">        url = <span class="string">'https://movie.douban.com/celebrity/1054531/movies?start=%s&amp;format=text&amp;sortby=time&amp;role=A1'</span> % i</span><br><span class="line"></span><br><span class="line">        res = requests.get(url).text</span><br><span class="line"></span><br><span class="line">        content = BeautifulSoup(res, <span class="string">"html.parser"</span>)</span><br><span class="line"></span><br><span class="line">        tbody_tag = content.find_all(<span class="string">'tbody'</span>)</span><br><span class="line"></span><br><span class="line">        tr_tag = tbody_tag[<span class="number">1</span>].find_all(<span class="string">'tr'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> tr <span class="keyword">in</span> tr_tag:</span><br><span class="line"></span><br><span class="line">            tmp = []</span><br><span class="line"></span><br><span class="line">            name = tr.find(<span class="string">'a'</span>).text</span><br><span class="line"></span><br><span class="line">            year = tr.find(<span class="string">'td'</span>, attrs=&#123;<span class="string">'headers'</span>: <span class="string">'mc_date'</span>&#125;).text</span><br><span class="line"></span><br><span class="line">            rate = tr.find(<span class="string">'td'</span>, attrs=&#123;<span class="string">'headers'</span>: <span class="string">'mc_rating'</span>&#125;).text</span><br><span class="line"></span><br><span class="line">            tmp.append(name)</span><br><span class="line"></span><br><span class="line">            tmp.append(year)</span><br><span class="line"></span><br><span class="line">            tmp.append(rate.replace(<span class="string">'\n'</span>, <span class="string">''</span>).strip().replace(<span class="string">'-'</span>, <span class="string">''</span>))</span><br><span class="line"></span><br><span class="line">            data.append(tmp)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line">    data = get_data()</span><br><span class="line"></span><br><span class="line">    print(data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'jack_data.csv'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line"></span><br><span class="line">        f.write(<span class="string">'name,year,rate\n'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> data:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line"></span><br><span class="line">                rowcsv = <span class="string">'&#123;&#125;,&#123;&#125;,&#123;&#125;'</span>.format(d[<span class="number">0</span>], d[<span class="number">1</span>], d[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">                f.write(rowcsv)</span><br><span class="line"></span><br><span class="line">                f.write(<span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line"></span><br><span class="line">                <span class="keyword">continue</span></span><br></pre></td></tr></table></figure></p><p>数据拿到之后，我们再做些简单的数据处理，去除掉 rate 为空的数据，和一些异常数据</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">'jack_data.csv'</span>)</span><br><span class="line"></span><br><span class="line">df.isnull().sum()  <span class="comment"># 查看缺失值情况</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df_copy = df.copy()</span><br><span class="line"></span><br><span class="line">df_copy.dropna(how=<span class="string">'any'</span>, inplace=<span class="literal">True</span>)  <span class="comment"># 去掉缺失值</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 去掉异常值</span></span><br><span class="line"></span><br><span class="line">except_data = df_copy[df_copy[<span class="string">'name'</span>].apply(<span class="keyword">lambda</span> x: x == <span class="string">'喜剧之王'</span>)].index</span><br><span class="line"></span><br><span class="line">df_copy.drop(except_data, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p><h1>数据分析</h1><h2>一、成龙电影总体得分分布</h2><p>成龙大哥的高分电影，多集中在早年。大多数电影的评分，都几种在6-7分上下浮动。而近些年的几部电影，口碑都不是很好，有持续下滑的趋势。</p><p><img src="/2019/08/30/数说成龙电影-数据告诉你，成龙大哥真的老了吗/total.jpg"></p><h2>二、评分最高与最低影片</h2><p>成龙大哥的电影，最高得分为《龙争虎斗》，8.2 分，不过这个电影好像是李小龙的呀，尴了个尬，不知道成龙在电影里干了啥，豆瓣会把这部电影分给成龙。</p><p><img src="/2019/08/30/数说成龙电影-数据告诉你，成龙大哥真的老了吗/top5.jpg"></p><p>评分最低的是《神探蒲松龄》，只有 3.8 分。年岁增大，不能再像以前那样“功夫喜剧”了，成龙电影未来的方向在哪里呢。</p><p><img src="/2019/08/30/数说成龙电影-数据告诉你，成龙大哥真的老了吗/bottom5.jpg"></p><p>而《龙争虎斗》是 1973 年上映的，《神探蒲松龄》 则是 2019 年上映的，也从侧面反映出近些年龙大哥在电影市场的不给力情况。其实龙大哥早些年的《A 计划》，《警察故事》等都是我蛮喜欢的电影。</p><h2>三、出产电影年份</h2><p>我们再来看看哪些年份，成龙大哥出产的电影比较多呢</p><p><img src="/2019/08/30/数说成龙电影-数据告诉你，成龙大哥真的老了吗/year10.jpg"></p><p>1978 年，成龙出产的电影占比是最多的，总共是 6 部，接下来就是 1973、1985 和 1976 年，都是 5部电影。</p><p>我们来看下这几年电影的评分情况</p><p>1978 年</p><p><img src="/2019/08/30/数说成龙电影-数据告诉你，成龙大哥真的老了吗/1978.jpg"></p><p>1973 年</p><p><img src="/2019/08/30/数说成龙电影-数据告诉你，成龙大哥真的老了吗/1973.jpg"></p><p>1985 年</p><p><img src="/2019/08/30/数说成龙电影-数据告诉你，成龙大哥真的老了吗/1985.jpg"></p><p>1976 年</p><p><img src="/2019/08/30/数说成龙电影-数据告诉你，成龙大哥真的老了吗/1976.jpg"></p><p>可以看出来，早些年，大哥年轻的时候，无论是数量还是质量，都是比较有保证的。</p><p>不过太多电影过于遥远，真心没看过啊！</p><p><img src="/2019/08/30/数说成龙电影-数据告诉你，成龙大哥真的老了吗/wunai.jpg"></p><p>虽然说，成龙电影总体评分并不是太高，最高也才 8 点几分，但是作为华语影坛的大哥级人物，大家对他的期待还是非常高的。</p><p>不管怎么说，还是希望成龙大哥能够好好保养身体，在以后的时光中，给大家带来更多好的作品。</p><p>完整代码：</p><blockquote><p>https://github.com/zhouwei713/douban/tree/master/jackchen</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/08/30/数说成龙电影-数据告诉你，成龙大哥真的老了吗/1.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;最近的电影《哪吒》绝对是风靡全国，各种“我命由我不由天”，激励着平民大众。而《上海堡垒》则彻底扑街，鹿晗也跌落神坛，流量不再。而老大哥成龙的新片《龙牌之谜》也在日前悄悄上映了，之所用悄悄是因为电影并没有做过多的宣传，低调上映。但是上映之后的口碑却不敢恭维，好多影迷都说，大哥老了，也开始持续拍烂片了。今天，我们就来分析下历年成龙的电影得分数据和《龙牌之谜》的评论，用数据来告诉你，真的是大哥老了，打不动了吗？&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.luobodazahui.top/categories/Python/"/>
    
    
      <category term="Python" scheme="https://blog.luobodazahui.top/tags/Python/"/>
    
      <category term="爬虫" scheme="https://blog.luobodazahui.top/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>搭建邮件服务器和论坛</title>
    <link href="https://blog.luobodazahui.top/2019/08/20/%E6%90%AD%E5%BB%BA%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%AE%BA%E5%9D%9B/"/>
    <id>https://blog.luobodazahui.top/2019/08/20/搭建邮件服务器和论坛/</id>
    <published>2019-08-20T03:05:38.000Z</published>
    <updated>2019-08-20T03:11:30.520Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/08/20/搭建邮件服务器和论坛/6.jpg" width="520" height="520"></p><p>今天一起来看看如何搭建自己的邮件服务器和论坛服务，使用的工具分别为 Ewomail 和 Discourse。</p><h1>搭建邮件服务器</h1><p>安装 Ewomail 还是很简单的，它支持一键式安装。（重要，如果服务器上有其他软件，特别是 MySQL 时，请慎重安装！）</p><h2>使用官网方法安装</h2><p>直接使用官方文档安装即可（http://doc.ewomail.com/docs/ewomail/install），安装的时候，需要指定一个域名地址，地址就写自己申请的域名，或者安装之后再修改也是可以的。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">yum -y install git</span><br><span class="line">cd /root</span><br><span class="line">git clone https://github.com/gyxuehu/EwoMail.git</span><br><span class="line">cd /root/EwoMail/install</span><br><span class="line">#需要输入一个邮箱域名，不需要前缀，列如下面的ewomail.cn</span><br><span class="line">sh ./start.sh ewomail.cn</span><br></pre></td></tr></table></figure></p><p>安装之后，会有 iptables，如果其他服务的端口不可访问，记得来检查下 iptables。</p><p><a id="more"></a></p><h2>DNS 配置</h2><p>需要准备好一个域名，并配置解析<img src="/2019/08/20/搭建邮件服务器和论坛/1.png">如上图所示，需要增加一个 mail 的子域名，同时再增加一个 MX 类型的解析规则。</p><h2>邮箱后台配置</h2><p>上面两步完成之后，就可以打开邮箱管理后台了（http://IP:8010 （默认账号admin，密码ewomail123））</p><h3>设置邮箱域名</h3><p>可以添加邮箱的副域名<img src="/2019/08/20/搭建邮件服务器和论坛/2.png"></p><h3>添加使用邮箱</h3><p>添加邮箱，用于收发邮件<img src="/2019/08/20/搭建邮件服务器和论坛/3.png"></p><h3>登陆客户端</h3><p>Ewomail 提供了一个 WebMail 客户端，但是有时候登陆会存在问题。这里不再介绍。我使用的是 Foxmail 客户端</p><p><strong>新建账号</strong><img src="/2019/08/20/搭建邮件服务器和论坛/4.png">使用刚刚创建的邮箱登陆</p><p><strong>设置服务器信息</strong><img src="/2019/08/20/搭建邮件服务器和论坛/5.png">如果密码，服务状态等信息都无误，点击创建之后，就成功创建了客户端。</p><p>接下来就可以发送邮件了，只是对于 QQ 邮箱，还是有被退信的危险，不过 163 邮箱我测试是成功的。</p><h2>troubleshooting</h2><p>如果以上配置完成之后，还存在问题，可以查看日志<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/var/log/maillog</span><br></pre></td></tr></table></figure></p><p>也可以修改配置文件中的相关信息<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/postfix/main.cf</span><br></pre></td></tr></table></figure></p><h1>基于 Discourse 搭建论坛</h1><p>搭建 Discourse 论坛也很简单，直接使用 docker 形式安装即可。Linux 版 docker 安装指南https://github.com/discourse/discourse/blob/master/docs/INSTALL-cloud.md</p><p>两个比较重要的配置，email 和 域名，需要在安装前就准备好，当然也可以先行安装，然后修改 app.yml 配置文件，再进行 rebuild 操作。执行命令<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./discourse-setup</span><br></pre></td></tr></table></figure></p><p>命令行输入<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Hostname for your Discourse? [discourse.example.com]: </span><br><span class="line">Email address for admin account(s)? [me@example.com,you@example.com]: </span><br><span class="line">SMTP server address? [smtp.example.com]: </span><br><span class="line">SMTP port? [587]: </span><br><span class="line">SMTP user name? [user@example.com]: </span><br><span class="line">SMTP password? [pa$$word]: </span><br><span class="line">Let&apos;s Encrypt account email? (ENTER to skip) [me@example.com]:</span><br></pre></td></tr></table></figure></p><blockquote><p>开始的安装，由于还没有 app.yml，所以有些配置不能做修改。</p></blockquote><p>安装完成后，会生成一个目录<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/var/discourse/containers</span><br></pre></td></tr></table></figure></p><blockquote><p>该目录下有一个 app.yml 文件</p></blockquote><h2>使用已经存在的 nginx 服务器</h2><p>修改 app.yml 文件<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">templates:</span><br><span class="line">  - &quot;templates/postgres.template.yml&quot;</span><br><span class="line">  - &quot;templates/redis.template.yml&quot;</span><br><span class="line">  - &quot;templates/web.template.yml&quot;</span><br><span class="line">  - &quot;templates/web.ratelimited.template.yml&quot;</span><br><span class="line">  - &quot;templates/web.socketed.template.yml&quot;</span><br><span class="line">## Uncomment these two lines if you wish to add Lets Encrypt (https)</span><br><span class="line">  #- &quot;templates/web.ssl.template.yml&quot;</span><br><span class="line">  #- &quot;templates/web.letsencrypt.ssl.template.yml&quot;</span><br><span class="line"></span><br><span class="line">## which TCP/IP ports should this container expose?</span><br><span class="line">## If you want Discourse to share a port with another webserver like Apache or nginx,</span><br><span class="line">## see https://meta.discourse.org/t/17247 for details</span><br><span class="line">## expose:</span><br><span class="line">##   - &quot;80:80&quot;   # http</span><br><span class="line">##   - &quot;443:443&quot; # https</span><br></pre></td></tr></table></figure></p><blockquote><p>增加 &quot;templates/web.socketed.template.yml&quot; 配置，并注释掉 http 和 https 所在行。</p></blockquote><h2>Email 配置</h2><p>这里的 email 服务器使用上面搭建的自有服务器。修改 app.yml 文件</p><h2>域名配置</h2><p>修改 app.yml 文件设置 DISCOURSE_HOSTNAME 参数为自有域名，如：talk.example.com<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">DISCOURSE_DEVELOPER_EMAILS: &apos;admin@example.com&apos;</span><br><span class="line"></span><br><span class="line">DISCOURSE_SMTP_ADDRESS: smtp.example.com</span><br><span class="line">DISCOURSE_SMTP_PORT: 25</span><br><span class="line">DISCOURSE_SMTP_USER_NAME: admin@example.com</span><br><span class="line">DISCOURSE_SMTP_PASSWORD: &quot;12345678&quot;</span><br><span class="line">DISCOURSE_SMTP_ENABLE_START_TLS: false           # (optional, default true)</span><br></pre></td></tr></table></figure></p><p>以上操作之后，都需要执行命令<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /var/discourse</span><br><span class="line"> ./launcher stop app</span><br><span class="line">./launcher rebuild app</span><br></pre></td></tr></table></figure></p><p>操作完成后，Discourse 论坛基本配置完成，可以正常访问及发送邮件。</p><h2>几个规避操作</h2><p>创建管理员</p><p>如果邮件还是有问题，就没有办法使用管理员登陆论坛，此时，可以做一个规避操作。执行如下命令，进入 app，创建管理员。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./launcher enter app</span><br><span class="line">rake admin:create</span><br><span class="line">exit</span><br></pre></td></tr></table></figure></p><p>切换通知邮箱地址</p><p>还可以手动切换邮箱地址，以此来绕过设置的 Discourse 邮件系统<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./launcher enter app</span><br><span class="line">rails r &quot;SiteSetting.notification_email = &apos;discourse@yoursite.com&apos;&quot;</span><br><span class="line">exit</span><br></pre></td></tr></table></figure></p><h2>troubleshooting</h2><p>进入 app 后，可以查看日志<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./launcher enter app</span><br><span class="line">cd /var/www/discourse/log</span><br><span class="line">tail -f production.log</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/08/20/搭建邮件服务器和论坛/6.jpg&quot; width=&quot;520&quot; height=&quot;520&quot;&gt;&lt;/p&gt;
&lt;p&gt;今天一起来看看如何搭建自己的邮件服务器和论坛服务，使用的工具分别为 Ewomail 和 Discourse。&lt;/p&gt;
&lt;h1&gt;搭建邮件服务器&lt;/h1&gt;
&lt;p&gt;安装 Ewomail 还是很简单的，它支持一键式安装。
（重要，如果服务器上有其他软件，特别是 MySQL 时，请慎重安装！）&lt;/p&gt;
&lt;h2&gt;使用官网方法安装&lt;/h2&gt;
&lt;p&gt;直接使用官方文档安装即可（http://doc.ewomail.com/docs/ewomail/install），安装的时候，需要指定一个域名地址，地址就写自己申请的域名，或者安装之后再修改也是可以的。
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;yum -y install git&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cd /root&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git clone https://github.com/gyxuehu/EwoMail.git&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cd /root/EwoMail/install&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#需要输入一个邮箱域名，不需要前缀，列如下面的ewomail.cn&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sh ./start.sh ewomail.cn&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;安装之后，会有 iptables，如果其他服务的端口不可访问，记得来检查下 iptables。&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="系统" scheme="https://blog.luobodazahui.top/categories/%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="系统" scheme="https://blog.luobodazahui.top/tags/%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Flask-JSGlue 库简介</title>
    <link href="https://blog.luobodazahui.top/2019/08/14/Flask-JSGlue-%E5%BA%93%E7%AE%80%E4%BB%8B/"/>
    <id>https://blog.luobodazahui.top/2019/08/14/Flask-JSGlue-库简介/</id>
    <published>2019-08-14T11:18:06.000Z</published>
    <updated>2019-08-14T11:23:40.011Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/08/14/Flask-JSGlue-库简介/Python.jpg" width="250" height="150"></p><p>今天介绍一个有用的胶水库，Flask-JSGlue，看它的名字，也基本可以看出是连接 Flask 和 JavaScript 的桥梁。我们先来看看它主要解决的问题</p><h1>问题</h1><p>使用 Flask 做 web 开发，不可避免的会遇到在 js 中处理 URL，而我们都知道，在 Flask 中使用 url_for 是很好的动态创建 url 的方式。举个栗子</p><p>在 HTML 中使用</p><p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"&#123;&#123; url_for('static', filename='chat/images/hi.jpg')&#125;&#125;"</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>在 后台逻辑中使用</p><p><a id="more"></a></p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> redirect(url_for(<span class="string">'main.index'</span>))</span><br></pre></td></tr></table></figure></p><p>以上，都不会有什么问题。</p><h2>问题场景</h2><p>在页面加载完成之后，某些动作，会触发页面新增一些 HTML 代码，说起来比较抽象，还是看个栗子</p><p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">sendMessage</span>(<span class="params">event, from_name, to_uid, to_uname</span>)</span>&#123;</span><br><span class="line">    <span class="keyword">var</span> msg = $(<span class="string">"#message_not"</span>).val();</span><br><span class="line"><span class="keyword">var</span> myDate = <span class="keyword">new</span> <span class="built_in">Date</span>();</span><br><span class="line"><span class="keyword">var</span> myTime = myDate.toLocaleTimeString();</span><br><span class="line"><span class="keyword">var</span> itTime = myDate.toLocaleString();</span><br><span class="line"><span class="keyword">var</span> htmlData =   <span class="string">'&lt;div class="msg_item fn-clear"&gt;'</span></span><br><span class="line">                   + <span class="string">'   &lt;div class="uface"&gt;&lt;img src="&#123;&#123; url_for('</span><span class="keyword">static</span><span class="string">', filename='</span>chat/images/hi.jpg<span class="string">')&#125;&#125;" width="40" height="40"  alt=""/&gt;&lt;/div&gt;'</span></span><br><span class="line">       + <span class="string">'   &lt;div class="item_right"&gt;'</span></span><br><span class="line">       + <span class="string">'     &lt;div class="msg own"&gt;'</span> + msg + <span class="string">'&lt;/div&gt;'</span></span><br><span class="line">       + <span class="string">'     &lt;div class="name_time"&gt;'</span> + from_name + <span class="string">' · '</span> + itTime +<span class="string">'&lt;/div&gt;'</span></span><br><span class="line">       + <span class="string">'   &lt;/div&gt;'</span></span><br><span class="line">       + <span class="string">'&lt;/div&gt;'</span>;</span><br><span class="line">$(<span class="string">"#message_box"</span>).append(htmlData);</span><br><span class="line">$(<span class="string">'#message_box'</span>).scrollTop($(<span class="string">"#message_box"</span>)[<span class="number">0</span>].scrollHeight + <span class="number">20</span>);</span><br><span class="line">$(<span class="string">"#message_not"</span>).val(<span class="string">''</span>);</span><br><span class="line">setTimeout(<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;sendToServernoLogin(from_name, msg)&#125;, <span class="number">1000</span>); <span class="comment">//延时调用</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这是我一个在线聊天室的 js 代码，在调用该函数后，会在 message_box 中增加一段 HTML 代码，用来展示用户发送的消息。</p><p>可以看到，在 htmlData 中，对于 img 标签，我用到了 url_for 函数来动态产生 URL，因为这个是用户的头像，很显然每个用户头像会有所不同，所以动态产生 URL 就是必须的了。</p><p>这样看起来还好，直接使用 url_for 编码到 HTML 代码中，也是可行的，下面我们再来看看另一种情况。</p><p>有一个类似如下形式的函数</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">@app.route(&apos;/nvshen/&lt;id&gt;/&apos;, methods=[&apos;GET&apos;, &apos;POST&apos;])</span><br><span class="line">def nvshen(id):</span><br></pre></td></tr></table></figure></p><p>那么使用 url_for 函数就需要为如下形式</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">url_for(&quot;nvshen&quot;, id=123)</span><br></pre></td></tr></table></figure></p><p>下面再来看看如果也是需要写到 HTML 代码里呢</p><p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">var myid = mydata[i][2];</span><br><span class="line">var htmlText = '<span class="tag">&lt;<span class="name">article</span> <span class="attr">class</span>=<span class="string">"white-panel"</span>&gt;</span>' +</span><br><span class="line">   '<span class="tag">&lt;<span class="name">img</span> <span class="attr">data-original</span>=<span class="string">' + myurl +'</span> <span class="attr">class</span>=<span class="string">"thumb"</span>&gt;</span>' +</span><br><span class="line">'<span class="tag">&lt;<span class="name">h1</span>&gt;</span>' +</span><br><span class="line">'<span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"&#123;&#123; url_for('nvshen', id=myid)&#125;&#125;"</span> <span class="attr">title</span>=<span class="string">"去投票"</span> <span class="attr">target</span>=<span class="string">"_blank"</span>&gt;</span>' +</span><br><span class="line">myname + '<span class="tag">&lt;/<span class="name">a</span>&gt;</span>' +</span><br><span class="line">'<span class="tag">&lt;/<span class="name">h1</span>&gt;</span>' +</span><br><span class="line">'<span class="tag">&lt;<span class="name">p</span>&gt;</span>' +</span><br><span class="line">'<span class="tag">&lt;/<span class="name">p</span>&gt;</span>' +</span><br><span class="line">'<span class="tag">&lt;/<span class="name">article</span>&gt;</span>';</span><br></pre></td></tr></table></figure></p><p>类似上面的写法，我试过了各种方式，都不能正确传递 myid 的值，如果有哪位小伙伴知道解法的话，还请告知下。</p><h1>使用 Flask-JSGlue 解决</h1><p>我们先来看看 Flask-JSGlue 的官网，上面的例子也是非常的简单</p><p>后台逻辑</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from flask import Flask</span><br><span class="line">from flask_jsglue import JSGlue</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line">jsglue = JSGlue(app)</span><br></pre></td></tr></table></figure></p><p>前端页面</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;head&gt;&#123;&#123; JSGlue.include() &#125;&#125;&lt;/head&gt;</span><br><span class="line"></span><br><span class="line">Flask.url_for(&quot;index&quot;)</span><br><span class="line"></span><br><span class="line">Flask.url_for(&quot;static&quot;, &#123;&quot;filename&quot;: &quot;jquery.min.js&quot;&#125;)</span><br><span class="line"></span><br><span class="line">Flask.url_for(&quot;api.hello_world&quot;, &#123;&quot;param1&quot;: 1, &quot;param2&quot;: &quot;text&quot;&#125;)</span><br><span class="line"></span><br><span class="line">Flask.url_for(&quot;api.external_link&quot;, &#123;&quot;_external&quot;: true, &quot;_scheme&quot;: &quot;https&quot;, &quot;_anchor&quot;: &quot;main&quot;&#125;)</span><br></pre></td></tr></table></figure></p><blockquote><p>对于需要传递 url 参数的情况，也能够很好的支持，beautiful！</p></blockquote><h2>改写上面的 HTML 字符串</h2><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&apos;&lt;a href=URL title=&quot;去投票&quot; target=&quot;_blank&quot;&gt;&apos;.replace(&quot;URL&quot;, Flask.url_for(&quot;nvshen&quot;, &#123;id: myid&#125;)) +</span><br></pre></td></tr></table></figure></p><p>完美解决</p><p>反正我是被惊艳到了，终于解决了我长久以来的困扰，香！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/08/14/Flask-JSGlue-库简介/Python.jpg&quot; width=&quot;250&quot; height=&quot;150&quot;&gt;&lt;/p&gt;
&lt;p&gt;今天介绍一个有用的胶水库，Flask-JSGlue，看它的名字，也基本可以看出是连接 Flask 和 JavaScript 的桥梁。
我们先来看看它主要解决的问题&lt;/p&gt;
&lt;h1&gt;问题&lt;/h1&gt;
&lt;p&gt;使用 Flask 做 web 开发，不可避免的会遇到在 js 中处理 URL，而我们都知道，在 Flask 中使用 url_for 是很好的动态创建 url 的方式。举个栗子&lt;/p&gt;
&lt;p&gt;在 HTML 中使用&lt;/p&gt;
&lt;p&gt;&lt;figure class=&quot;highlight html&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;src&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;&amp;#123;&amp;#123; url_for(&#39;static&#39;, filename=&#39;chat/images/hi.jpg&#39;)&amp;#125;&amp;#125;&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在 后台逻辑中使用&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="Flask" scheme="https://blog.luobodazahui.top/categories/Flask/"/>
    
    
      <category term="Python" scheme="https://blog.luobodazahui.top/tags/Python/"/>
    
      <category term="Flask" scheme="https://blog.luobodazahui.top/tags/Flask/"/>
    
  </entry>
  
  <entry>
    <title>用 Python 来理一理红楼梦里的那些关系</title>
    <link href="https://blog.luobodazahui.top/2019/08/13/%E7%94%A8-Python-%E6%9D%A5%E7%90%86%E4%B8%80%E7%90%86%E7%BA%A2%E6%A5%BC%E6%A2%A6%E9%87%8C%E7%9A%84%E9%82%A3%E4%BA%9B%E5%85%B3%E7%B3%BB/"/>
    <id>https://blog.luobodazahui.top/2019/08/13/用-Python-来理一理红楼梦里的那些关系/</id>
    <published>2019-08-13T09:34:19.000Z</published>
    <updated>2019-08-13T09:38:33.606Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/08/13/用-Python-来理一理红楼梦里的那些关系/2.jpg"></p><p>今天，一起用 Python 来理一理红楼梦里的那些关系不要问我为啥是红楼梦，而不是水浒三国或西游，因为我也鉴定的认为，红楼才是无可争议的中国古典小说只巅峰，且不接受反驳！而红楼梦也是我多次反复品读的为数不多的小说，对它的感情也是最深的。好了，不酸了，开干。</p><p><a id="more"></a></p><h1>数据准备</h1><ol><li>红楼梦 TXT 文件一份</li><li>金陵十二钗 + 贾宝玉 人物名称列表人物列表内容如下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">宝玉 nr</span><br><span class="line">黛玉 nr</span><br><span class="line">宝钗 nr</span><br><span class="line">湘云 nr</span><br><span class="line">凤姐 nr</span><br><span class="line">李纨 nr</span><br><span class="line">元春 nr</span><br><span class="line">迎春 nr</span><br><span class="line">探春 nr</span><br><span class="line">惜春 nr</span><br><span class="line">妙玉 nr</span><br><span class="line">巧姐 nr</span><br><span class="line">秦氏 nr</span><br></pre></td></tr></table></figure></li></ol><p>这份列表，同时也是为了做分词时使用，后面的 nr 就是人名的意思。</p><h1>数据处理</h1><h2>读取数据并加载词典</h2><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">"红楼梦.txt"</span>, encoding=<span class="string">'gb18030'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    honglou = f.readlines()</span><br><span class="line">jieba.load_userdict(<span class="string">"renwu_forcut"</span>)</span><br><span class="line">renwu_data = pd.read_csv(<span class="string">"renwu_forcut"</span>, header=<span class="number">-1</span>)</span><br><span class="line">mylist = [k[<span class="number">0</span>].split(<span class="string">" "</span>)[<span class="number">0</span>] <span class="keyword">for</span> k <span class="keyword">in</span> renwu_data.values.tolist()]</span><br></pre></td></tr></table></figure></p><p>这样，我们就把红楼梦读取到了 honglou 这个变量当中，同时也通过 load_userdict 将我们自定义的词典加载到了 jieba 库中。</p><h2>对文本进行分词处理并提取</h2><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">tmpNames = []</span><br><span class="line">    names = &#123;&#125;</span><br><span class="line">    relationships = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> h <span class="keyword">in</span> honglou:</span><br><span class="line">        h.replace(<span class="string">"贾妃"</span>, <span class="string">"元春"</span>)</span><br><span class="line">        h.replace(<span class="string">"李宫裁"</span>, <span class="string">"李纨"</span>)</span><br><span class="line">        poss = pseg.cut(h)</span><br><span class="line">        tmpNames.append([])</span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> poss:</span><br><span class="line">            <span class="keyword">if</span> w.flag != <span class="string">'nr'</span> <span class="keyword">or</span> len(w.word) != <span class="number">2</span> <span class="keyword">or</span> w.word <span class="keyword">not</span> <span class="keyword">in</span> mylist:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            tmpNames[<span class="number">-1</span>].append(w.word)</span><br><span class="line">            <span class="keyword">if</span> names.get(w.word) <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                names[w.word] = <span class="number">0</span></span><br><span class="line">            relationships[w.word] = &#123;&#125;</span><br><span class="line">            names[w.word] += <span class="number">1</span></span><br></pre></td></tr></table></figure></p><ul><li>首先，因为文中&quot;贾妃&quot;, &quot;元春&quot;，&quot;李宫裁&quot;, &quot;李纨&quot; 混用严重，所以这里直接做替换处理。</li><li>然后使用 jieba 库提供的 pseg 工具来做分词处理，会返回每个分词的词性。</li><li>之后做判断，只有符合要求且在我们提供的字典列表里的分词，才会保留。</li><li>一个人每出现一次，就会增加一，方便后面画关系图时，人物 node 大小的确定。</li><li>对于存在于我们自定义词典的人名，保存到一个临时变量当中 tmpNames。</li></ul><h2>处理人物关系</h2><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name <span class="keyword">in</span> tmpNames:</span><br><span class="line">    <span class="keyword">for</span> name1 <span class="keyword">in</span> name:</span><br><span class="line">        <span class="keyword">for</span> name2 <span class="keyword">in</span> name:</span><br><span class="line">            <span class="keyword">if</span> name1 == name2:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> relationships[name1].get(name2) <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                relationships[name1][name2] = <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                relationships[name1][name2] += <span class="number">1</span></span><br></pre></td></tr></table></figure></p><p>对于出现在同一个段落中的人物，我们认为他们是关系紧密的，每同时出现一次，关系增加1.</p><h2>保存到文件</h2><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">"relationship.csv"</span>, <span class="string">"w"</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">"Source,Target,Weight\n"</span>)</span><br><span class="line">    <span class="keyword">for</span> name, edges <span class="keyword">in</span> relationships.items():</span><br><span class="line">        <span class="keyword">for</span> v, w <span class="keyword">in</span> edges.items():</span><br><span class="line">            f.write(name + <span class="string">","</span> + v + <span class="string">","</span> + str(w) + <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"NameNode.csv"</span>, <span class="string">"w"</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">"ID,Label,Weight\n"</span>)</span><br><span class="line">    <span class="keyword">for</span> name, times <span class="keyword">in</span> names.items():</span><br><span class="line">        f.write(name + <span class="string">","</span> + name + <span class="string">","</span> + str(times) + <span class="string">"\n"</span>)</span><br></pre></td></tr></table></figure></p><ul><li>文件1：人物关系表，包含首先出现的人物、之后出现的人物和一同出现次数</li><li>文件2：人物比重表，包含该人物总体出现次数，出现次数越多，认为所占比重越大。</li></ul><h1>制作关系图表</h1><p>使用 pyecharts 作图<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deal_graph</span><span class="params">()</span>:</span></span><br><span class="line">    relationship_data = pd.read_csv(<span class="string">'relationship.csv'</span>)</span><br><span class="line">    namenode_data = pd.read_csv(<span class="string">'NameNode.csv'</span>)</span><br><span class="line">    relationship_data_list = relationship_data.values.tolist()</span><br><span class="line">    namenode_data_list = namenode_data.values.tolist()</span><br><span class="line"></span><br><span class="line">    nodes = []</span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> namenode_data_list:</span><br><span class="line">        <span class="keyword">if</span> node[<span class="number">0</span>] == <span class="string">"宝玉"</span>:</span><br><span class="line">            node[<span class="number">2</span>] = node[<span class="number">2</span>]/<span class="number">3</span></span><br><span class="line">        nodes.append(&#123;<span class="string">"name"</span>: node[<span class="number">0</span>], <span class="string">"symbolSize"</span>: node[<span class="number">2</span>]/<span class="number">30</span>&#125;)</span><br><span class="line">    links = []</span><br><span class="line">    <span class="keyword">for</span> link <span class="keyword">in</span> relationship_data_list:</span><br><span class="line">        links.append(&#123;<span class="string">"source"</span>: link[<span class="number">0</span>], <span class="string">"target"</span>: link[<span class="number">1</span>], <span class="string">"value"</span>: link[<span class="number">2</span>]&#125;)</span><br><span class="line"></span><br><span class="line">    g = (</span><br><span class="line">        Graph()</span><br><span class="line">        .add(<span class="string">""</span>, nodes, links, repulsion=<span class="number">8000</span>)</span><br><span class="line">        .set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">"红楼人物关系"</span>))</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> g</span><br></pre></td></tr></table></figure></p><ul><li>首先把两个文件读取成列表形式</li><li>对于“宝玉”，由于其占比过大，如果统一进行缩放，会导致其他人物的 node 过小，展示不美观，所以这里先做了一次缩放</li></ul><p>最后得出的关系图<img src="/2019/08/13/用-Python-来理一理红楼梦里的那些关系/1.png"></p><p>所有代码已经上传至 Github：</p><p>https://github.com/zhouwei713/data_analysis/tree/master/honglou</p><p>最后，我还准备了一份更加全面的红楼人物字典，可以在代码仓库中找到-“renwu_total”，感兴趣的小伙伴也可以尝试下，制作一个全人物的关系图。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/08/13/用-Python-来理一理红楼梦里的那些关系/2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;今天，一起用 Python 来理一理红楼梦里的那些关系
不要问我为啥是红楼梦，而不是水浒三国或西游，因为我也鉴定的认为，红楼才是无可争议的中国古典小说只巅峰，且不接受反驳！而红楼梦也是我多次反复品读的为数不多的小说，对它的感情也是最深的。
好了，不酸了，开干。&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.luobodazahui.top/categories/Python/"/>
    
    
      <category term="Python" scheme="https://blog.luobodazahui.top/tags/Python/"/>
    
      <category term="数据分析" scheme="https://blog.luobodazahui.top/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>女神网站优化之分批返回数据及懒加载</title>
    <link href="https://blog.luobodazahui.top/2019/08/08/%E5%A5%B3%E7%A5%9E%E7%BD%91%E7%AB%99%E4%BC%98%E5%8C%96%E4%B9%8B%E5%88%86%E6%89%B9%E8%BF%94%E5%9B%9E%E6%95%B0%E6%8D%AE%E5%8F%8A%E6%87%92%E5%8A%A0%E8%BD%BD/"/>
    <id>https://blog.luobodazahui.top/2019/08/08/女神网站优化之分批返回数据及懒加载/</id>
    <published>2019-08-08T12:16:08.000Z</published>
    <updated>2019-08-08T12:21:32.179Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/08/08/女神网站优化之分批返回数据及懒加载/fengmian.png"></p><p>作为一个手残的外行前端 coder，今天因为需要，研究了下瀑布延时加载和图片的懒加载，做个总结，免得以后忘记了！</p><h1>瀑布流</h1><p>最近做了一个图片网站，采用的是瀑布流的布局效果，大致如下：</p><p><img src="/2019/08/08/女神网站优化之分批返回数据及懒加载/nvshen1.gif"></p><p>看起来效果还不错，但是问题却来了，首页这里，每次 loading 都会一次性加载200+图片，我的天啊。如果赶上网速不好的时候，会导致其他网页也无法打开。这个真实没法忍，于是我准备优化一下。</p><h1>下拉加载</h1><p>很容易，我自然而然的就想到了采用下拉的形式，每次加载一部分数据，那么说干就干。</p><p><a id="more"></a></p><h2>改造后台</h2><p>最开始，我的后台代码是一次性把所有数据都返回给前端，现在把数据分成4分，首次进入首页时，只返回第一份<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@app.route('/', methods=['GET', 'POST'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">()</span>:</span></span><br><span class="line">    db = get_db()</span><br><span class="line">    cur = db.execute(<span class="string">'select name, nvshen_id from nvshen order by id desc'</span>)</span><br><span class="line">    nvshen = [dict(name=row[<span class="number">0</span>], nvshen_id=row[<span class="number">1</span>]) <span class="keyword">for</span> row <span class="keyword">in</span> cur.fetchall()]</span><br><span class="line">    seg = int(len(nvshen)/<span class="number">4</span>)</span><br><span class="line">    data = []</span><br><span class="line">    socre = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> nvshen[:seg]:</span><br><span class="line">        tmp_data = []</span><br><span class="line">        pic = db.execute(<span class="string">'select pic_url from picture where nvshen_id = (?)'</span>, [n[<span class="string">'nvshen_id'</span>]])</span><br><span class="line">        pic_list = [row[<span class="number">0</span>] <span class="keyword">for</span> row <span class="keyword">in</span> pic.fetchall()]</span><br><span class="line">        pic_url = random.choice(pic_list)</span><br><span class="line">        tmp_data.append(n[<span class="string">'name'</span>])</span><br><span class="line">        tmp_data.append(pic_url)</span><br><span class="line">        tmp_data.append(n[<span class="string">'nvshen_id'</span>])</span><br><span class="line">        data.append(tmp_data)</span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">'index.html'</span>, data=data, score=socre)</span><br></pre></td></tr></table></figure></p><p>然后再写一个获取数据的接口，参数就是 page<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@app.route('/api/getdata/&lt;int:page&gt;', methods=['POST'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">(page)</span>:</span></span><br><span class="line">    db = get_db()</span><br><span class="line">    cur = db.execute(<span class="string">'select name, nvshen_id from nvshen order by id desc'</span>)</span><br><span class="line">    nvshen = [dict(name=row[<span class="number">0</span>], nvshen_id=row[<span class="number">1</span>]) <span class="keyword">for</span> row <span class="keyword">in</span> cur.fetchall()]</span><br><span class="line">    seg = <span class="number">0</span></span><br><span class="line">    seg_page = int(len(nvshen)/<span class="number">4</span>)</span><br><span class="line">    end = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> page == <span class="number">2</span>:</span><br><span class="line">        seg = seg_page</span><br><span class="line">        seg_page = seg*<span class="number">2</span></span><br><span class="line">    <span class="keyword">elif</span> page == <span class="number">3</span>:</span><br><span class="line">        seg = seg_page*<span class="number">2</span></span><br><span class="line">        seg_page = seg*<span class="number">3</span></span><br><span class="line">    <span class="keyword">elif</span> page == <span class="number">4</span>:</span><br><span class="line">        seg = seg_page*<span class="number">3</span></span><br><span class="line">        seg_page = int(len(nvshen)) + <span class="number">1</span></span><br><span class="line">        end = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">elif</span> page == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> jsonify(&#123;<span class="string">"msg"</span>: <span class="string">"error page id"</span>, <span class="string">"code"</span>: <span class="number">422</span>&#125;), <span class="number">422</span></span><br><span class="line">    data = []</span><br><span class="line">    socre = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> nvshen[seg:seg_page]:</span><br><span class="line">        tmp_data = []</span><br><span class="line">        pic = db.execute(<span class="string">'select pic_url from picture where nvshen_id = (?)'</span>, [n[<span class="string">'nvshen_id'</span>]])</span><br><span class="line">        pic_list = [row[<span class="number">0</span>] <span class="keyword">for</span> row <span class="keyword">in</span> pic.fetchall()]</span><br><span class="line">        pic_url = random.choice(pic_list)</span><br><span class="line">        tmp_data.append(n[<span class="string">'name'</span>])</span><br><span class="line">        tmp_data.append(pic_url)</span><br><span class="line">        tmp_data.append(n[<span class="string">'nvshen_id'</span>])</span><br><span class="line">        data.append(tmp_data)</span><br><span class="line">    print(<span class="string">"getdata: "</span>, data)</span><br><span class="line">    <span class="keyword">return</span> jsonify(&#123;<span class="string">"msg"</span>: data, <span class="string">"code"</span>: <span class="number">200</span>, <span class="string">"end"</span>: end&#125;), <span class="number">200</span></span><br></pre></td></tr></table></figure></p><blockquote><p>因为当前只是把数据分成4分，所以当 page 为4的时候，就把停止信号 end 设置为 True，这样前端判断这个信号就可以判断什么时候停止请求数据了。</p></blockquote><h2>改造前端</h2><p>先写一个用户获取数据的函数<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getData</span>(<span class="params">page</span>) </span>&#123;</span><br><span class="line"><span class="keyword">var</span> xhr = <span class="keyword">new</span> XMLHttpRequest();</span><br><span class="line">xhr.responseType = <span class="string">"json"</span>;</span><br><span class="line">xhr.open(<span class="string">'POST'</span>, <span class="string">'/api/getdata/'</span> + page, <span class="literal">true</span>);</span><br><span class="line">xhr.setRequestHeader(<span class="string">"Content-Type"</span>, <span class="string">"application/x-www-form-urlencoded"</span>);</span><br><span class="line">xhr.onload = <span class="function"><span class="keyword">function</span> (<span class="params">ev</span>) </span>&#123;</span><br><span class="line"><span class="keyword">if</span>(<span class="keyword">this</span>.status === <span class="number">200</span>) &#123;</span><br><span class="line"><span class="comment">//console.log(this.response);</span></span><br><span class="line"><span class="keyword">if</span>(<span class="keyword">this</span>.response[<span class="string">'end'</span>] === <span class="literal">true</span>) &#123;</span><br><span class="line"><span class="comment">//console.log("end is true");</span></span><br><span class="line">flag = <span class="literal">false</span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">var</span> mydata = <span class="keyword">this</span>.response[<span class="string">'msg'</span>];</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">var</span> i=<span class="number">0</span>, len=mydata.length; i&lt;len; i++)&#123;</span><br><span class="line"><span class="keyword">var</span> myurl = mydata[i][<span class="number">1</span>];</span><br><span class="line"><span class="keyword">var</span> myid = mydata[i][<span class="number">2</span>];</span><br><span class="line"><span class="keyword">var</span> myname = mydata[i][<span class="number">0</span>];</span><br><span class="line"><span class="keyword">var</span> htmlText = <span class="string">'&lt;article class="white-panel"&gt;'</span> +</span><br><span class="line"><span class="string">'&lt;img data-src='</span> + myurl +<span class="string">' class="thumb"&gt;'</span> +</span><br><span class="line"><span class="string">'&lt;h1&gt;'</span> +</span><br><span class="line"><span class="string">'&lt;a href=URL title="去投票" target="_blank"&gt;'</span>.replace(<span class="string">"URL"</span>, Flask.url_for(<span class="string">"nvshen"</span>, &#123;<span class="attr">id</span>: myid&#125;)) +</span><br><span class="line"> myname + <span class="string">'&lt;/a&gt;'</span> +</span><br><span class="line"><span class="string">'&lt;/h1&gt;'</span> +</span><br><span class="line"><span class="string">'&lt;p&gt;'</span> +</span><br><span class="line"><span class="string">'&lt;div id="starBg" class="stars-bg"&gt;'</span> +</span><br><span class="line"><span class="string">'&#123;% if score == 1 %&#125;'</span> +</span><br><span class="line"><span class="string">'&lt;a href="#" class="star-active" style="width: 20%"&gt;&lt;/a&gt;'</span> +</span><br><span class="line"><span class="string">'&#123;% elif score == 2 %&#125;'</span> +</span><br><span class="line"><span class="string">'&lt;a href="#" class="star-active" style="width: 40%"&gt;&lt;/a&gt;'</span> +</span><br><span class="line"><span class="string">'&#123;% elif score == 3 %&#125;'</span> +</span><br><span class="line"><span class="string">'&lt;a href="#" class="star-active" style="width: 60%"&gt;&lt;/a&gt;'</span> +</span><br><span class="line"><span class="string">'&#123;% elif score == 4 %&#125;'</span> +</span><br><span class="line"><span class="string">'&lt;a href="#" class="star-active" style="width: 80%"&gt;&lt;/a&gt;'</span> +</span><br><span class="line"><span class="string">'&#123;% elif score == 5 %&#125;'</span> +</span><br><span class="line"><span class="string">'&lt;a href="#" class="star-active" style="width: 100%"&gt;&lt;/a&gt;'</span> +</span><br><span class="line"><span class="string">'&#123;% else %&#125;'</span> +</span><br><span class="line"><span class="string">'&lt;a href="#" class="star-active" style="width: 0%"&gt;&lt;/a&gt;'</span> +</span><br><span class="line"><span class="string">'&#123;% endif %&#125;'</span> +</span><br><span class="line"><span class="string">'&lt;/div&gt;'</span> +</span><br><span class="line"><span class="string">'&lt;/p&gt;'</span> +</span><br><span class="line"><span class="string">'&lt;/article&gt;'</span>;</span><br><span class="line"><span class="keyword">var</span> script = <span class="string">'&lt;script&gt;'</span> +</span><br><span class="line"><span class="string">'$(function()&#123;'</span> +</span><br><span class="line"><span class="string">'$("img.thumb").lazyload();'</span> +</span><br><span class="line"><span class="string">'&#125;)'</span> +</span><br><span class="line"><span class="string">'&lt;\/script&gt;'</span>;</span><br><span class="line">$(<span class="string">'#gallery-wrapper'</span>).append(htmlText);</span><br><span class="line">$(<span class="string">'body'</span>).append(script);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//console.log("add new html finish");</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line">xhr.send();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><blockquote><p>主要还是拼接字符串，然后把获取到的数据塞进字符串中。</p></blockquote><p><strong>flask_jsglue</strong></p><p>这里不得不提一下 flask 的一个插件 --flask_jsglue对于在 JavaScript 中使用 url_for 函数真的是太好用了，感兴趣的同学可以自行去看看，非常的简单好用。</p><p>然后就是下拉的逻辑了<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">      <span class="keyword">var</span> totalHeight = $(<span class="built_in">document</span>).height(); <span class="comment">//整个文档高度</span></span><br><span class="line"><span class="keyword">var</span> scrollTop = $(<span class="built_in">window</span>).scrollTop();<span class="comment">//浏览器可视窗口顶端距离网页顶端的高度（垂直偏移）</span></span><br><span class="line"><span class="keyword">var</span> p = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">var</span> flag = <span class="literal">true</span>;</span><br><span class="line">$(<span class="built_in">window</span>).scroll(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">scrollTop = $(<span class="built_in">window</span>).scrollTop();</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">"totalHeight-scrollTop-$(this).height()"</span>, totalHeight-scrollTop-$(<span class="keyword">this</span>).height());</span><br><span class="line">totalHeight = $(<span class="built_in">document</span>).height();</span><br><span class="line"><span class="keyword">if</span>(flag)&#123;</span><br><span class="line"><span class="keyword">if</span>(totalHeight-scrollTop-$(<span class="keyword">this</span>).height()&lt;<span class="number">0.5</span>)&#123;</span><br><span class="line"><span class="comment">//console.log("add new html");</span></span><br><span class="line">getData(p);</span><br><span class="line">p ++;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p><blockquote><p>因为我们再进入首页的时候，已经返回了数据的第一部分，所以这里的 page 就从2开始取值；然后当整个文档的高度减去垂直偏移量，再减去浏览器可是窗口的高度小于0.5时，则调用拉取数据的函数，并且 p 自加1.</p></blockquote><h1>图片懒加载</h1><p>对于图片懒加载，就比较简单了，有现成的组件库可以使用。首先引入类库<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;script src=<span class="string">"https://rawgit.com/tuupola/jquery_lazyload/2.x/lazyload.js"</span> type=<span class="string">"text/javascript"</span>&gt;<span class="xml"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br></pre></td></tr></table></figure></p><p>然后修改 img 元素的图片地址属性<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;img <span class="class"><span class="keyword">class</span></span>=<span class="string">"thumb"</span> data-src=<span class="string">"&#123;&#123; p[1] &#125;&#125;"</span>&gt;</span><br></pre></td></tr></table></figure></p><blockquote><p>我们一般会把图片地址赋值给 src，现在我们赋值给 data-src。</p></blockquote><p>最后，在页面全局写一个函数<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$(<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">      $(<span class="string">"img.thumb"</span>).lazyload();</span><br><span class="line">  &#125;);</span><br></pre></td></tr></table></figure></p><p>这样，就能保证图片只要当页面滚动到它的位置时才加载了。</p><p>最后再提供下网站地址，供大家参考https://nvshen.luobodazahui.top</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/08/08/女神网站优化之分批返回数据及懒加载/fengmian.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;作为一个手残的外行前端 coder，今天因为需要，研究了下瀑布延时加载和图片的懒加载，做个总结，免得以后忘记了！&lt;/p&gt;
&lt;h1&gt;瀑布流&lt;/h1&gt;
&lt;p&gt;最近做了一个图片网站，采用的是瀑布流的布局效果，大致如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/08/08/女神网站优化之分批返回数据及懒加载/nvshen1.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;看起来效果还不错，但是问题却来了，首页这里，每次 loading 都会一次性加载200+图片，我的天啊。如果赶上网速不好的时候，会导致其他网页也无法打开。这个真实没法忍，于是我准备优化一下。&lt;/p&gt;
&lt;h1&gt;下拉加载&lt;/h1&gt;
&lt;p&gt;很容易，我自然而然的就想到了采用下拉的形式，每次加载一部分数据，那么说干就干。&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="前端杂记" scheme="https://blog.luobodazahui.top/categories/%E5%89%8D%E7%AB%AF%E6%9D%82%E8%AE%B0/"/>
    
    
      <category term="Flask" scheme="https://blog.luobodazahui.top/tags/Flask/"/>
    
      <category term="JavaScript" scheme="https://blog.luobodazahui.top/tags/JavaScript/"/>
    
  </entry>
  
  <entry>
    <title>没有忍住，还是用Python爬了N多个女神</title>
    <link href="https://blog.luobodazahui.top/2019/08/05/%E6%B2%A1%E6%9C%89%E5%BF%8D%E4%BD%8F%EF%BC%8C%E8%BF%98%E6%98%AF%E7%94%A8Python%E7%88%AC%E4%BA%86N%E5%A4%9A%E4%B8%AA%E5%A5%B3%E7%A5%9E/"/>
    <id>https://blog.luobodazahui.top/2019/08/05/没有忍住，还是用Python爬了N多个女神/</id>
    <published>2019-08-05T10:42:33.000Z</published>
    <updated>2019-08-05T12:31:26.497Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/08/05/没有忍住，还是用Python爬了N多个女神/nvshen11.png"></p><p>学 Python，从爬女神开始啥也不说，今天是来送福利的</p><h1>女神大会</h1><p>不是知道有多少人知道“懂球帝”这个 APP（网站），又有多少人关注过它的一个栏目“女神大会”，在这里，没有足球，只有女神哦。画风是这样的<img src="/2019/08/05/没有忍住，还是用Python爬了N多个女神/1.png"></p><p>女神评分，全部是由球迷来决定，是不是很赤鸡，下面就一起来看看球迷眼中女神排名吧。</p><p><a id="more"></a></p><h1>开工</h1><h2>获取 ID 信息</h2><p>首先，我们可以通过抓取懂球帝 APP 的网络请求，拿到一个 API，http://api.dongqiudi.com/search?keywords=type=all&amp;page=该 API ，我们能够拿到如下信息<img src="/2019/08/05/没有忍住，还是用Python爬了N多个女神/4.png">我们主要关注 ID 和 thumb，ID 后面用来拼接女神所在页面的 HTML 地址，thumb 就用来收藏。</p><p><img src="/2019/08/05/没有忍住，还是用Python爬了N多个女神/huaixiao.jpg"></p><p>于是，我们就可以得到一个简单的解析函数</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_list</span><span class="params">(page)</span>:</span></span><br><span class="line">    nvshen_id_list = []</span><br><span class="line">    nvshen_id_picture = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, page):</span><br><span class="line">        print(<span class="string">"获取第"</span> + str(i) + <span class="string">"页数据"</span>)</span><br><span class="line">        url = <span class="string">'http://api.dongqiudi.com/search?keywords=%E5%A5%B3%E7%A5%9E%E5%A4%A7%E4%BC%9A&amp;type=all&amp;page='</span> + str(i)</span><br><span class="line">        html = requests.get(url=url).text</span><br><span class="line">        news = json.loads(html)[<span class="string">'news'</span>]</span><br><span class="line">        <span class="keyword">if</span> len(news) == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"没有更多啦"</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        nvshen_id = [k[<span class="string">'id'</span>] <span class="keyword">for</span> k <span class="keyword">in</span> news]</span><br><span class="line">        nvshen_id_list = nvshen_id_list + nvshen_id</span><br><span class="line">        nvshen_id_picture = nvshen_id_picture + [&#123;k[<span class="string">'id'</span>]: k[<span class="string">'thumb'</span>]&#125; <span class="keyword">for</span> k <span class="keyword">in</span> news]</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> nvshen_id_list, nvshen_id_picture</span><br></pre></td></tr></table></figure></p><h2>下载 HTML 页面</h2><p>接下来，通过观察，我们能够得到，每个女神所在的页面地址都是这样的，</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.dongqiudi.com/archive/**.html</span><br></pre></td></tr></table></figure></p><p>其中 ** 就是上面拿到的 ID 值，那么获取 HTML 页面的代码也就有了</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_page</span><span class="params">(nvshen_id_list)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> nvshen_id_list:</span><br><span class="line">        print(<span class="string">"正在下载ID为"</span> + i + <span class="string">"的HTML网页"</span>)</span><br><span class="line">        url = <span class="string">'https://www.dongqiudi.com/archive/%s.html'</span> % i</span><br><span class="line">        download = DownloadPage()</span><br><span class="line">        html = download.getHtml(url)</span><br><span class="line">        download.saveHtml(i, html)</span><br><span class="line">        time.sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DownloadPage</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getHtml</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        html = requests.get(url=url).content</span><br><span class="line">        <span class="keyword">return</span> html</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">saveHtml</span><span class="params">(self, file_name, file_content)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'html_page/'</span> + file_name + <span class="string">'.html'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(file_content)</span><br></pre></td></tr></table></figure></p><blockquote><p>防止访问限制，每次请求都做了2秒的等待</p></blockquote><p>但是，问题来了当我直接请求这个页面的时候，竟然是这样的</p><p><img src="/2019/08/05/没有忍住，还是用Python爬了N多个女神/5.png"></p><p>被（悲）拒（剧）了<img src="/2019/08/05/没有忍住，还是用Python爬了N多个女神/zhenjing.jpg">没办法，继续斗争。重新分析，发现请求中有携带一个 cookie，哈哈，这个我们已经轻车熟路啦对 requests 请求增加 cookie，同时再把 headers 里面增加个 User-Agent，再试</p><p><img src="/2019/08/05/没有忍住，还是用Python爬了N多个女神/6.png"></p><p>成了！</p><p><img src="/2019/08/05/没有忍住，还是用Python爬了N多个女神/7.png"></p><h2>解析本地 HTML</h2><p>最后，就是解析下载到本地的 HTML 页面了，页面的规则就是，本期女神介绍页面，会公布上期女神的综合得分，而我们的主要任务就是获取各个女神的得分<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deal_loaclfile</span><span class="params">(nvshen_id_picture)</span>:</span></span><br><span class="line">    files = os.listdir(<span class="string">'html_page/'</span>)</span><br><span class="line">    nvshen_list = []</span><br><span class="line">    special_page = []</span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> files:</span><br><span class="line">        <span class="keyword">if</span> f[<span class="number">-4</span>:] == <span class="string">'html'</span> <span class="keyword">and</span> <span class="keyword">not</span> f.startswith(<span class="string">'~'</span>):</span><br><span class="line">            htmlfile = open(<span class="string">'html_page/'</span> + f, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>).read()</span><br><span class="line">            content = BeautifulSoup(htmlfile, <span class="string">'html.parser'</span>)</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                tmp_list = []</span><br><span class="line">                nvshen_name = content.find(text=re.compile(<span class="string">"上一期女神"</span>))</span><br><span class="line">                <span class="keyword">if</span> nvshen_name <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                nvshen_name_new = re.findall(<span class="string">r"女神(.+?)，"</span>, nvshen_name)</span><br><span class="line">                nvshen_count = re.findall(<span class="string">r"超过(.+?)人"</span>, nvshen_name)</span><br><span class="line">                tmp_list.append(<span class="string">''</span>.join(nvshen_name_new))</span><br><span class="line">                tmp_list.append(<span class="string">''</span>.join(nvshen_count))</span><br><span class="line">                tmp_list.append(f[:<span class="number">-4</span>])</span><br><span class="line">                tmp_score = content.find_all(<span class="string">'span'</span>, attrs=&#123;<span class="string">'style'</span>: <span class="string">"color:#ff0000"</span>&#125;)</span><br><span class="line">                tmp_score = list(filter(<span class="literal">None</span>, [k.string <span class="keyword">for</span> k <span class="keyword">in</span> tmp_score]))</span><br><span class="line">                <span class="keyword">if</span> <span class="string">'.'</span> <span class="keyword">in</span> tmp_score[<span class="number">0</span>]:</span><br><span class="line">                    <span class="keyword">if</span> len(tmp_score[<span class="number">0</span>]) &gt; <span class="number">3</span>:</span><br><span class="line">                        tmp_list.append(<span class="string">''</span>.join(list(filter(str.isdigit, tmp_score[<span class="number">0</span>].strip()))))</span><br><span class="line">                        nvshen_list = nvshen_list + get_picture(content, tmp_list, nvshen_id_picture)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        tmp_list.append(tmp_score[<span class="number">0</span>])</span><br><span class="line">                        nvshen_list = nvshen_list + get_picture(content, tmp_list, nvshen_id_picture)</span><br><span class="line">                <span class="keyword">elif</span> len(tmp_score) &gt; <span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">if</span> <span class="string">'.'</span> <span class="keyword">in</span> tmp_score[<span class="number">1</span>]:</span><br><span class="line">                        <span class="keyword">if</span> len(tmp_score[<span class="number">1</span>]) &gt; <span class="number">3</span>:</span><br><span class="line">                            tmp_list.append(<span class="string">''</span>.join(list(filter(str.isdigit, tmp_score[<span class="number">1</span>].strip()))))</span><br><span class="line">                            nvshen_list = nvshen_list + get_picture(content, tmp_list, nvshen_id_picture)</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            tmp_list.append(tmp_score[<span class="number">1</span>])</span><br><span class="line">                            nvshen_list = nvshen_list + get_picture(content, tmp_list, nvshen_id_picture)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        special_page.append(f)</span><br><span class="line">                        print(<span class="string">"拿不到score的HTML："</span>, f)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    special_page.append(f)</span><br><span class="line">                    print(<span class="string">"拿不到score的HTML："</span>, f)</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                print(<span class="string">"解析出错的HTML："</span>, f)</span><br><span class="line">                <span class="keyword">raise</span></span><br><span class="line">    <span class="keyword">return</span> nvshen_list, special_page</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_picture</span><span class="params">(c, t_list, n_id_p)</span>:</span></span><br><span class="line">    print(<span class="string">"进入get_picture函数:"</span>)</span><br><span class="line">    nvshen_l = []</span><br><span class="line">    tmp_prev_id = c.find_all(<span class="string">'a'</span>, attrs=&#123;<span class="string">"target"</span>: <span class="string">"_self"</span>&#125;)</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> tmp_prev_id:</span><br><span class="line">        <span class="keyword">if</span> <span class="string">'期'</span> <span class="keyword">in</span> j.string:</span><br><span class="line">            href_list = j[<span class="string">'href'</span>].split(<span class="string">'/'</span>)</span><br><span class="line">            tmp_id = re.findall(<span class="string">r"\d+\.?\d*"</span>, href_list[<span class="number">-1</span>])</span><br><span class="line">            <span class="keyword">if</span> len(tmp_id) == <span class="number">1</span>:</span><br><span class="line">                prev_nvshen_id = tmp_id[<span class="number">0</span>]</span><br><span class="line">                t_list.append(prev_nvshen_id)</span><br><span class="line">                <span class="keyword">for</span> n <span class="keyword">in</span> n_id_p:</span><br><span class="line">                    <span class="keyword">for</span> k, v <span class="keyword">in</span> n.items():</span><br><span class="line">                        <span class="keyword">if</span> k == prev_nvshen_id:</span><br><span class="line">                            t_list.append(v)</span><br><span class="line">                            print(<span class="string">"t_list"</span>, t_list)</span><br><span class="line">                            nvshen_l.append(t_list)</span><br><span class="line">                            print(<span class="string">"get_picture函数结束"</span>)</span><br><span class="line">                            <span class="keyword">return</span> nvshen_l</span><br></pre></td></tr></table></figure></p><h2>保存数据</h2><p>对于我们最后解析出来的数据，我们直接保存到 csv 文件中，如果数据量比较大的话，还可以考虑保存到 mongodb 中。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_file</span><span class="params">(nvshen_list, filename)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(filename + <span class="string">'.csv'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> output:</span><br><span class="line">        output.write(<span class="string">'name,count,score,weight_score,page_id,picture\n'</span>)</span><br><span class="line">        <span class="keyword">for</span> row <span class="keyword">in</span> nvshen_list:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                weight = int(<span class="string">''</span>.join(list(filter(str.isdigit, row[<span class="number">1</span>])))) / <span class="number">1000</span></span><br><span class="line">                weight_2 = float(row[<span class="number">2</span>]) + float(<span class="string">'%.2f'</span> % weight)</span><br><span class="line">                weight_score = float(<span class="string">'%.2f'</span> % weight_2)</span><br><span class="line">                rowcsv = <span class="string">'&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;'</span>.format(row[<span class="number">0</span>], row[<span class="number">1</span>], row[<span class="number">3</span>], weight_score, row[<span class="number">4</span>], row[<span class="number">5</span>])</span><br><span class="line">                output.write(rowcsv)</span><br><span class="line">                output.write(<span class="string">'\n'</span>)</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="keyword">raise</span></span><br></pre></td></tr></table></figure></p><blockquote><p>对于女神的得分，又根据打分的人数，做了个加权分数</p></blockquote><p>保存图片<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_pic</span><span class="params">(url, nick_name)</span>:</span></span><br><span class="line">    resp = requests.get(url)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'picture'</span>):</span><br><span class="line">        os.mkdir(<span class="string">'picture'</span>)</span><br><span class="line">    <span class="keyword">if</span> resp.status_code == <span class="number">200</span>:</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'picture'</span> + <span class="string">f'/<span class="subst">&#123;nick_name&#125;</span>.jpg'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(resp.content)</span><br></pre></td></tr></table></figure></p><blockquote><p>直接从拿到的 thumb 地址中下载图片，并保存到本地。</p></blockquote><h1>做一些图</h1><p>首先我们先做一个柱状图，看看排名前10和倒数前10的情况<img src="/2019/08/05/没有忍住，还是用Python爬了N多个女神/8.png">可以看到，朱茵、石川恋和高圆圆位列三甲，而得分高达95+的女神也有7位之多。那么排名后10位的呢，自行看吧，有没有人感到有点扎心呢，哈哈哈。同时，也能够从打分的人数来看出，人气高的女神，普遍得分也不低哦。不过，该排名目前只代表球迷心目中的榜单，不知道程序猿心中的榜单会是怎样的呢<img src="/2019/08/05/没有忍住，还是用Python爬了N多个女神/touxiao.gif"></p><p><strong>词云</strong><img src="/2019/08/05/没有忍住，还是用Python爬了N多个女神/9.png"></p><p><strong>图片墙</strong><img src="/2019/08/05/没有忍住，还是用Python爬了N多个女神/11.png"></p><p>不要流口水哦</p><p><img src="/2019/08/05/没有忍住，还是用Python爬了N多个女神/liukoushui.gif"></p><h1>百度 API 评分</h1><p>百度有免费的人脸检测 API，只要输入图片，就能够得到对应的人脸得分，还是非常方便的，感兴趣的小伙伴可以去官网看看哦。我这里直接给出了我通过百度 API 得出的女神新得分，一起来看看吧<img src="/2019/08/05/没有忍住，还是用Python爬了N多个女神/10.png">哈哈哈哈，AI 的评分，对于图片的依赖太高，纯属娱乐。</p><p>代码地址：https://github.com/zhouwei713/data_analysis/tree/master/nvshendahui</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/08/05/没有忍住，还是用Python爬了N多个女神/nvshen11.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;学 Python，从爬女神开始
啥也不说，今天是来送福利的&lt;/p&gt;
&lt;h1&gt;女神大会&lt;/h1&gt;
&lt;p&gt;不是知道有多少人知道“懂球帝”这个 APP（网站），又有多少人关注过它的一个栏目“女神大会”，在这里，没有足球，只有女神哦。
画风是这样的
&lt;img src=&quot;/2019/08/05/没有忍住，还是用Python爬了N多个女神/1.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;女神评分，全部是由球迷来决定，是不是很赤鸡，下面就一起来看看球迷眼中女神排名吧。&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.luobodazahui.top/categories/Python/"/>
    
    
      <category term="爬虫" scheme="https://blog.luobodazahui.top/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>微博内容及评论自动爬取</title>
    <link href="https://blog.luobodazahui.top/2019/08/01/%E5%BE%AE%E5%8D%9A%E5%86%85%E5%AE%B9%E5%8F%8A%E8%AF%84%E8%AE%BA%E8%87%AA%E5%8A%A8%E7%88%AC%E5%8F%96/"/>
    <id>https://blog.luobodazahui.top/2019/08/01/微博内容及评论自动爬取/</id>
    <published>2019-08-01T11:13:25.000Z</published>
    <updated>2019-08-01T12:34:03.431Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/08/01/微博内容及评论自动爬取/spider.jpg"></p><p>今天呢，继续撸微博，希望新浪的大神们不在啊啊啊。</p><p><strong>缘起</strong></p><p>昨天写了一篇文章，主要是有感于文章马伊琍的婚姻，才爬了下他们微博下的评论，结果有位老哥说<img src="/2019/08/01/微博内容及评论自动爬取/1.png">这还了得，我这小暴脾气不能忍啊，果断准备再次出手，拿下姐姐的微博评论。但是当我把瓜子都买好的时候。。。正当我准备再次 F12 查 ID，造 URL 的时候，作为一名非专业码农的惰性就体现出来了，每次都这么搞，是不是有点太繁琐了。于是，作为各类轮子的深度依赖者，这次我准备自己造个轮子。</p><p><a id="more"></a></p><h1>设想</h1><ol><li>最起码是一个自动抓取的脚本，嗯，这是底线！</li><li>有个入口输入要爬取的人物（当前设定为大 V，和搜索到的第一个人）</li><li>之后，就交给程序，坐等数据</li></ol><h1>思路</h1><p>于是乎，在上述设想的指引下，我开始了轮子之旅</p><h2>抓取入口</h2><p>首先想到的就是利用微博的搜索功能，然后再看看能得到些啥这个搜索 URL：</p><p>https://s.weibo.com/user?q=林志玲</p><p>可以直接调，爽的飞起！具体分析过程就不详细写了，从中我们可以拿到用户的 UID，很重要。</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">url = <span class="string">'https://s.weibo.com/user?q=林志玲'</span></span><br><span class="line">res = requests.get(url).text</span><br><span class="line">content = BeautifulSoup(res, <span class="string">'html.parser'</span>)</span><br><span class="line">user = content.find(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'card card-user-b s-pg16 s-brt1'</span>&#125;)</span><br><span class="line"></span><br><span class="line">user_info = user.find(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'info'</span>&#125;).find(<span class="string">'div'</span>)</span><br><span class="line">href_list = user_info.find_all(<span class="string">'a'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> len(href_list) == <span class="number">3</span>:</span><br><span class="line">    title = href_list[<span class="number">1</span>].get(<span class="string">'title'</span>)</span><br><span class="line">    <span class="keyword">if</span> title == <span class="string">'微博个人认证'</span>:</span><br><span class="line">        uid = href_list[<span class="number">2</span>].get(<span class="string">'uid'</span>)</span><br><span class="line">        print(uid)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">"this is not a big VIP"</span>)</span><br></pre></td></tr></table></figure></p><blockquote><p>因为这种搜索，可能会搜索出很多结果，张三、李四啥的都出来了，我们只关心大 V ，对于非大 V，就取第一个喽。</p></blockquote><h2>两次调用</h2><p>下面要隆重解释一个 URL</p><p>https://m.weibo.cn/api/container/getIndex</p><p>这个地址可以在微博的 m 站上找到，有时候，爬 m 站的地址要更容易些哦。这个地址，我们主要有两个作用，使用不同的参数，调用两次</p><h3>调用一</h3><p>首先我们这样调用该 URL</p><p>https://m.weibo.cn/api/container/getIndex?type=uid&amp;value=1312412824</p><blockquote><p>value 为上面拿到的用户 UID</p></blockquote><p>看 Postman<img src="/2019/08/01/微博内容及评论自动爬取/2.png">能得到该用户的用户信息，这里面有一个很重要的信息，containerid，保存下来，一会用。</p><h3>调用二</h3><p>接着我们再这样调用该 URL</p><p>https://m.weibo.cn/api/container/getIndex?containerid=1076031312412824&amp;page=0</p><blockquote><p>containerid 就是上一步得到的 ID</p></blockquote><p>继续看 Postman<img src="/2019/08/01/微博内容及评论自动爬取/3.png">得到的就是 blog 信息了，返回的是 json 数据，很棒。</p><p>最后，我们可以再结合前面文章的获取评论的方法，那么该用户下的博客和评论内容就都到手喽。</p><h1>开搞</h1><p>此处先省去菜鸟被虐的一万点伤害值<img src="/2019/08/01/微博内容及评论自动爬取/4.jpg">其中的千辛万苦，谁能知之。</p><h2>一、配置文件</h2><p>先来个配置文件，毕竟大型项目都是这么玩的，我这也是大型项目<img src="/2019/08/01/微博内容及评论自动爬取/5.gif"></p><p>config.py 文件</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sleep_time = <span class="number">5</span>  <span class="comment"># 延迟时间，建议配置5-10s</span></span><br><span class="line">headers = &#123;</span><br><span class="line">        <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36"</span>,</span><br><span class="line">        <span class="string">"Cookie"</span>: <span class="string">"your cookie"</span></span><br><span class="line">    &#125;</span><br><span class="line">day = <span class="number">60</span>  <span class="comment"># 最久抓取的微博时间，60即为只抓取两个月前到现在的微博</span></span><br></pre></td></tr></table></figure></p><h2>二、工具箱</h2><p>抽象出一些公共的函数，不能把代码写的太丑了</p><p>tools.py 文件</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkTime</span><span class="params">(inputtime, day)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        intime = datetime.datetime.strptime(<span class="string">"2019-"</span> + inputtime, <span class="string">'%Y-%m-%d'</span>)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"时间转换失败"</span></span><br><span class="line"></span><br><span class="line">    now = datetime.datetime.now()</span><br><span class="line">    n_days = now - intime</span><br><span class="line">    days = n_days.days</span><br><span class="line">    <span class="keyword">if</span> days &lt; day:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure></p><blockquote><p>这个是用来检查时间间隔的，后面在抓取微博时，如果时间太久远的，就不抓了。</p></blockquote><p>还有一个函数是用来解析 blog 数据的，因为是 json 数据，解析起来很简单，就不多说了<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_blog_info</span><span class="params">(cards, i, name, page)</span>:</span></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></p><h2>三、主逻辑</h2><p>定义一个 WeiBo 类<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">class WeiBo(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self, name, headers):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.headers = headers</span><br></pre></td></tr></table></figure></p><blockquote><p>后面所有的操作，都是基于该类来的</p></blockquote><p>类中的方法<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_uid</span><span class="params">(self)</span>:</span>  <span class="comment"># 获取用户的 UID</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_userinfo</span><span class="params">(self, uid)</span>:</span>  <span class="comment"># 获取用户信息，包括 containerid</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_blog_by_page</span><span class="params">(self, containerid, page, name)</span>:</span>  <span class="comment"># 获取 page 页的微博信息</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_blog_by_text</span><span class="params">(self, containerid, blog_text, name)</span>:</span>  <span class="comment"># 一个简单的搜索功能，根据输入的内容查找对应的微博</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_comment</span><span class="params">(self, mblog_id, page)</span>:</span>  <span class="comment"># 与上个函数配合使用，用于获取某个微博的评论</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_comment</span><span class="params">(self, comment)</span>:</span>  <span class="comment"># 下载评论</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_pic</span><span class="params">(self)</span>:</span>  <span class="comment"># 灵感来源于“胖虎”哥的“营养快线”文章，暂未实现</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></p><h2>四、运行函数</h2><p>这里个人感觉逻辑写的还是有点臃肿，没办法，菜！各位大神如果路过，还请不要嫌弃。主要就是配合 input 函数，来获取用户的输入，然后根据不同情况调取 WeiBo 类里的方法。</p><p>至此，一个勉强可用的轮子基本完成了，可把我累（牛）坏（逼）了（坏）啦（了）<img src="/2019/08/01/微博内容及评论自动爬取/6.jpg"></p><h3>成果展示</h3><p>扯了这么多，终于到了见成果的时候了，先来看个动图<img src="/2019/08/01/微博内容及评论自动爬取/7.gif">网络上爆炸的“乔碧萝殿下”，成为了我检（祭）验（刀）的第一人<img src="/2019/08/01/微博内容及评论自动爬取/8.jpg"></p><p>那么最后还是要扣题呀，把那段缘结束掉。看看志玲姐姐微博下的评论，到底是咋样其实拿到评论数据之后，简单浏览了下，确实有很多难以启齿的评论，但是呢，这个事情我觉得还是没有必要太上纲上线了，哈哈哈，总之祝福吧<img src="/2019/08/01/微博内容及评论自动爬取/zhiling.png">（此处请自动过滤掉一些些不和谐因素）</p><p>下面，前方，高能，<img src="/2019/08/01/微博内容及评论自动爬取/9.jpg">前方是大型认亲现场，怕引起不适的请跳过。<img src="/2019/08/01/微博内容及评论自动爬取/qiaobiluo.png">持续发酵的事件背后，产生了各种赢家，斗鱼平台、主播晴子，当然还有 CXK 喽，不能说了<img src="/2019/08/01/微博内容及评论自动爬取/10.jpg"></p><p>最后的最后，献上代码：</p><p><a href="https://github.com/zhouwei713/weibo_spider" target="_blank" rel="noopener">https://github.com/zhouwei713/weibo_spider</a></p><p>完！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/08/01/微博内容及评论自动爬取/spider.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;今天呢，继续撸微博，希望新浪的大神们不在啊啊啊。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;缘起&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;昨天写了一篇文章，主要是有感于文章马伊琍的婚姻，才爬了下他们微博下的评论，结果有位老哥说
&lt;img src=&quot;/2019/08/01/微博内容及评论自动爬取/1.png&quot;&gt;
这还了得，我这小暴脾气不能忍啊，果断准备再次出手，拿下姐姐的微博评论。但是当我把瓜子都买好的时候。。。
正当我准备再次 F12 查 ID，造 URL 的时候，作为一名非专业码农的惰性就体现出来了，每次都这么搞，是不是有点太繁琐了。于是，作为各类轮子的深度依赖者，这次我准备自己造个轮子。&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.luobodazahui.top/categories/Python/"/>
    
    
      <category term="爬虫" scheme="https://blog.luobodazahui.top/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="微博" scheme="https://blog.luobodazahui.top/tags/%E5%BE%AE%E5%8D%9A/"/>
    
  </entry>
  
  <entry>
    <title>基于矩阵分解算法的推荐系统实战</title>
    <link href="https://blog.luobodazahui.top/2019/07/30/%E5%9F%BA%E4%BA%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E7%AE%97%E6%B3%95%E7%9A%84%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/"/>
    <id>https://blog.luobodazahui.top/2019/07/30/基于矩阵分解算法的推荐系统实战/</id>
    <published>2019-07-30T13:05:52.000Z</published>
    <updated>2019-07-31T10:40:53.262Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/07/30/基于矩阵分解算法的推荐系统实战/jiqixuexi.jpg"></p><p>基于矩阵分解算法的图书推荐系统实战</p><h1>推荐系统</h1><p>推荐系统，可以根据用户的喜好来推荐给用户不同的事物。</p><p>推荐系统类型：</p><ol><li>纯手工设置推荐内容</li><li>根据物品的销量，曝光率等来排序物品，并推荐给用户</li><li>根据不同的算法，整合不同维度的数据，来智能的推荐物品</li></ol><h2>简单的推荐系统模型</h2><p>设：U 为所有用户集合P 为所有物品集合R 为用户对物品的喜好程度模型 Model(R) = U * P算法核心：</p><p><a id="more"></a></p><p>通过用户对不同物品的打分，来预测用户对其他物品的喜好程度。此处并没有考虑用户和物品的属性，如：用户年龄，性别，学历，工作等，物品价格，品类，外观等。</p><p>通过用户对物品的打分，可以建立一个推荐值矩阵，之后就可以通过运算该矩阵来预测用户喜好，即为矩阵分解算法！矩阵分解：将推荐值矩阵 R 分解为矩阵 U 和 矩阵 P，使得 U 和 P 的乘积得到的新矩阵 R* 中的元素与 R 中的已知元素的值非常接近，那么 R* 中对应于 R 中的未知元素的值就是预测值。</p><p>推荐值矩阵：</p><table><thead><tr><th></th><th>时间简史</th><th>万历三十年</th><th>大秦帝国</th><th>红楼梦</th><th>数学简史</th></tr></thead><tbody><tr><td>小明</td><td>1</td><td></td><td>4</td><td></td><td>1</td></tr><tr><td>小王</td><td></td><td>2</td><td></td><td>2</td><td>4</td></tr><tr><td>小李</td><td>4</td><td></td><td>1</td><td></td><td>4</td></tr><tr><td>小张</td><td></td><td>5</td><td>1</td><td>4</td><td></td></tr></tbody></table><p>推荐值矩阵关键性问题：</p><ol><li>初始值获取，数据的收集</li><li>从推荐值矩阵中已知数据预测未知数据</li><li>建立评价系统，用于检验推荐系统的效果</li></ol><h1>收集数据</h1><p>一般可以采取网络爬虫的方式，比如对于数据的评分，可以爬取豆瓣读书上的数据，也可以在自己可以控制的网站上做埋点等来收集用户信息。</p><h1>预测未知数据</h1><p>关键挑战：</p><ul><li><p>当用户和物品的数量都比较大时，推荐之矩阵通常会是一个稀疏矩阵（在矩阵中，若数值为0的元素数目远远多于非0元素的数目，并且非0元素分布没有规律时，则称该矩阵为稀疏矩阵），说明大多数用户可能并没有对大多数物品表达喜好。</p></li><li><p>冷启动问题，是每一个推荐系统都需要面对的问题。</p></li></ul><p>矩阵分解实例：$$\begin{pmatrix}1 &amp; 3 &amp; 5 &amp; 4 \\&amp; 2  &amp;  &amp; 4 \\<br>3 &amp; 4 &amp; 3 &amp; &amp;  \\\end{pmatrix}<br>\approx\begin{pmatrix}-0.77 &amp; -1.84 \\-0.2 &amp; -1.85 \\<br>-1.98 &amp; -0.54 \\\end{pmatrix}\begin{pmatrix}-1.46 &amp; -1.67 &amp; -0.88 &amp; -0.32 \\0.04 &amp; -0.89 &amp; -2.3 &amp; -2.04 &amp;  \\\end{pmatrix}  \\=\begin{pmatrix}1.06 &amp; 2.93 &amp; 4.9 &amp; 4 \\0.21 &amp; 1.97 &amp; 4.41 &amp; 3.84 \\<br>2.88 &amp; 3.79 &amp; 2.98 &amp; 1.73 &amp;  \\\end{pmatrix}$$即：$$R \approx U * P^T = R^*$$对比最左侧的元素矩阵和最右侧的预测矩阵，预测矩阵中位于原始矩阵缺失数值位置的元素值，即为预测值。同时也可以得到$$R_{ij} \approx U_i * P_j = R^*_{ij}$$</p><p>即：对于在 ij 位置上的物品的喜好数据，可以通过第 i 个用户的画像向量和第 j 个物品的画像向量代表。使用图形表示如下：<img src="/2019/07/30/基于矩阵分解算法的推荐系统实战/1.png">其中 k 在数学上的意义为矩阵分解的秩，在业务上的意义为 影响用户给物品评分的 k 个影响因子，当前我们无法直接知道 k 的值，在模型训练时，一般采取交叉验证的方式来寻找最优的 k 值。</p><p>我们可以使用“和方差”来作为损失函数</p><p>$$min_{U,P}\sum_{i,j}1/2(R_{ij}-U_i \cdot P_j)^2$$</p><blockquote><p>这里通过已知的{(i，j),r(ij)，计算“和方差”，使之达到最小，即预测值越接近真实值。以此得出的 U 和 P 的值就是我们需要的值。</p></blockquote><h2>损失函数的梯度</h2><p>单独取出误差$$L_{ij} = 1/2(R_{ij} - U_i \cdot P_j)^2$$对误差 L 分别在 U 和 P 上求导可得$$\frac{\partial L_{ij}}{\partial U_i} = \frac{\partial 1/2(R_{ij} - U_i \cdot P_j)^2}{\partial U_i} = -P_j(R_{ij} - U_i \cdot P_j)$$</p><p>$$\frac{\partial L_{ij}}{\partial P_j} = \frac{\partial 1/2(R_{ij} - U_i \cdot P_j)^2}{\partial P_j} = -U_i(R_{ij} - U_i \cdot P_j)$$</p><p>现在我们已经知道了损失函数的梯度（导数），下面就可以使用梯度下降法来求解 U 和 P 的值。</p><p><strong>梯度下降法</strong><img src="/2019/07/30/基于矩阵分解算法的推荐系统实战/2.png">随机选取一个起始点，然后在负梯度的方向上持续训练，直到损失函数的梯度越来越接近零，此时即可取得最优解。</p><h2>引入正则化</h2><p>为了防止过拟合的发生，对损失函数加入正则化参数$$λ[\sum_{i=1}^m|U_i|^2 + \sum_{i=1}^n|P_i|^2]$$λ&gt;0</p><blockquote><p>这样，当 U 和 P 都保证比较小的情况下，U 或者 P 的数值剧烈变化时，U 和 P 的点积也不会有太大的变化。</p></blockquote><p>最终的损失函数为：$$min_{U,P}\sum_{i,j}1/2(R_{ij}-U_i \cdot P_j)^2 + λ[\sum_{i=1}^m|U_i|^2 + \sum_{i=1}^n|P_i|^2]$$最终损失函数的梯度为：$$\frac{\partial L_{ij}}{\partial U_i} = \frac{\partial 1/2(R_{ij} - U_i \cdot P_j)^2}{\partial U_i} = -P_j(R_{ij} - U_i \cdot P_j) + λU_i$$</p><p>$$\frac{\partial L_{ij}}{\partial P_j} = \frac{\partial 1/2(R_{ij} - U_i \cdot P_j)^2}{\partial P_j} = -U_i(R_{ij} - U_i \cdot P_j) + λP_j$$</p><h2>运用梯度下降法求最优解</h2><p>设定梯度下降的速率 γ（学习速率）和 k 值，并随机初始化 U 和 P，重复训练，直到误差满意为止。$$U_i = U_i - γ\frac{\partial L_{ij}}{\partial U_i}$$</p><p>$$P_j = P_j - γ\frac{\partial L_{ij}}{\partial P_j}$$</p><h1>评估推荐系统</h1><ul><li>最基本的就是，通过训练集训练模型，通过测试集测试模型，如果模型在测试集上的表现达到我们的预期，则该模型可以上线部署。一般采用平均绝对离差来验证模型预测值的好坏$$M_d = 1/n\sum|r_{up} - r^*_{up}|$$</li></ul><blockquote><p>n: 测试集中推荐值的总数量</p><p>r(up): 真实的用户 u 对物品 p 的推荐值</p><p>r*(up): 预测的用户 u 对物品 p 的推荐值</p></blockquote><ul><li>在线的 A/B 测试</li></ul><h1>项目实战</h1><p>数据集格式如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span><span class="number">1119</span><span class="number">9.000000</span></span><br><span class="line"><span class="number">1</span><span class="number">167</span><span class="number">8.000000</span></span><br><span class="line"><span class="number">1</span><span class="number">6265</span><span class="number">8.000000</span></span><br><span class="line"><span class="number">1</span><span class="number">1440</span><span class="number">9.000000</span></span><br><span class="line"><span class="number">1</span><span class="number">1427</span><span class="number">9.000000</span></span><br><span class="line"><span class="number">1</span><span class="number">5404</span><span class="number">8.000000</span></span><br><span class="line"><span class="number">1</span><span class="number">259</span><span class="number">7.000000</span></span><br><span class="line"><span class="number">1</span><span class="number">4156</span><span class="number">8.000000</span></span><br><span class="line"><span class="number">2</span><span class="number">419</span><span class="number">9.000000</span></span><br><span class="line"><span class="number">2</span><span class="number">415</span><span class="number">10.000000</span></span><br><span class="line"><span class="number">2</span><span class="number">2834</span><span class="number">9.000000</span></span><br><span class="line"><span class="number">2</span><span class="number">228</span><span class="number">10.000000</span></span><br><span class="line"><span class="number">2</span><span class="number">107</span><span class="number">10.000000</span></span><br><span class="line"><span class="number">2</span><span class="number">440</span><span class="number">9.000000</span></span><br><span class="line"><span class="number">2</span><span class="number">44</span><span class="number">10.000000</span></span><br><span class="line"><span class="number">2</span><span class="number">455</span><span class="number">10.000000</span></span><br></pre></td></tr></table></figure></p><blockquote><p>第一列为用户 ID，第二列为物品 ID，第三列为对应的打分（1-10）</p></blockquote><p>总体代码基于 surprise 库，可以先安装<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scikit-surprise</span><br></pre></td></tr></table></figure></p><p>下面导入相关库和数据集</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> surprise</span><br><span class="line"><span class="keyword">from</span> surprise <span class="keyword">import</span> BaselineOnly</span><br><span class="line"><span class="keyword">from</span> surprise <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> surprise <span class="keyword">import</span> Reader</span><br><span class="line"><span class="keyword">from</span> surprise <span class="keyword">import</span> accuracy</span><br><span class="line"><span class="keyword">from</span> surprise.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line"><span class="keyword">from</span> surprise.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">reader = Reader(line_format=<span class="string">'user item rating'</span>, sep=<span class="string">'\t'</span>, rating_scale=(<span class="number">1</span>, <span class="number">10</span>))</span><br><span class="line">data = Dataset.load_from_file(<span class="string">'book_ratings.dat.txt'</span>, reader=reader)</span><br><span class="line"><span class="comment"># 将数据随机分为训练和测试数据集</span></span><br><span class="line">trainset, testset = train_test_split(data, test_size=<span class="number">.25</span>)</span><br></pre></td></tr></table></figure></p><p>根据公式，定义算法函数<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MatrixFactorization</span><span class="params">(surprise.AlgoBase)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, lr, n_epochs, n_factors, lmd)</span>:</span></span><br><span class="line">        self.lr = lr  <span class="comment"># 梯度下降法的学习速率</span></span><br><span class="line">        self.n_epochs = n_epochs  <span class="comment"># 梯度下降法的迭代次数</span></span><br><span class="line">        self.n_factors = n_factors  <span class="comment"># 分解的矩阵的秩，即影响用户打分的隐藏因子</span></span><br><span class="line">        self.lmd = lmd  <span class="comment"># 正则化参数</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, trainset)</span>:</span></span><br><span class="line">        print(<span class="string">"Fitting data..."</span>)</span><br><span class="line">        <span class="comment"># 随机初始化 u 和 p 矩阵</span></span><br><span class="line">        u = np.random.normal(<span class="number">0</span>, <span class="number">.1</span>, (trainset.n_users, self.n_factors))  <span class="comment"># 均值为0，方差为0.1，（行数，列数）</span></span><br><span class="line">        p = np.random.normal(<span class="number">0</span>, <span class="number">.1</span>, (trainset.n_items, self.n_factors))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 梯度下降法</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(self.n_epochs):</span><br><span class="line">            print(<span class="string">"Round:"</span>, _)</span><br><span class="line">            <span class="keyword">for</span> i, j, r_ij <span class="keyword">in</span> trainset.all_ratings():</span><br><span class="line">                <span class="comment"># 这里就是套用上面得到的公式</span></span><br><span class="line">                <span class="comment"># u_old[i] = u[i]</span></span><br><span class="line">                err = r_ij - np.dot(u[i], p[j])</span><br><span class="line">                u[i] -= -self.lr * err * p[j] + self.lr * self.lmd * u[i]</span><br><span class="line">                p[j] -= -self.lr * err * u[i] + self.lr * self.lmd * p[j]</span><br><span class="line">        </span><br><span class="line">        self.u, self.p = u, p</span><br><span class="line">        self.trainset = trainset</span><br><span class="line">        print(<span class="string">"End fitting!"</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">estimate</span><span class="params">(self, i, j)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.trainset.knows_user(i) <span class="keyword">and</span> self.trainset.knows_item(j):</span><br><span class="line">            <span class="keyword">return</span> np.dot(self.u[i], self.p[j])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.trainset.global_mean  <span class="comment"># 返回平均值</span></span><br></pre></td></tr></table></figure></p><p>最后再训练、预测，评估<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">algo = MatrixFactorization(<span class="number">0.005</span>, <span class="number">60</span>, <span class="number">3</span>, <span class="number">0.2</span>)</span><br><span class="line">algo.fit(trainset)</span><br><span class="line">predictions = algo.test(testset)</span><br><span class="line">accuracy.mae(predictions)</span><br></pre></td></tr></table></figure></p><blockquote><p>可以调整学习速率，迭代次数，隐藏因子个数和正则化参数等来训练不同的模型，并评估结果，获取满意的模型。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/07/30/基于矩阵分解算法的推荐系统实战/jiqixuexi.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;基于矩阵分解算法的图书推荐系统实战&lt;/p&gt;
&lt;h1&gt;推荐系统&lt;/h1&gt;
&lt;p&gt;推荐系统，可以根据用户的喜好来推荐给用户不同的事物。&lt;/p&gt;
&lt;p&gt;推荐系统类型：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;纯手工设置推荐内容&lt;/li&gt;
&lt;li&gt;根据物品的销量，曝光率等来排序物品，并推荐给用户&lt;/li&gt;
&lt;li&gt;根据不同的算法，整合不同维度的数据，来智能的推荐物品&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;简单的推荐系统模型&lt;/h2&gt;
&lt;p&gt;设：
U 为所有用户集合
P 为所有物品集合
R 为用户对物品的喜好程度
模型 Model(R) = U * P
算法核心：&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://blog.luobodazahui.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Python" scheme="https://blog.luobodazahui.top/tags/Python/"/>
    
      <category term="机器学习" scheme="https://blog.luobodazahui.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>轻松玩转HTTPS</title>
    <link href="https://blog.luobodazahui.top/2019/07/30/%E8%BD%BB%E6%9D%BE%E7%8E%A9%E8%BD%ACHTTPS/"/>
    <id>https://blog.luobodazahui.top/2019/07/30/轻松玩转HTTPS/</id>
    <published>2019-07-30T01:22:22.000Z</published>
    <updated>2019-07-31T10:40:43.918Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/07/30/轻松玩转HTTPS/4.jpg"></p><p>今天分享一个非常给力的 SSL 证书生成网站，从此 HTTPS 不再是难事儿！</p><h1>Certbot</h1><p>不错，今天的主角就是给力的 Certbot，免费好用，真是我等 diaosi 的一大福音。</p><p>我们先打开其官网，整体浏览下</p><blockquote><p>https://certbot.eff.org/lets-encrypt/centos6-nginx</p></blockquote><p>我们可以看到，想使用 Certbot，需要一些条件</p><p><img src="/2019/07/30/轻松玩转HTTPS/1.png"></p><ol><li><p>需要一个命令行服务器，一般就是 linux了。我这里使用的是 CentOS6</p></li><li><p>我们需要已经部署了一个 http 服务，80 端口是监听状态的，我使用的是 Nginx 代理。</p></li><li><p>有执行 root 权限的用户。</p><p><a id="more"></a></p></li></ol><h1>具体安装</h1><p>在使用官网上的安装步骤前，我们要先有 Nginx，并且已经成功启动，当然也要有绑定了公网 IP 的域名，因为 SSL 证书都是要绑定到具体域名的。公网 IP，域名申请，Nginx 安装等，就不说啦，我们现在来看一下我这里 Nginx 的简单配置。</p><p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       443;</span><br><span class="line">    server_name  www.kungfuworld.top;</span><br><span class="line">    ssl on;</span><br><span class="line">    root        /home/KungFuWorld/      ;</span><br><span class="line">    access_log  /home/log/access.log;</span><br><span class="line">    error_log   /home/log/error.log;</span><br><span class="line">    ssl_session_timeout 5m;</span><br><span class="line">    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;</span><br><span class="line">    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">    ssl_prefer_server_ciphers on;</span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass       http://127.0.0.1:5000;</span><br><span class="line">        proxy_set_header Host $host;</span><br><span class="line">        proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">        index  index.html index.htm;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name kungfuworld.top;</span><br><span class="line">    rewrite ^(.*)$ https://$host$1 permanent;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p>我配置的域名是 www.kungfuworld.top，后面在执行 Certbot 安装时，会自动扫描到这里配置的域名，从而根据这个域名来生成证书。下面，就是一步步的安装官网的步骤来操作就好了</p><h2>安装 Certbot</h2><p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https://dl.eff.org/certbot-auto</span><br><span class="line">sudo mv certbot-auto /usr/local/bin/certbot-auto</span><br><span class="line">sudo chown root /usr/local/bin/certbot-auto</span><br><span class="line">sudo chmod 0755 /usr/local/bin/certbot-auto</span><br></pre></td></tr></table></figure></p><h2>生成证书</h2><p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /usr/local/bin/certbot-auto certonly --nginx</span><br></pre></td></tr></table></figure></p><blockquote><p>中间会有一些需要用户交互的步骤，按照提示操作就好</p></blockquote><h2>配置 Nginx</h2><p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssl_certificate /etc/letsencrypt/live/kungfuworld.top/fullchain.pem;</span><br><span class="line">ssl_certificate_key /etc/letsencrypt/live/kungfuworld.top/privkey.pem;</span><br></pre></td></tr></table></figure></p><p>在刚刚的 Nginx 配置文件中，增加上面的两条配置，就完成了证书的配置。</p><p>如果不出意外，该域名的 HTTPS 就可以访问了，而且是浏览器信任的证书。</p><p><img src="/2019/07/30/轻松玩转HTTPS/2.png"></p><h2>自动更新</h2><p>使用 Certbot 安装的证书，只有 90 天的有效期，还好其提供了方便的自动更新功能</p><p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/bin/certbot-auto renew</span><br></pre></td></tr></table></figure></p><p>我们可以创建一个 crontab 任务，来自动更新<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 4 */80 * * /usr/local/bin/certbot-auto renew &amp;&gt;&gt; /dev/null</span><br></pre></td></tr></table></figure></p><blockquote><p>每隔 80 天在凌晨 4 点执行一次 renew 操作</p></blockquote><p>至此，基于 Certbot 的 HTTPS 配置就完成了，可以开心的使用 HTTPS 喽。</p><p><img src="/2019/07/30/轻松玩转HTTPS/3.jpg"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/07/30/轻松玩转HTTPS/4.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;今天分享一个非常给力的 SSL 证书生成网站，从此 HTTPS 不再是难事儿！&lt;/p&gt;
&lt;h1&gt;Certbot&lt;/h1&gt;
&lt;p&gt;不错，今天的主角就是给力的 Certbot，免费好用，真是我等 diaosi 的一大福音。&lt;/p&gt;
&lt;p&gt;我们先打开其官网，整体浏览下&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;https://certbot.eff.org/lets-encrypt/centos6-nginx&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们可以看到，想使用 Certbot，需要一些条件&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/07/30/轻松玩转HTTPS/1.png&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;需要一个命令行服务器，一般就是 linux了。我这里使用的是 CentOS6&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;我们需要已经部署了一个 http 服务，80 端口是监听状态的，我使用的是 Nginx 代理。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有执行 root 权限的用户。&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="系统" scheme="https://blog.luobodazahui.top/categories/%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="系统" scheme="https://blog.luobodazahui.top/tags/%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="shell" scheme="https://blog.luobodazahui.top/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>惊闻马大姐婚变，我连夜爬了微博评论，沦陷</title>
    <link href="https://blog.luobodazahui.top/2019/07/29/%E6%83%8A%E9%97%BB%E9%A9%AC%E5%A4%A7%E5%A7%90%E5%A9%9A%E5%8F%98%EF%BC%8C%E6%88%91%E8%BF%9E%E5%A4%9C%E7%88%AC%E4%BA%86%E5%BE%AE%E5%8D%9A%E8%AF%84%E8%AE%BA%EF%BC%8C%E6%B2%A6%E9%99%B7/"/>
    <id>https://blog.luobodazahui.top/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/</id>
    <published>2019-07-29T11:41:36.000Z</published>
    <updated>2019-07-31T10:40:10.633Z</updated>
    
    <content type="html"><![CDATA[<p></p><p><img src="/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/pojing.jpg"></p><p>娱乐圈的瓜真的是一波又一波，这次又轮到文章和马伊琍了。他们具体为啥会婚变，咱也不知道，啥也不敢问，啥也不干说。不过他们微博下面还是开锅了，下面就一起来看看吧。</p><h1>微博页面分析</h1><p>首先我们先来看看微博页面，爬虫要从何处下手。</p><h2>页面分析</h2><p>我们直接进入到马伊琍微博的评论页面</p><p>https://weibo.com/1196235387/HFyy4wabF?filter=hot&amp;root_comment_id=0&amp;type=comment</p><p>可以看到页面如下：</p><p><img src="/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/1.png"></p><p><a id="more"></a></p><p>然后我们使用 Chrome 的调试工具（F12），切换到 Network 页签，再次刷新页面，能够看到一条请求，如下：</p><p><img src="/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/2.png"></p><p>先拷贝出这个请求 URL，放到 Postman 里试一试，如图：</p><p><img src="/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/3.png"></p><p>这都是些神马啊</p><p><img src="/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/4.png" width="250" height="150"></p><p>果然没那么简单，看来有反爬在作怪，那么反反爬三板斧先用起来，headers 加一哈再来继续继续观察 Network 中的请求 headers，发现有一个 Cookie 是那么的长，拷贝出来添加上试试吧</p><p><img src="/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/5.png"></p><p>再次使用 Postman 调用</p><p><img src="/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/6.png"></p><p>哎呦，不错哦，有正常数据返回了</p><p><img src="/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/aiyou.jpg"></p><h2>URL 分析</h2><p>现在再来看看我们使用的 URL</p><p>https://weibo.com/aj/v6/comment/big?ajwvr=6&amp;id=4399042567665659&amp;from=singleWeiBo&amp;__rnd=1564381638125，总共有4各参数，ajwvr、id、from 和 __rnd。</p><p><strong>1.精简 URL</strong></p><p>我们先从后往前一个一个的去掉每个参数试试，发现去掉后面两个，我们都可以获取到评论记录，那么后面两个参数我们就去掉它，现在的 URL 变为：</p><p>https://weibo.com/aj/v6/comment/big?ajwvr=6&amp;id=4399042567665659</p><p><strong>2.增加 page 参数</strong></p><p>再次观察现在获取到的数据，发现返回的数据还有一个 page 的数据域，如下：</p><p><img src="/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/7.png"></p><p>而且当前是在 &quot;pagenum&quot;: 1 的，那么我们要怎么控制到不同的 page 页面呢，试着增加一个 page 参数到 URL 中，如：</p><p>https://weibo.com/aj/v6/comment/big?ajwvr=6&amp;id=4399042567665659&amp;page=2</p><p>果然，真的访问到 page 2 了，是不是很香啊</p><p><img src="/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/8.png"></p><p><img src="/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/zhengxiang.jpg"></p><p>至此，我们的页面分析就基本完成了，下面就是拿数据喽。</p><h1>获取并保存数据</h1><p>获取保存数据的部分就比较常规了，直接看代码</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Headers = &#123;<span class="string">'Cookie'</span>: <span class="string">'SINAGLOBAL=4979979695709.662.1540896279940; SUB=_2AkMrYbTuf8PxqwJRmPkVyG_nb45wwwHEieKdPUU1JRMxHRl-yT83qnI9tRB6AOGaAcavhZVIZBiCoxtgPDNVspj9jtju; SUBP=0033WrSXqPxfM72-Ws9jqgMF55529P9D9W5d4hHnVEbZCn4G2L775Qe1; _s_tentry=-; Apache=1711120851984.973.1564019682028; ULV=1564019682040:7:2:1:1711120851984.973.1564019682028:1563525180101; login_sid_t=8e1b73050dedb94d4996a67f8d74e464; cross_origin_proto=SSL; Ugrow-G0=140ad66ad7317901fc818d7fd7743564; YF-V5-G0=95d69db6bf5dfdb71f82a9b7f3eb261a; WBStorage=edfd723f2928ec64|undefined; UOR=bbs.51testing.com,widget.weibo.com,www.baidu.com; wb_view_log=1366*7681; WBtopGlobal_register_version=307744aa77dd5677; YF-Page-G0=580fe01acc9791e17cca20c5fa377d00|1564363890|1564363890'</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mayili</span><span class="params">(page)</span>:</span></span><br><span class="line">    mayili = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, page):</span><br><span class="line">        print(<span class="string">"page: "</span>, i)</span><br><span class="line">        url = <span class="string">'https://weibo.com/aj/v6/comment/big?ajwvr=6&amp;id=4399042567665659&amp;page=%s'</span> % int(i)</span><br><span class="line">        req = requests.get(url, headers=Headers).text</span><br><span class="line">        html = json.loads(req)[<span class="string">'data'</span>][<span class="string">'html'</span>]</span><br><span class="line">        content = BeautifulSoup(html, <span class="string">"html.parser"</span>)</span><br><span class="line">        <span class="comment"># comment = content.find_all('div', attrs=&#123;'class': 'list_li S_line1 clearfix'&#125;)</span></span><br><span class="line">        comment_text = content.find_all(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'WB_text'</span>&#125;)</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> comment_text:</span><br><span class="line">            mayili_text = c.text.split(<span class="string">"："</span>)[<span class="number">1</span>]</span><br><span class="line">            mayili.append(mayili_text)</span><br><span class="line">        time.sleep(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mayili</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wenzhang</span><span class="params">(page)</span>:</span></span><br><span class="line">    wenzhang = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, page):</span><br><span class="line">        print(<span class="string">"page: "</span>, i)</span><br><span class="line">        url = <span class="string">'https://weibo.com/aj/v6/comment/big?ajwvr=6&amp;id=4399042089738682&amp;page=%s'</span> % int(i)</span><br><span class="line">        req = requests.get(url, headers=Headers).text</span><br><span class="line">        html = json.loads(req)[<span class="string">'data'</span>][<span class="string">'html'</span>]</span><br><span class="line">        content = BeautifulSoup(html, <span class="string">"html.parser"</span>)</span><br><span class="line">        <span class="comment"># comment = content.find_all('div', attrs=&#123;'class': 'list_li S_line1 clearfix'&#125;)</span></span><br><span class="line">        comment_text = content.find_all(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'WB_text'</span>&#125;)</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> comment_text:</span><br><span class="line">            wenzhang_text = c.text.split(<span class="string">"："</span>)[<span class="number">1</span>]</span><br><span class="line">            wenzhang.append(wenzhang_text)</span><br><span class="line">        time.sleep(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> wenzhang</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">"start"</span>)</span><br><span class="line">    ma_comment = mayili(<span class="number">1001</span>)</span><br><span class="line">    mayili_pd = pd.DataFrame(columns=[<span class="string">'mayili_comment'</span>], data=ma_comment)</span><br><span class="line">    mayili_pd.to_csv(<span class="string">'mayili.csv'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">    wen_comment = wenzhang(<span class="number">1001</span>)</span><br><span class="line">    wenzhang_pd = pd.DataFrame(columns=[<span class="string">'wenzhang_comment'</span>], data=wen_comment)</span><br><span class="line">    wenzhang_pd.to_csv(<span class="string">'wenzhang.csv'</span>, encoding=<span class="string">'utf-8'</span>)</span><br></pre></td></tr></table></figure></p><p>总共 page 页面有 2000 多页，要爬完还真是需要一段时间，我这里配置了 1000，应该是够了。</p><p>而且还做了 sleep 5 的操作，主要是因为如果爬取太快，会被微博视为异常请求，会被禁，而且也不会对人家的正常服务产生影响，毕竟盗亦有道嘛！</p><p><img src="/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/jilinggui.jpg" width="250" height="150"></p><h1>词云做成</h1><p>等爬虫跑完之后，我们简单看下数据的内容马伊琍微博评论</p><p><img src="/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/9.png"></p><p>文章微博评论</p><p><img src="/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/10.png"></p><p>数据都拿到了，下面就做成词云看看各路粉丝的态度吧这里就不对评论内容做过多置喙了，毕竟说多了都是错</p><p><img src="/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/jilinggui2.jpg" width="250" height="150"></p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wordcloud_m</span><span class="params">()</span>:</span></span><br><span class="line">    df = pd.read_csv(<span class="string">'mayili.csv'</span>, usecols=[<span class="number">1</span>])</span><br><span class="line">    df_copy = df.copy()</span><br><span class="line">    df_copy[<span class="string">'mayili_comment'</span>] = df_copy[<span class="string">'mayili_comment'</span>].apply(<span class="keyword">lambda</span> x: str(x).split())  <span class="comment"># 去掉空格</span></span><br><span class="line">    df_list = df_copy.values.tolist()</span><br><span class="line">    comment = jieba.cut(str(df_list), cut_all=<span class="literal">False</span>)</span><br><span class="line">    words = <span class="string">' '</span>.join(comment)</span><br><span class="line">    wc = WordCloud(width=<span class="number">2000</span>, height=<span class="number">1800</span>, background_color=<span class="string">'white'</span>, font_path=font,</span><br><span class="line">                   stopwords=STOPWORDS, contour_width=<span class="number">3</span>, contour_color=<span class="string">'steelblue'</span>)</span><br><span class="line">    wc.generate(words)</span><br><span class="line">    wc.to_file(<span class="string">'m.png'</span>)</span><br></pre></td></tr></table></figure></p><p>马伊琍评论词云</p><p><img src="/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/m.png"></p><p>文章评论词云</p><p><img src="/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/w.png"></p><p>最后，我把所有的代码都上传到 GitHub 上了，需要的可以自取https://github.com/zhouwei713/data_analysis/tree/master/weibo_mayili_wenzhang</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/pojing.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;娱乐圈的瓜真的是一波又一波，这次又轮到文章和马伊琍了。他们具体为啥会婚变，咱也不知道，啥也不敢问，啥也不干说。不过他们微博下面还是开锅了，下面就一起来看看吧。&lt;/p&gt;
&lt;h1&gt;微博页面分析&lt;/h1&gt;
&lt;p&gt;首先我们先来看看微博页面，爬虫要从何处下手。&lt;/p&gt;
&lt;h2&gt;页面分析&lt;/h2&gt;
&lt;p&gt;我们直接进入到马伊琍微博的评论页面&lt;/p&gt;
&lt;p&gt;https://weibo.com/1196235387/HFyy4wabF?filter=hot&amp;amp;root_comment_id=0&amp;amp;type=comment&lt;/p&gt;
&lt;p&gt;可以看到页面如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/07/29/惊闻马大姐婚变，我连夜爬了微博评论，沦陷/1.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.luobodazahui.top/categories/Python/"/>
    
    
      <category term="Python" scheme="https://blog.luobodazahui.top/tags/Python/"/>
    
      <category term="爬虫" scheme="https://blog.luobodazahui.top/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
</feed>
